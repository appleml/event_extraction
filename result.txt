Vocab size 9823 loaded from file
Loading data from dataset/2013_data with batch size 1...
所有事件个数: 6013
跨句子事件个数： 261
有效事件个数： 5752
#################################
data_utils.py error
data_utils.py error
data_utils.py error
2060 batches created for dataset/2013_data/2013_train
所有事件个数: 3199
跨句子事件个数： 116
有效事件个数： 3083
#################################
data_utils.py error
data_utils.py error
data_utils.py error
1057 batches created for dataset/2013_data/2013_devel
Directory ./saved_models/00 do not exist; creating...
Config saved to file ./saved_models/00/config.json

Running with the following configs:
	data_dir : dataset/2013_data
	parse_dir : dataset/2013_genia_parse
	vocab_dir : dataset/vocab
	emb_dim : 300
	char_dim : 30
	conv_filter_size : 2
	pos_dim : 30
	prot_dim : 2
	jprot_dim : 2
	cjprot_dim : 2
	ctrig_dim : 8
	dep_dim : 30
	ner_dim : 10
	rnn_input_dim : 600
	hidden_dim : 200
	num_layers : 2
	input_dropout : 0.5
	gcn_dropout : 0.5
	word_dropout : 0.04
	context_window : 100
	conv_l2 : 0
	pooling : avg
	pooling_l2 : 0
	mlp_layers : 2
	rnn : True
	rnn_hidden : 200
	rnn_layers : 1
	rnn_dropout : 0.5
	lr : 0.0001
	jprot_lr : 0.0001
	trig_lr : 0.0001
	lr_decay : 0.95
	decay_epoch : 5
	warmup_steps : 0
	optim : adam
	num_epoch : 80
	batch_size : 1
	max_grad_norm : 5.0
	log_step : 20
	log : logs.txt
	save_epoch : 100
	save_dir : ./saved_models
	id : 00
	info : 
	seed : 1234
	cuda : True
	cpu : False
	load : False
	model_file : None
	num_class : 3
	vocab_size : 9823
	t_total : 164800
	model_save_dir : ./saved_models/00


/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
2021-07-12 09:25:24.804885: step 20/164800 (epoch 1/80),jp_loss = 10.585976, trig_loss = 19.546310, rela_loss = 22.552237, bind_loss = 0.000000 (1.795 sec/batch), lr: 0.000100
2021-07-12 09:25:54.707461: step 40/164800 (epoch 1/80),jp_loss = 4.436867, trig_loss = 20.646500, rela_loss = 9.082946, bind_loss = 0.000000 (0.836 sec/batch), lr: 0.000100
2021-07-12 09:26:29.695921: step 60/164800 (epoch 1/80),jp_loss = 7.103271, trig_loss = 7.458847, rela_loss = 16.820210, bind_loss = 0.000000 (0.678 sec/batch), lr: 0.000100
2021-07-12 09:26:53.073849: step 80/164800 (epoch 1/80),jp_loss = 3.270882, trig_loss = 4.998215, rela_loss = 12.390163, bind_loss = 0.000000 (0.650 sec/batch), lr: 0.000100
2021-07-12 09:27:27.966696: step 100/164800 (epoch 1/80),jp_loss = 2.733131, trig_loss = 19.875114, rela_loss = 4.513425, bind_loss = 0.000000 (0.751 sec/batch), lr: 0.000100
2021-07-12 09:27:55.218315: step 120/164800 (epoch 1/80),jp_loss = 3.040268, trig_loss = 8.007080, rela_loss = 0.037044, bind_loss = 0.000000 (1.223 sec/batch), lr: 0.000100
2021-07-12 09:28:27.570438: step 140/164800 (epoch 1/80),jp_loss = 0.964863, trig_loss = 5.795040, rela_loss = 2.481990, bind_loss = 0.003170 (0.617 sec/batch), lr: 0.000100
2021-07-12 09:28:50.914540: step 160/164800 (epoch 1/80),jp_loss = 0.326385, trig_loss = 5.455353, rela_loss = 4.848160, bind_loss = 0.000000 (0.697 sec/batch), lr: 0.000100
2021-07-12 09:29:23.754705: step 180/164800 (epoch 1/80),jp_loss = 1.432373, trig_loss = 7.201431, rela_loss = 5.038565, bind_loss = 0.000000 (1.201 sec/batch), lr: 0.000100
2021-07-12 09:29:47.018197: step 200/164800 (epoch 1/80),jp_loss = 0.828224, trig_loss = 30.327660, rela_loss = 7.977697, bind_loss = 0.000000 (1.218 sec/batch), lr: 0.000100
2021-07-12 09:30:13.517941: step 220/164800 (epoch 1/80),jp_loss = 0.234726, trig_loss = 6.074371, rela_loss = 14.634767, bind_loss = 0.000000 (0.667 sec/batch), lr: 0.000100
2021-07-12 09:30:48.475325: step 240/164800 (epoch 1/80),jp_loss = 0.127899, trig_loss = 5.142487, rela_loss = 5.498821, bind_loss = 0.000000 (0.695 sec/batch), lr: 0.000100
2021-07-12 09:31:14.442212: step 260/164800 (epoch 1/80),jp_loss = 3.511841, trig_loss = 1.610168, rela_loss = 6.330758, bind_loss = 0.000000 (1.336 sec/batch), lr: 0.000100
2021-07-12 09:31:47.027129: step 280/164800 (epoch 1/80),jp_loss = 0.051311, trig_loss = 2.371704, rela_loss = 1.228980, bind_loss = 0.000000 (0.400 sec/batch), lr: 0.000100
2021-07-12 09:32:18.630603: step 300/164800 (epoch 1/80),jp_loss = 0.150558, trig_loss = 2.074341, rela_loss = 4.374151, bind_loss = 0.000000 (0.608 sec/batch), lr: 0.000100
2021-07-12 09:32:46.547353: step 320/164800 (epoch 1/80),jp_loss = 0.092361, trig_loss = 18.975708, rela_loss = 3.100475, bind_loss = 0.000000 (1.077 sec/batch), lr: 0.000100
2021-07-12 09:33:17.158447: step 340/164800 (epoch 1/80),jp_loss = 0.080750, trig_loss = 1.880936, rela_loss = 7.725630, bind_loss = 0.000000 (0.595 sec/batch), lr: 0.000100
2021-07-12 09:33:49.496660: step 360/164800 (epoch 1/80),jp_loss = 0.110657, trig_loss = 3.967667, rela_loss = 6.199483, bind_loss = 0.000000 (0.666 sec/batch), lr: 0.000100
2021-07-12 09:34:10.249079: step 380/164800 (epoch 1/80),jp_loss = 1.514679, trig_loss = 5.422577, rela_loss = 9.016262, bind_loss = 0.019250 (2.138 sec/batch), lr: 0.000100
2021-07-12 09:34:31.357965: step 400/164800 (epoch 1/80),jp_loss = 3.840210, trig_loss = 3.747574, rela_loss = 0.305277, bind_loss = 0.000000 (0.703 sec/batch), lr: 0.000100
2021-07-12 09:35:08.581913: step 420/164800 (epoch 1/80),jp_loss = 7.241150, trig_loss = 20.447388, rela_loss = 2.329251, bind_loss = 0.000000 (2.417 sec/batch), lr: 0.000100
2021-07-12 09:35:35.399863: step 440/164800 (epoch 1/80),jp_loss = 6.554550, trig_loss = 8.455444, rela_loss = 0.010025, bind_loss = 0.000000 (0.832 sec/batch), lr: 0.000100
2021-07-12 09:35:58.480273: step 460/164800 (epoch 1/80),jp_loss = 5.658543, trig_loss = 5.452431, rela_loss = 0.417826, bind_loss = 0.003247 (1.160 sec/batch), lr: 0.000100
2021-07-12 09:36:46.720692: step 480/164800 (epoch 1/80),jp_loss = 5.777985, trig_loss = 13.313934, rela_loss = 0.723744, bind_loss = 0.000000 (6.529 sec/batch), lr: 0.000100
2021-07-12 09:37:07.914879: step 500/164800 (epoch 1/80),jp_loss = 0.069656, trig_loss = 1.502151, rela_loss = 3.279504, bind_loss = 0.000000 (0.608 sec/batch), lr: 0.000100
2021-07-12 09:37:33.424316: step 520/164800 (epoch 1/80),jp_loss = 0.061462, trig_loss = 0.558029, rela_loss = 2.217377, bind_loss = 0.000000 (0.789 sec/batch), lr: 0.000100
2021-07-12 09:38:09.278974: step 540/164800 (epoch 1/80),jp_loss = 1.646652, trig_loss = 3.182465, rela_loss = 0.024481, bind_loss = 0.000000 (0.856 sec/batch), lr: 0.000100
2021-07-12 09:38:44.530768: step 560/164800 (epoch 1/80),jp_loss = 12.704575, trig_loss = 15.896469, rela_loss = 1.102933, bind_loss = 0.000000 (3.491 sec/batch), lr: 0.000100
2021-07-12 09:39:21.465447: step 580/164800 (epoch 1/80),jp_loss = 0.216263, trig_loss = 22.348022, rela_loss = 0.167383, bind_loss = 0.000000 (1.427 sec/batch), lr: 0.000100
2021-07-12 09:39:45.049018: step 600/164800 (epoch 1/80),jp_loss = 0.077332, trig_loss = 3.910233, rela_loss = 0.452152, bind_loss = 0.000000 (1.441 sec/batch), lr: 0.000100
2021-07-12 09:40:10.123576: step 620/164800 (epoch 1/80),jp_loss = 11.104538, trig_loss = 5.263443, rela_loss = 0.257714, bind_loss = 0.011508 (1.986 sec/batch), lr: 0.000100
2021-07-12 09:40:42.142407: step 640/164800 (epoch 1/80),jp_loss = 2.294998, trig_loss = 7.104523, rela_loss = 0.011530, bind_loss = 0.000000 (1.532 sec/batch), lr: 0.000100
2021-07-12 09:41:05.161355: step 660/164800 (epoch 1/80),jp_loss = 0.029404, trig_loss = 0.363861, rela_loss = 0.000006, bind_loss = 0.000000 (0.625 sec/batch), lr: 0.000100
2021-07-12 09:41:29.143743: step 680/164800 (epoch 1/80),jp_loss = 7.692276, trig_loss = 2.399857, rela_loss = 6.935426, bind_loss = 0.000000 (0.938 sec/batch), lr: 0.000100
2021-07-12 09:41:54.043000: step 700/164800 (epoch 1/80),jp_loss = 0.015495, trig_loss = 31.940117, rela_loss = 2.586470, bind_loss = 0.000000 (1.143 sec/batch), lr: 0.000100
2021-07-12 09:42:20.559300: step 720/164800 (epoch 1/80),jp_loss = 0.017387, trig_loss = 2.543182, rela_loss = 0.925563, bind_loss = 0.000000 (0.633 sec/batch), lr: 0.000100
2021-07-12 09:42:45.576887: step 740/164800 (epoch 1/80),jp_loss = 2.158920, trig_loss = 5.853180, rela_loss = 0.075638, bind_loss = 0.000000 (1.334 sec/batch), lr: 0.000100
2021-07-12 09:43:17.889863: step 760/164800 (epoch 1/80),jp_loss = 12.312500, trig_loss = 7.020370, rela_loss = 0.095053, bind_loss = 0.000000 (0.723 sec/batch), lr: 0.000100
2021-07-12 09:43:49.163893: step 780/164800 (epoch 1/80),jp_loss = 0.029728, trig_loss = 1.236565, rela_loss = 3.368525, bind_loss = 0.000000 (0.324 sec/batch), lr: 0.000100
2021-07-12 09:44:32.082735: step 800/164800 (epoch 1/80),jp_loss = 4.974411, trig_loss = 3.623398, rela_loss = 3.370116, bind_loss = 0.000000 (0.745 sec/batch), lr: 0.000100
2021-07-12 09:44:58.202669: step 820/164800 (epoch 1/80),jp_loss = 0.064346, trig_loss = 9.755981, rela_loss = 1.183584, bind_loss = 0.000000 (1.128 sec/batch), lr: 0.000100
2021-07-12 09:45:31.178985: step 840/164800 (epoch 1/80),jp_loss = 26.999969, trig_loss = 5.719147, rela_loss = 3.287504, bind_loss = 2.293942 (4.251 sec/batch), lr: 0.000100
2021-07-12 09:45:55.521652: step 860/164800 (epoch 1/80),jp_loss = 3.774628, trig_loss = 2.265686, rela_loss = 2.836527, bind_loss = 0.000000 (0.942 sec/batch), lr: 0.000100
2021-07-12 09:46:22.920024: step 880/164800 (epoch 1/80),jp_loss = 0.094910, trig_loss = 3.053162, rela_loss = 2.377050, bind_loss = 0.000000 (2.846 sec/batch), lr: 0.000100
2021-07-12 09:46:46.537292: step 900/164800 (epoch 1/80),jp_loss = 4.709610, trig_loss = 2.881958, rela_loss = 1.819364, bind_loss = 0.000000 (0.423 sec/batch), lr: 0.000100
2021-07-12 09:47:17.012590: step 920/164800 (epoch 1/80),jp_loss = 0.018951, trig_loss = 3.940369, rela_loss = 0.000822, bind_loss = 0.000000 (0.745 sec/batch), lr: 0.000100
2021-07-12 09:47:50.172612: step 940/164800 (epoch 1/80),jp_loss = 3.596649, trig_loss = 1.314941, rela_loss = 2.339204, bind_loss = 0.000000 (0.701 sec/batch), lr: 0.000100
2021-07-12 09:48:18.396979: step 960/164800 (epoch 1/80),jp_loss = 0.126648, trig_loss = 0.669922, rela_loss = 0.540424, bind_loss = 0.000000 (2.036 sec/batch), lr: 0.000100
2021-07-12 09:48:47.529994: step 980/164800 (epoch 1/80),jp_loss = 7.204147, trig_loss = 12.666275, rela_loss = 0.806378, bind_loss = 0.000000 (0.524 sec/batch), lr: 0.000100
2021-07-12 09:49:23.034406: step 1000/164800 (epoch 1/80),jp_loss = 26.882660, trig_loss = 2.282990, rela_loss = 0.396936, bind_loss = 0.000000 (0.896 sec/batch), lr: 0.000100
2021-07-12 09:49:53.084798: step 1020/164800 (epoch 1/80),jp_loss = 0.021118, trig_loss = 8.585602, rela_loss = 0.061331, bind_loss = 0.000000 (2.022 sec/batch), lr: 0.000100
2021-07-12 09:50:20.599546: step 1040/164800 (epoch 1/80),jp_loss = 2.389084, trig_loss = 0.052460, rela_loss = 0.263320, bind_loss = 0.000000 (1.557 sec/batch), lr: 0.000100
2021-07-12 09:50:42.846878: step 1060/164800 (epoch 1/80),jp_loss = 2.948669, trig_loss = 1.381470, rela_loss = 1.832559, bind_loss = 0.000000 (0.817 sec/batch), lr: 0.000100
2021-07-12 09:51:11.124390: step 1080/164800 (epoch 1/80),jp_loss = 0.015137, trig_loss = 0.703247, rela_loss = 1.493433, bind_loss = 0.000000 (1.131 sec/batch), lr: 0.000100
2021-07-12 09:51:32.001506: step 1100/164800 (epoch 1/80),jp_loss = 3.544373, trig_loss = 2.150024, rela_loss = 0.227686, bind_loss = 0.007793 (1.475 sec/batch), lr: 0.000100
2021-07-12 09:52:06.702672: step 1120/164800 (epoch 1/80),jp_loss = 0.041046, trig_loss = 0.245567, rela_loss = 4.890573, bind_loss = 0.000000 (0.929 sec/batch), lr: 0.000100
2021-07-12 09:52:38.097911: step 1140/164800 (epoch 1/80),jp_loss = 0.013000, trig_loss = 0.855728, rela_loss = 0.373197, bind_loss = 0.000000 (0.493 sec/batch), lr: 0.000100
2021-07-12 09:53:04.047759: step 1160/164800 (epoch 1/80),jp_loss = 0.044189, trig_loss = 0.551865, rela_loss = 0.000239, bind_loss = 0.005303 (0.599 sec/batch), lr: 0.000100
2021-07-12 09:53:27.278887: step 1180/164800 (epoch 1/80),jp_loss = 0.191864, trig_loss = 1.205200, rela_loss = 0.545665, bind_loss = 0.007439 (1.228 sec/batch), lr: 0.000100
2021-07-12 09:53:49.522640: step 1200/164800 (epoch 1/80),jp_loss = 3.907410, trig_loss = 0.546387, rela_loss = 12.013811, bind_loss = 0.000000 (0.452 sec/batch), lr: 0.000100
2021-07-12 09:54:13.359868: step 1220/164800 (epoch 1/80),jp_loss = 1.377747, trig_loss = 0.353912, rela_loss = 2.626219, bind_loss = 2.397627 (2.309 sec/batch), lr: 0.000100
2021-07-12 09:54:46.384619: step 1240/164800 (epoch 1/80),jp_loss = 0.041183, trig_loss = 8.044937, rela_loss = 0.000008, bind_loss = 0.000000 (2.721 sec/batch), lr: 0.000100
2021-07-12 09:55:11.953495: step 1260/164800 (epoch 1/80),jp_loss = 0.053024, trig_loss = 3.404724, rela_loss = 0.543711, bind_loss = 0.000000 (1.161 sec/batch), lr: 0.000100
2021-07-12 09:55:42.696500: step 1280/164800 (epoch 1/80),jp_loss = 0.086639, trig_loss = 0.322418, rela_loss = 2.215396, bind_loss = 0.024661 (1.717 sec/batch), lr: 0.000100
2021-07-12 09:56:06.024790: step 1300/164800 (epoch 1/80),jp_loss = 0.065750, trig_loss = 13.721710, rela_loss = 1.182831, bind_loss = 0.000000 (0.940 sec/batch), lr: 0.000100
2021-07-12 09:56:41.723818: step 1320/164800 (epoch 1/80),jp_loss = 0.118454, trig_loss = 14.074493, rela_loss = 2.281641, bind_loss = 0.000000 (2.526 sec/batch), lr: 0.000100
2021-07-12 09:57:03.245472: step 1340/164800 (epoch 1/80),jp_loss = 7.748001, trig_loss = 7.918640, rela_loss = 0.527865, bind_loss = 0.000000 (1.106 sec/batch), lr: 0.000100
2021-07-12 09:57:30.580139: step 1360/164800 (epoch 1/80),jp_loss = 2.945694, trig_loss = 1.562515, rela_loss = 0.854749, bind_loss = 0.000000 (0.703 sec/batch), lr: 0.000100
2021-07-12 09:58:06.171510: step 1380/164800 (epoch 1/80),jp_loss = 12.655945, trig_loss = 9.010712, rela_loss = 0.000064, bind_loss = 0.005355 (1.386 sec/batch), lr: 0.000100
2021-07-12 09:58:38.500669: step 1400/164800 (epoch 1/80),jp_loss = 0.259911, trig_loss = 10.595139, rela_loss = 1.661270, bind_loss = 0.000000 (1.108 sec/batch), lr: 0.000100
2021-07-12 09:59:02.717438: step 1420/164800 (epoch 1/80),jp_loss = 0.082458, trig_loss = 8.397202, rela_loss = 0.050560, bind_loss = 0.000000 (1.051 sec/batch), lr: 0.000100
2021-07-12 09:59:23.866320: step 1440/164800 (epoch 1/80),jp_loss = 3.839905, trig_loss = 0.708374, rela_loss = 0.000481, bind_loss = 0.000000 (1.229 sec/batch), lr: 0.000100
2021-07-12 09:59:45.169712: step 1460/164800 (epoch 1/80),jp_loss = 6.461777, trig_loss = 1.169678, rela_loss = 1.412737, bind_loss = 0.025265 (1.557 sec/batch), lr: 0.000100
2021-07-12 10:00:10.632416: step 1480/164800 (epoch 1/80),jp_loss = 0.826416, trig_loss = 0.100494, rela_loss = 0.362991, bind_loss = 0.000000 (1.735 sec/batch), lr: 0.000100
2021-07-12 10:00:34.352571: step 1500/164800 (epoch 1/80),jp_loss = 0.108093, trig_loss = 2.793732, rela_loss = 1.221184, bind_loss = 0.000000 (0.625 sec/batch), lr: 0.000100
2021-07-12 10:01:04.518228: step 1520/164800 (epoch 1/80),jp_loss = 0.048916, trig_loss = 0.410610, rela_loss = 0.241563, bind_loss = 0.000000 (0.758 sec/batch), lr: 0.000100
2021-07-12 10:01:22.685354: step 1540/164800 (epoch 1/80),jp_loss = 0.027344, trig_loss = 14.664490, rela_loss = 1.573956, bind_loss = 0.000000 (1.519 sec/batch), lr: 0.000100
2021-07-12 10:02:02.478504: step 1560/164800 (epoch 1/80),jp_loss = 0.016785, trig_loss = 0.350891, rela_loss = 0.832485, bind_loss = 0.000000 (2.625 sec/batch), lr: 0.000100
2021-07-12 10:02:25.360349: step 1580/164800 (epoch 1/80),jp_loss = 0.013565, trig_loss = 2.572205, rela_loss = 0.041367, bind_loss = 0.000000 (1.108 sec/batch), lr: 0.000100
2021-07-12 10:02:50.259384: step 1600/164800 (epoch 1/80),jp_loss = 0.019821, trig_loss = 1.515747, rela_loss = 0.020236, bind_loss = 0.000000 (1.295 sec/batch), lr: 0.000100
2021-07-12 10:03:10.902119: step 1620/164800 (epoch 1/80),jp_loss = 0.110001, trig_loss = 0.089195, rela_loss = 2.860281, bind_loss = 0.000000 (0.406 sec/batch), lr: 0.000100
2021-07-12 10:03:45.336347: step 1640/164800 (epoch 1/80),jp_loss = 0.032471, trig_loss = 2.253815, rela_loss = 0.547514, bind_loss = 0.000000 (1.675 sec/batch), lr: 0.000100
2021-07-12 10:04:14.040056: step 1660/164800 (epoch 1/80),jp_loss = 0.073486, trig_loss = 0.104553, rela_loss = 1.095410, bind_loss = 0.000000 (1.051 sec/batch), lr: 0.000100
2021-07-12 10:04:32.453705: step 1680/164800 (epoch 1/80),jp_loss = 8.717941, trig_loss = 7.071014, rela_loss = 0.277165, bind_loss = 0.000000 (0.830 sec/batch), lr: 0.000100
2021-07-12 10:04:56.472024: step 1700/164800 (epoch 1/80),jp_loss = 0.022552, trig_loss = 0.195801, rela_loss = 0.006630, bind_loss = 0.000000 (1.681 sec/batch), lr: 0.000100
2021-07-12 10:05:18.159216: step 1720/164800 (epoch 1/80),jp_loss = 0.017838, trig_loss = 0.018311, rela_loss = 0.000257, bind_loss = 0.000000 (0.569 sec/batch), lr: 0.000100
2021-07-12 10:05:43.575671: step 1740/164800 (epoch 1/80),jp_loss = 0.039383, trig_loss = 4.866150, rela_loss = 0.455329, bind_loss = 0.000000 (2.267 sec/batch), lr: 0.000100
2021-07-12 10:06:07.520041: step 1760/164800 (epoch 1/80),jp_loss = 0.282059, trig_loss = 0.970306, rela_loss = 3.141609, bind_loss = 0.000000 (1.369 sec/batch), lr: 0.000100
2021-07-12 10:06:33.873999: step 1780/164800 (epoch 1/80),jp_loss = 4.330078, trig_loss = 0.379150, rela_loss = 0.597343, bind_loss = 0.000000 (1.430 sec/batch), lr: 0.000100
2021-07-12 10:07:07.838109: step 1800/164800 (epoch 1/80),jp_loss = 0.175781, trig_loss = 1.045593, rela_loss = 0.285504, bind_loss = 0.052288 (2.928 sec/batch), lr: 0.000100
2021-07-12 10:07:32.075792: step 1820/164800 (epoch 1/80),jp_loss = 0.193146, trig_loss = 4.855530, rela_loss = 1.175209, bind_loss = 0.000000 (0.792 sec/batch), lr: 0.000100
2021-07-12 10:07:58.156231: step 1840/164800 (epoch 1/80),jp_loss = 31.008087, trig_loss = 4.507141, rela_loss = 1.742128, bind_loss = 0.000000 (3.201 sec/batch), lr: 0.000100
2021-07-12 10:08:39.085983: step 1860/164800 (epoch 1/80),jp_loss = 0.036575, trig_loss = 1.883484, rela_loss = 0.006590, bind_loss = 0.000000 (1.553 sec/batch), lr: 0.000100
2021-07-12 10:09:02.648525: step 1880/164800 (epoch 1/80),jp_loss = 1.303253, trig_loss = 1.564072, rela_loss = 0.548834, bind_loss = 0.000000 (1.713 sec/batch), lr: 0.000100
2021-07-12 10:09:46.430260: step 1900/164800 (epoch 1/80),jp_loss = 0.024139, trig_loss = 0.359131, rela_loss = 2.222653, bind_loss = 0.000000 (0.671 sec/batch), lr: 0.000100
2021-07-12 10:10:10.468937: step 1920/164800 (epoch 1/80),jp_loss = 9.728119, trig_loss = 12.097778, rela_loss = 1.469571, bind_loss = 0.000000 (3.833 sec/batch), lr: 0.000100
2021-07-12 10:10:38.855143: step 1940/164800 (epoch 1/80),jp_loss = 0.096375, trig_loss = 0.113831, rela_loss = 0.000141, bind_loss = 0.000000 (0.690 sec/batch), lr: 0.000100
2021-07-12 10:11:05.176689: step 1960/164800 (epoch 1/80),jp_loss = 6.951523, trig_loss = 11.582825, rela_loss = 0.005085, bind_loss = 0.025969 (3.638 sec/batch), lr: 0.000100
2021-07-12 10:11:27.948620: step 1980/164800 (epoch 1/80),jp_loss = 3.666092, trig_loss = 0.105469, rela_loss = 0.043740, bind_loss = 0.000000 (0.839 sec/batch), lr: 0.000100
2021-07-12 10:11:55.395269: step 2000/164800 (epoch 1/80),jp_loss = 0.024780, trig_loss = 5.396255, rela_loss = 0.075425, bind_loss = 0.000000 (1.293 sec/batch), lr: 0.000100
2021-07-12 10:12:19.790026: step 2020/164800 (epoch 1/80),jp_loss = 0.008972, trig_loss = 0.054474, rela_loss = 0.000137, bind_loss = 0.000000 (0.979 sec/batch), lr: 0.000100
2021-07-12 10:12:47.781108: step 2040/164800 (epoch 1/80),jp_loss = 0.027107, trig_loss = 0.175629, rela_loss = 2.110087, bind_loss = 0.015531 (1.413 sec/batch), lr: 0.000100
2021-07-12 10:13:13.909398: step 2060/164800 (epoch 1/80),jp_loss = 0.013290, trig_loss = 2.780487, rela_loss = 0.000115, bind_loss = 0.000000 (1.286 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  89.27%  R:  92.64%  F1:  90.93%  #: 2174

Final Score:
Precision (micro): 89.273%
   Recall (micro): 92.640%
       F1 (micro): 90.926%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  88.67%  R:  92.26%  F1:  90.43%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  82.82%  R:  89.01%  F1:  85.81%  #: 455
Localization         P:  77.16%  R:  85.39%  F1:  81.07%  #: 178
Negative_regulation  P:  82.10%  R:  87.17%  F1:  84.56%  #: 421
Phosphorylation      P:  93.63%  R:  94.84%  F1:  94.23%  #: 155
Positive_regulation  P:  81.24%  R:  75.28%  F1:  78.15%  #: 627
Protein_catabolism   P: 100.00%  R:   0.00%  F1:   0.00%  #: 30
Regulation           P:  82.68%  R:  50.97%  F1:  63.06%  #: 206
Transcription        P:  11.11%  R:   1.49%  F1:   2.63%  #: 67

Final Score:
Precision (micro): 83.031%
   Recall (micro): 78.779%
       F1 (micro): 80.849%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  74.14%  R:  80.25%  F1:  77.08%  #: 486
Gene_expression      P:  81.61%  R:  86.74%  F1:  84.09%  #: 573
Localization         P:  73.71%  R:  81.77%  F1:  77.53%  #: 192
Negative_regulation  P:  61.41%  R:  54.82%  F1:  57.93%  #: 653
Phosphorylation      P:  83.74%  R:  86.29%  F1:  85.00%  #: 197
Positive_regulation  P:  63.19%  R:  48.80%  F1:  55.07%  #: 918
Protein_catabolism   P: 100.00%  R:   0.00%  F1:   0.00%  #: 30
Regulation           P:  56.17%  R:  32.73%  F1:  41.36%  #: 278
Transcription        P:  25.00%  R:   3.41%  F1:   6.00%  #: 88

Final Score:
Precision (micro): 70.070%
   Recall (micro): 61.903%
       F1 (micro): 65.734%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  31.65%  R:  74.34%  F1:  44.40%  #: 152

Final Score:
Precision (micro): 31.653%
   Recall (micro): 74.342%
       F1 (micro): 44.401%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  41.25%  R:  60.23%  F1:  48.96%  #: 352

Gene_expression      P:  81.61%  R:  86.74%  F1:  84.09%  #: 573

Localization         P:  73.71%  R:  81.77%  F1:  77.53%  #: 192

Negative_regulation  P:  38.72%  R:  42.17%  F1:  40.37%  #: 517

Phosphorylation      P:  81.58%  R:  81.15%  F1:  81.36%  #: 191

Positive_regulation  P:  44.36%  R:  36.20%  F1:  39.87%  #: 848

Protein_catabolism   P: 100.00%  R:   0.00%  F1:   0.00%  #: 30

Regulation           P:  38.79%  R:  24.52%  F1:  30.05%  #: 261

Transcription        P:  25.00%  R:   3.41%  F1:   6.00%  #: 88

Final Score:
Precision (micro): 54.530%
   Recall (micro): 52.851%
       F1 (micro): 53.677%
epoch 1: train_loss = 2.216413, dev_loss = 0.000000, dev_rela_f1 = 0.5368
0.5367720465890181 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_1.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.5367720465890181 ---- 1

2021-07-12 10:25:15.646031: step 2080/164800 (epoch 2/80),jp_loss = 0.022781, trig_loss = 4.642334, rela_loss = 0.000166, bind_loss = 0.000000 (1.807 sec/batch), lr: 0.000100
2021-07-12 10:25:46.004472: step 2100/164800 (epoch 2/80),jp_loss = 0.012909, trig_loss = 19.285797, rela_loss = 2.322763, bind_loss = 0.000000 (0.836 sec/batch), lr: 0.000100
2021-07-12 10:26:24.896368: step 2120/164800 (epoch 2/80),jp_loss = 0.319412, trig_loss = 0.027618, rela_loss = 1.563817, bind_loss = 0.000000 (0.656 sec/batch), lr: 0.000100
2021-07-12 10:26:49.560285: step 2140/164800 (epoch 2/80),jp_loss = 5.623672, trig_loss = 0.363388, rela_loss = 0.002210, bind_loss = 0.000000 (0.615 sec/batch), lr: 0.000100
2021-07-12 10:27:24.904948: step 2160/164800 (epoch 2/80),jp_loss = 0.010269, trig_loss = 7.489548, rela_loss = 1.188475, bind_loss = 0.000000 (0.800 sec/batch), lr: 0.000100
2021-07-12 10:27:53.512478: step 2180/164800 (epoch 2/80),jp_loss = 1.166626, trig_loss = 0.450958, rela_loss = 0.012095, bind_loss = 0.000000 (1.221 sec/batch), lr: 0.000100
2021-07-12 10:28:25.567494: step 2200/164800 (epoch 2/80),jp_loss = 0.018555, trig_loss = 0.066666, rela_loss = 0.000000, bind_loss = 0.003677 (0.551 sec/batch), lr: 0.000100
2021-07-12 10:28:48.543489: step 2220/164800 (epoch 2/80),jp_loss = 0.008865, trig_loss = 0.025284, rela_loss = 0.000057, bind_loss = 0.000000 (0.687 sec/batch), lr: 0.000100
2021-07-12 10:29:20.849034: step 2240/164800 (epoch 2/80),jp_loss = 0.079239, trig_loss = 4.552368, rela_loss = 3.972802, bind_loss = 0.000000 (1.117 sec/batch), lr: 0.000100
2021-07-12 10:29:43.058910: step 2260/164800 (epoch 2/80),jp_loss = 0.052673, trig_loss = 14.886581, rela_loss = 3.036079, bind_loss = 0.000000 (1.242 sec/batch), lr: 0.000100
2021-07-12 10:30:09.209141: step 2280/164800 (epoch 2/80),jp_loss = 0.011307, trig_loss = 4.853973, rela_loss = 0.912318, bind_loss = 0.000000 (0.682 sec/batch), lr: 0.000100
2021-07-12 10:30:44.169566: step 2300/164800 (epoch 2/80),jp_loss = 0.020218, trig_loss = 2.831161, rela_loss = 0.000020, bind_loss = 0.000000 (0.753 sec/batch), lr: 0.000100
2021-07-12 10:31:09.429875: step 2320/164800 (epoch 2/80),jp_loss = 0.005524, trig_loss = 0.019470, rela_loss = 0.000108, bind_loss = 0.000000 (1.264 sec/batch), lr: 0.000100
2021-07-12 10:31:41.231965: step 2340/164800 (epoch 2/80),jp_loss = 0.017891, trig_loss = 0.043724, rela_loss = 0.000000, bind_loss = 0.000000 (0.434 sec/batch), lr: 0.000100
2021-07-12 10:32:11.835629: step 2360/164800 (epoch 2/80),jp_loss = 0.008026, trig_loss = 0.028473, rela_loss = 0.000003, bind_loss = 0.000000 (0.558 sec/batch), lr: 0.000100
2021-07-12 10:32:38.886048: step 2380/164800 (epoch 2/80),jp_loss = 0.009888, trig_loss = 32.321091, rela_loss = 0.000364, bind_loss = 0.000000 (1.008 sec/batch), lr: 0.000100
2021-07-12 10:33:09.057231: step 2400/164800 (epoch 2/80),jp_loss = 0.012772, trig_loss = 0.022110, rela_loss = 0.000000, bind_loss = 0.000000 (0.523 sec/batch), lr: 0.000100
2021-07-12 10:33:40.120754: step 2420/164800 (epoch 2/80),jp_loss = 0.020859, trig_loss = 5.329086, rela_loss = 0.001190, bind_loss = 0.000000 (0.709 sec/batch), lr: 0.000100
2021-07-12 10:34:00.293212: step 2440/164800 (epoch 2/80),jp_loss = 4.153778, trig_loss = 3.195221, rela_loss = 1.205648, bind_loss = 0.021118 (1.628 sec/batch), lr: 0.000100
2021-07-12 10:34:19.966245: step 2460/164800 (epoch 2/80),jp_loss = 3.545212, trig_loss = 4.228119, rela_loss = 0.000006, bind_loss = 0.000000 (0.675 sec/batch), lr: 0.000100
2021-07-12 10:34:54.980549: step 2480/164800 (epoch 2/80),jp_loss = 1.070190, trig_loss = 12.427948, rela_loss = 5.934514, bind_loss = 0.000000 (2.132 sec/batch), lr: 0.000100
2021-07-12 10:35:20.201274: step 2500/164800 (epoch 2/80),jp_loss = 0.010193, trig_loss = 4.124878, rela_loss = 1.441746, bind_loss = 0.000000 (0.819 sec/batch), lr: 0.000100
2021-07-12 10:35:42.299037: step 2520/164800 (epoch 2/80),jp_loss = 0.074257, trig_loss = 0.042625, rela_loss = 2.248329, bind_loss = 0.002932 (1.118 sec/batch), lr: 0.000100
2021-07-12 10:36:27.094564: step 2540/164800 (epoch 2/80),jp_loss = 0.081482, trig_loss = 0.390869, rela_loss = 1.632342, bind_loss = 0.000000 (5.856 sec/batch), lr: 0.000100
2021-07-12 10:36:47.147344: step 2560/164800 (epoch 2/80),jp_loss = 0.005417, trig_loss = 0.048187, rela_loss = 0.000016, bind_loss = 0.000000 (0.593 sec/batch), lr: 0.000100
2021-07-12 10:37:12.277656: step 2580/164800 (epoch 2/80),jp_loss = 0.097900, trig_loss = 0.035233, rela_loss = 0.000593, bind_loss = 0.000000 (0.709 sec/batch), lr: 0.000100
2021-07-12 10:37:47.376058: step 2600/164800 (epoch 2/80),jp_loss = 1.510498, trig_loss = 0.069885, rela_loss = 0.000032, bind_loss = 0.000000 (0.824 sec/batch), lr: 0.000100
2021-07-12 10:38:22.888140: step 2620/164800 (epoch 2/80),jp_loss = 8.046204, trig_loss = 6.962921, rela_loss = 2.063948, bind_loss = 0.000000 (3.312 sec/batch), lr: 0.000100
2021-07-12 10:39:00.235755: step 2640/164800 (epoch 2/80),jp_loss = 0.022919, trig_loss = 17.657715, rela_loss = 1.319080, bind_loss = 0.000000 (1.571 sec/batch), lr: 0.000100
2021-07-12 10:39:23.361597: step 2660/164800 (epoch 2/80),jp_loss = 0.017929, trig_loss = 0.033798, rela_loss = 0.006783, bind_loss = 0.000000 (1.221 sec/batch), lr: 0.000100
2021-07-12 10:39:48.783327: step 2680/164800 (epoch 2/80),jp_loss = 10.023468, trig_loss = 2.637451, rela_loss = 0.416706, bind_loss = 0.015938 (1.847 sec/batch), lr: 0.000100
2021-07-12 10:40:21.087225: step 2700/164800 (epoch 2/80),jp_loss = 4.227524, trig_loss = 0.328430, rela_loss = 0.001343, bind_loss = 0.000000 (1.560 sec/batch), lr: 0.000100
2021-07-12 10:40:43.981511: step 2720/164800 (epoch 2/80),jp_loss = 0.014114, trig_loss = 0.011810, rela_loss = 0.000009, bind_loss = 0.000000 (0.591 sec/batch), lr: 0.000100
2021-07-12 10:41:07.605364: step 2740/164800 (epoch 2/80),jp_loss = 6.677353, trig_loss = 2.376678, rela_loss = 1.122669, bind_loss = 0.000000 (0.886 sec/batch), lr: 0.000100
2021-07-12 10:41:31.969013: step 2760/164800 (epoch 2/80),jp_loss = 0.005432, trig_loss = 15.314766, rela_loss = 0.000006, bind_loss = 0.000000 (1.099 sec/batch), lr: 0.000100
2021-07-12 10:41:58.750603: step 2780/164800 (epoch 2/80),jp_loss = 0.006920, trig_loss = 0.167313, rela_loss = 0.020150, bind_loss = 0.000000 (0.658 sec/batch), lr: 0.000100
2021-07-12 10:42:23.469080: step 2800/164800 (epoch 2/80),jp_loss = 0.009216, trig_loss = 0.316254, rela_loss = 0.000170, bind_loss = 0.000000 (1.196 sec/batch), lr: 0.000100
2021-07-12 10:42:54.796595: step 2820/164800 (epoch 2/80),jp_loss = 12.056686, trig_loss = 12.007431, rela_loss = 0.000180, bind_loss = 0.000000 (0.760 sec/batch), lr: 0.000100
2021-07-12 10:43:27.429644: step 2840/164800 (epoch 2/80),jp_loss = 0.004509, trig_loss = 0.019905, rela_loss = 0.000005, bind_loss = 0.000000 (0.364 sec/batch), lr: 0.000100
2021-07-12 10:44:09.294493: step 2860/164800 (epoch 2/80),jp_loss = 0.022018, trig_loss = 0.424362, rela_loss = 0.000573, bind_loss = 0.000000 (0.866 sec/batch), lr: 0.000100
2021-07-12 10:44:35.803182: step 2880/164800 (epoch 2/80),jp_loss = 0.006943, trig_loss = 1.785553, rela_loss = 0.000317, bind_loss = 0.000000 (1.291 sec/batch), lr: 0.000100
2021-07-12 10:45:09.387118: step 2900/164800 (epoch 2/80),jp_loss = 26.857559, trig_loss = 2.877289, rela_loss = 0.000036, bind_loss = 2.449702 (4.336 sec/batch), lr: 0.000100
2021-07-12 10:45:33.453277: step 2920/164800 (epoch 2/80),jp_loss = 0.219818, trig_loss = 0.023254, rela_loss = 0.001867, bind_loss = 0.000000 (0.922 sec/batch), lr: 0.000100
2021-07-12 10:46:00.086438: step 2940/164800 (epoch 2/80),jp_loss = 0.013947, trig_loss = 1.853577, rela_loss = 0.002663, bind_loss = 0.000000 (2.926 sec/batch), lr: 0.000100
2021-07-12 10:46:23.585545: step 2960/164800 (epoch 2/80),jp_loss = 0.079247, trig_loss = 8.671906, rela_loss = 0.000071, bind_loss = 0.000000 (0.501 sec/batch), lr: 0.000100
2021-07-12 10:46:53.790229: step 2980/164800 (epoch 2/80),jp_loss = 0.005341, trig_loss = 1.606354, rela_loss = 0.000110, bind_loss = 0.000000 (0.709 sec/batch), lr: 0.000100
2021-07-12 10:47:28.348992: step 3000/164800 (epoch 2/80),jp_loss = 0.012695, trig_loss = 0.059479, rela_loss = 0.331376, bind_loss = 0.000000 (0.828 sec/batch), lr: 0.000100
2021-07-12 10:47:56.444647: step 3020/164800 (epoch 2/80),jp_loss = 0.013489, trig_loss = 0.018433, rela_loss = 0.012902, bind_loss = 0.000000 (1.955 sec/batch), lr: 0.000100
2021-07-12 10:48:25.780454: step 3040/164800 (epoch 2/80),jp_loss = 0.001907, trig_loss = 6.055923, rela_loss = 0.000305, bind_loss = 0.000000 (0.545 sec/batch), lr: 0.000100
2021-07-12 10:49:01.498670: step 3060/164800 (epoch 2/80),jp_loss = 25.932343, trig_loss = 0.909546, rela_loss = 0.000069, bind_loss = 0.000000 (0.907 sec/batch), lr: 0.000100
2021-07-12 10:49:30.488373: step 3080/164800 (epoch 2/80),jp_loss = 0.009399, trig_loss = 7.075165, rela_loss = 0.025702, bind_loss = 0.000000 (1.980 sec/batch), lr: 0.000100
2021-07-12 10:49:58.148849: step 3100/164800 (epoch 2/80),jp_loss = 1.941620, trig_loss = 0.450714, rela_loss = 0.782720, bind_loss = 0.000000 (1.075 sec/batch), lr: 0.000100
2021-07-12 10:50:20.333303: step 3120/164800 (epoch 2/80),jp_loss = 0.019714, trig_loss = 0.084503, rela_loss = 0.174216, bind_loss = 0.000000 (0.724 sec/batch), lr: 0.000100
2021-07-12 10:50:49.048124: step 3140/164800 (epoch 2/80),jp_loss = 0.006714, trig_loss = 0.017975, rela_loss = 0.019184, bind_loss = 0.000000 (1.067 sec/batch), lr: 0.000100
2021-07-12 10:51:10.381039: step 3160/164800 (epoch 2/80),jp_loss = 0.016388, trig_loss = 3.978912, rela_loss = 0.000231, bind_loss = 0.008365 (1.755 sec/batch), lr: 0.000100
2021-07-12 10:51:45.631395: step 3180/164800 (epoch 2/80),jp_loss = 0.008148, trig_loss = 0.012390, rela_loss = 0.000076, bind_loss = 0.000000 (0.952 sec/batch), lr: 0.000100
2021-07-12 10:52:17.735613: step 3200/164800 (epoch 2/80),jp_loss = 0.001968, trig_loss = 0.074631, rela_loss = 0.000000, bind_loss = 0.000000 (0.518 sec/batch), lr: 0.000100
2021-07-12 10:52:44.059944: step 3220/164800 (epoch 2/80),jp_loss = 0.003021, trig_loss = 0.017502, rela_loss = 0.028248, bind_loss = 0.068928 (0.599 sec/batch), lr: 0.000100
2021-07-12 10:53:08.158082: step 3240/164800 (epoch 2/80),jp_loss = 0.019196, trig_loss = 0.618713, rela_loss = 0.931500, bind_loss = 0.011455 (1.189 sec/batch), lr: 0.000100
2021-07-12 10:53:31.007679: step 3260/164800 (epoch 2/80),jp_loss = 0.011581, trig_loss = 0.011398, rela_loss = 0.000004, bind_loss = 0.000000 (0.436 sec/batch), lr: 0.000100
2021-07-12 10:53:55.150938: step 3280/164800 (epoch 2/80),jp_loss = 0.017548, trig_loss = 0.023743, rela_loss = 0.001395, bind_loss = 2.232614 (2.213 sec/batch), lr: 0.000100
2021-07-12 10:54:28.534371: step 3300/164800 (epoch 2/80),jp_loss = 0.019203, trig_loss = 11.351425, rela_loss = 0.000000, bind_loss = 0.000000 (2.759 sec/batch), lr: 0.000100
2021-07-12 10:54:54.497195: step 3320/164800 (epoch 2/80),jp_loss = 0.030792, trig_loss = 1.823990, rela_loss = 0.000709, bind_loss = 0.000000 (1.213 sec/batch), lr: 0.000100
2021-07-12 10:55:25.866228: step 3340/164800 (epoch 2/80),jp_loss = 0.016052, trig_loss = 0.239136, rela_loss = 0.000000, bind_loss = 0.019188 (1.604 sec/batch), lr: 0.000100
2021-07-12 10:55:49.759540: step 3360/164800 (epoch 2/80),jp_loss = 0.023941, trig_loss = 5.685181, rela_loss = 0.001532, bind_loss = 0.000000 (1.163 sec/batch), lr: 0.000100
2021-07-12 10:56:28.033673: step 3380/164800 (epoch 2/80),jp_loss = 0.016022, trig_loss = 7.215012, rela_loss = 3.277672, bind_loss = 0.000000 (2.784 sec/batch), lr: 0.000100
2021-07-12 10:56:49.925078: step 3400/164800 (epoch 2/80),jp_loss = 5.948334, trig_loss = 9.589691, rela_loss = 0.003811, bind_loss = 0.000000 (0.991 sec/batch), lr: 0.000100
2021-07-12 10:57:18.462141: step 3420/164800 (epoch 2/80),jp_loss = 0.265289, trig_loss = 0.095001, rela_loss = 0.007605, bind_loss = 0.000000 (0.707 sec/batch), lr: 0.000100
2021-07-12 10:57:55.866894: step 3440/164800 (epoch 2/80),jp_loss = 0.229507, trig_loss = 5.003967, rela_loss = 0.000003, bind_loss = 0.010016 (1.565 sec/batch), lr: 0.000100
2021-07-12 10:58:29.249477: step 3460/164800 (epoch 2/80),jp_loss = 0.015244, trig_loss = 11.296555, rela_loss = 0.055799, bind_loss = 0.000000 (1.154 sec/batch), lr: 0.000100
2021-07-12 10:58:53.609945: step 3480/164800 (epoch 2/80),jp_loss = 0.010620, trig_loss = 4.825836, rela_loss = 0.000055, bind_loss = 0.000000 (1.033 sec/batch), lr: 0.000100
2021-07-12 10:59:16.528949: step 3500/164800 (epoch 2/80),jp_loss = 0.008667, trig_loss = 0.283905, rela_loss = 0.000004, bind_loss = 0.000000 (1.305 sec/batch), lr: 0.000100
2021-07-12 10:59:38.726697: step 3520/164800 (epoch 2/80),jp_loss = 0.088806, trig_loss = 0.381821, rela_loss = 0.020621, bind_loss = 0.005657 (1.703 sec/batch), lr: 0.000100
2021-07-12 11:00:06.232694: step 3540/164800 (epoch 2/80),jp_loss = 0.009033, trig_loss = 0.019073, rela_loss = 0.530170, bind_loss = 0.000000 (2.044 sec/batch), lr: 0.000100
2021-07-12 11:00:31.279948: step 3560/164800 (epoch 2/80),jp_loss = 0.013977, trig_loss = 1.543091, rela_loss = 0.000130, bind_loss = 0.000000 (0.741 sec/batch), lr: 0.000100
2021-07-12 11:01:04.793777: step 3580/164800 (epoch 2/80),jp_loss = 0.052898, trig_loss = 0.022171, rela_loss = 0.000517, bind_loss = 0.000000 (0.986 sec/batch), lr: 0.000100
2021-07-12 11:01:24.045958: step 3600/164800 (epoch 2/80),jp_loss = 0.009705, trig_loss = 3.945465, rela_loss = 2.596425, bind_loss = 0.000000 (1.569 sec/batch), lr: 0.000100
2021-07-12 11:02:04.135551: step 3620/164800 (epoch 2/80),jp_loss = 0.007202, trig_loss = 0.118652, rela_loss = 1.923856, bind_loss = 0.000000 (2.631 sec/batch), lr: 0.000100
2021-07-12 11:02:26.769571: step 3640/164800 (epoch 2/80),jp_loss = 0.005112, trig_loss = 0.157684, rela_loss = 1.454601, bind_loss = 0.000000 (1.016 sec/batch), lr: 0.000100
2021-07-12 11:02:52.104457: step 3660/164800 (epoch 2/80),jp_loss = 0.008575, trig_loss = 0.029877, rela_loss = 0.000039, bind_loss = 0.000000 (1.339 sec/batch), lr: 0.000100
2021-07-12 11:03:13.539627: step 3680/164800 (epoch 2/80),jp_loss = 0.003403, trig_loss = 0.005478, rela_loss = 0.000000, bind_loss = 0.000000 (0.422 sec/batch), lr: 0.000100
2021-07-12 11:03:47.557036: step 3700/164800 (epoch 2/80),jp_loss = 0.007965, trig_loss = 0.515259, rela_loss = 0.003475, bind_loss = 0.000000 (1.655 sec/batch), lr: 0.000100
2021-07-12 11:04:15.541026: step 3720/164800 (epoch 2/80),jp_loss = 0.012421, trig_loss = 0.010834, rela_loss = 0.000022, bind_loss = 0.000000 (0.946 sec/batch), lr: 0.000100
2021-07-12 11:04:32.556778: step 3740/164800 (epoch 2/80),jp_loss = 0.010284, trig_loss = 0.115189, rela_loss = 0.000180, bind_loss = 0.000000 (0.631 sec/batch), lr: 0.000100
2021-07-12 11:04:55.719835: step 3760/164800 (epoch 2/80),jp_loss = 0.022888, trig_loss = 0.018219, rela_loss = 0.000000, bind_loss = 0.000000 (1.595 sec/batch), lr: 0.000100
2021-07-12 11:05:16.360099: step 3780/164800 (epoch 2/80),jp_loss = 0.003387, trig_loss = 0.009338, rela_loss = 0.000000, bind_loss = 0.000000 (0.527 sec/batch), lr: 0.000100
2021-07-12 11:05:39.986361: step 3800/164800 (epoch 2/80),jp_loss = 0.034195, trig_loss = 2.649551, rela_loss = 0.283535, bind_loss = 0.000000 (1.994 sec/batch), lr: 0.000100
2021-07-12 11:06:03.507583: step 3820/164800 (epoch 2/80),jp_loss = 1.076904, trig_loss = 0.083008, rela_loss = 3.107857, bind_loss = 0.000000 (1.310 sec/batch), lr: 0.000100
2021-07-12 11:06:29.521336: step 3840/164800 (epoch 2/80),jp_loss = 5.434875, trig_loss = 0.022400, rela_loss = 0.177892, bind_loss = 0.000000 (1.390 sec/batch), lr: 0.000100
2021-07-12 11:07:04.165766: step 3860/164800 (epoch 2/80),jp_loss = 0.020401, trig_loss = 0.345520, rela_loss = 0.033314, bind_loss = 0.019383 (3.140 sec/batch), lr: 0.000100
2021-07-12 11:07:27.389779: step 3880/164800 (epoch 2/80),jp_loss = 1.936188, trig_loss = 5.407379, rela_loss = 0.000722, bind_loss = 0.000000 (0.900 sec/batch), lr: 0.000100
2021-07-12 11:07:52.865913: step 3900/164800 (epoch 2/80),jp_loss = 8.664276, trig_loss = 0.134399, rela_loss = 0.522818, bind_loss = 0.000000 (2.954 sec/batch), lr: 0.000100
2021-07-12 11:08:31.653791: step 3920/164800 (epoch 2/80),jp_loss = 0.017242, trig_loss = 0.130798, rela_loss = 0.005249, bind_loss = 0.000000 (1.547 sec/batch), lr: 0.000100
2021-07-12 11:08:54.714475: step 3940/164800 (epoch 2/80),jp_loss = 0.012543, trig_loss = 1.128128, rela_loss = 0.692344, bind_loss = 0.000000 (1.824 sec/batch), lr: 0.000100
2021-07-12 11:09:36.388618: step 3960/164800 (epoch 2/80),jp_loss = 0.011475, trig_loss = 0.021515, rela_loss = 0.000000, bind_loss = 0.000000 (0.655 sec/batch), lr: 0.000100
2021-07-12 11:09:58.923194: step 3980/164800 (epoch 2/80),jp_loss = 0.037109, trig_loss = 5.585144, rela_loss = 0.876178, bind_loss = 0.000000 (3.702 sec/batch), lr: 0.000100
2021-07-12 11:10:26.581724: step 4000/164800 (epoch 2/80),jp_loss = 0.003342, trig_loss = 0.005280, rela_loss = 0.000353, bind_loss = 0.000000 (0.665 sec/batch), lr: 0.000100
2021-07-12 11:10:52.054096: step 4020/164800 (epoch 2/80),jp_loss = 0.032501, trig_loss = 12.486603, rela_loss = 0.001165, bind_loss = 0.005483 (3.229 sec/batch), lr: 0.000100
2021-07-12 11:11:13.987298: step 4040/164800 (epoch 2/80),jp_loss = 3.085373, trig_loss = 0.014862, rela_loss = 0.008608, bind_loss = 0.000000 (0.816 sec/batch), lr: 0.000100
2021-07-12 11:11:39.154558: step 4060/164800 (epoch 2/80),jp_loss = 0.011337, trig_loss = 0.984543, rela_loss = 0.000791, bind_loss = 0.000000 (1.283 sec/batch), lr: 0.000100
2021-07-12 11:12:01.596691: step 4080/164800 (epoch 2/80),jp_loss = 0.003357, trig_loss = 0.005676, rela_loss = 0.000008, bind_loss = 0.000000 (0.937 sec/batch), lr: 0.000100
2021-07-12 11:12:28.806368: step 4100/164800 (epoch 2/80),jp_loss = 0.024933, trig_loss = 0.011551, rela_loss = 0.763490, bind_loss = 0.047972 (1.362 sec/batch), lr: 0.000100
2021-07-12 11:12:53.951539: step 4120/164800 (epoch 2/80),jp_loss = 0.006073, trig_loss = 4.598297, rela_loss = 0.013818, bind_loss = 0.000000 (1.050 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  93.04%  R:  96.60%  F1:  94.79%  #: 2174

Final Score:
Precision (micro): 93.044%
   Recall (micro): 96.596%
       F1 (micro): 94.787%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  90.20%  R:  92.93%  F1:  91.54%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  86.96%  R:  92.31%  F1:  89.55%  #: 455
Localization         P:  92.78%  R:  93.82%  F1:  93.30%  #: 178
Negative_regulation  P:  83.26%  R:  90.97%  F1:  86.95%  #: 421
Phosphorylation      P:  94.38%  R:  97.42%  F1:  95.87%  #: 155
Positive_regulation  P:  85.50%  R:  81.82%  F1:  83.62%  #: 627
Protein_catabolism   P:  94.44%  R:  56.67%  F1:  70.83%  #: 30
Regulation           P:  89.12%  R:  63.59%  F1:  74.22%  #: 206
Transcription        P:  45.45%  R:  59.70%  F1:  51.61%  #: 67

Final Score:
Precision (micro): 85.913%
   Recall (micro): 85.948%
       F1 (micro): 85.931%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  81.84%  R:  80.33%  F1:  81.08%  #: 488
Gene_expression      P:  86.40%  R:  89.67%  F1:  88.01%  #: 581
Localization         P:  89.30%  R:  86.98%  F1:  88.13%  #: 192
Negative_regulation  P:  64.92%  R:  79.39%  F1:  71.43%  #: 655
Phosphorylation      P:  88.78%  R:  92.39%  F1:  90.55%  #: 197
Positive_regulation  P:  66.56%  R:  70.53%  F1:  68.49%  #: 923
Protein_catabolism   P:  94.12%  R:  53.33%  F1:  68.09%  #: 30
Regulation           P:  69.43%  R:  55.59%  F1:  61.75%  #: 286
Transcription        P:  46.94%  R:  51.69%  F1:  49.20%  #: 89

Final Score:
Precision (micro): 73.784%
   Recall (micro): 77.129%
       F1 (micro): 75.419%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  45.14%  R:  76.82%  F1:  56.86%  #: 151

Final Score:
Precision (micro): 45.136%
   Recall (micro): 76.821%
       F1 (micro): 56.863%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  53.68%  R:  64.02%  F1:  58.40%  #: 353

Gene_expression      P:  86.83%  R:  89.67%  F1:  88.23%  #: 581

Localization         P:  90.27%  R:  86.98%  F1:  88.59%  #: 192

Negative_regulation  P:  56.90%  R:  58.77%  F1:  57.82%  #: 519

Phosphorylation      P:  85.19%  R:  84.29%  F1:  84.74%  #: 191

Positive_regulation  P:  59.84%  R:  52.46%  F1:  55.91%  #: 852

Protein_catabolism   P:  94.12%  R:  53.33%  F1:  68.09%  #: 30

Regulation           P:  64.67%  R:  40.15%  F1:  49.54%  #: 269

Transcription        P:  47.42%  R:  51.69%  F1:  49.46%  #: 89

Final Score:
Precision (micro): 67.489%
   Recall (micro): 64.922%
       F1 (micro): 66.181%
epoch 2: train_loss = 0.682981, dev_loss = 0.000000, dev_rela_f1 = 0.6618
0.6618061309030655 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_2.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.6618061309030655 ---- 2

2021-07-12 11:26:26.764209: step 4140/164800 (epoch 3/80),jp_loss = 0.010529, trig_loss = 5.112823, rela_loss = 0.000080, bind_loss = 0.000000 (1.869 sec/batch), lr: 0.000100
2021-07-12 11:26:57.487086: step 4160/164800 (epoch 3/80),jp_loss = 0.003876, trig_loss = 21.323700, rela_loss = 3.071859, bind_loss = 0.000000 (0.868 sec/batch), lr: 0.000100
2021-07-12 11:27:35.338527: step 4180/164800 (epoch 3/80),jp_loss = 0.013779, trig_loss = 0.006409, rela_loss = 2.041817, bind_loss = 0.000000 (0.720 sec/batch), lr: 0.000100
2021-07-12 11:27:59.074560: step 4200/164800 (epoch 3/80),jp_loss = 0.019302, trig_loss = 0.274628, rela_loss = 0.000000, bind_loss = 0.000000 (0.595 sec/batch), lr: 0.000100
2021-07-12 11:28:36.180844: step 4220/164800 (epoch 3/80),jp_loss = 0.005432, trig_loss = 1.678619, rela_loss = 1.557240, bind_loss = 0.000000 (0.708 sec/batch), lr: 0.000100
2021-07-12 11:29:04.585189: step 4240/164800 (epoch 3/80),jp_loss = 0.005249, trig_loss = 0.211670, rela_loss = 0.000494, bind_loss = 0.000000 (1.349 sec/batch), lr: 0.000100
2021-07-12 11:29:36.888019: step 4260/164800 (epoch 3/80),jp_loss = 0.005112, trig_loss = 0.004539, rela_loss = 0.000008, bind_loss = 0.034964 (0.621 sec/batch), lr: 0.000100
2021-07-12 11:29:59.845361: step 4280/164800 (epoch 3/80),jp_loss = 0.006485, trig_loss = 0.005569, rela_loss = 0.000527, bind_loss = 0.000000 (0.708 sec/batch), lr: 0.000100
2021-07-12 11:30:33.672151: step 4300/164800 (epoch 3/80),jp_loss = 0.174286, trig_loss = 5.156433, rela_loss = 0.018424, bind_loss = 0.000000 (1.210 sec/batch), lr: 0.000100
2021-07-12 11:30:56.733960: step 4320/164800 (epoch 3/80),jp_loss = 7.025986, trig_loss = 6.406082, rela_loss = 2.051396, bind_loss = 0.000000 (1.303 sec/batch), lr: 0.000100
2021-07-12 11:31:23.754204: step 4340/164800 (epoch 3/80),jp_loss = 0.002563, trig_loss = 7.656708, rela_loss = 0.000301, bind_loss = 0.000000 (0.588 sec/batch), lr: 0.000100
2021-07-12 11:32:00.112526: step 4360/164800 (epoch 3/80),jp_loss = 0.248520, trig_loss = 2.158691, rela_loss = 0.064715, bind_loss = 0.000000 (0.670 sec/batch), lr: 0.000100
2021-07-12 11:32:25.938548: step 4380/164800 (epoch 3/80),jp_loss = 0.001831, trig_loss = 0.008362, rela_loss = 0.000029, bind_loss = 0.000000 (1.369 sec/batch), lr: 0.000100
2021-07-12 11:32:59.444821: step 4400/164800 (epoch 3/80),jp_loss = 0.004379, trig_loss = 0.007927, rela_loss = 0.000008, bind_loss = 0.000000 (0.383 sec/batch), lr: 0.000100
2021-07-12 11:33:32.209393: step 4420/164800 (epoch 3/80),jp_loss = 0.001907, trig_loss = 0.028259, rela_loss = 0.000001, bind_loss = 0.000000 (0.599 sec/batch), lr: 0.000100
2021-07-12 11:34:00.249600: step 4440/164800 (epoch 3/80),jp_loss = 0.006897, trig_loss = 25.330780, rela_loss = 0.000243, bind_loss = 0.000000 (0.972 sec/batch), lr: 0.000100
2021-07-12 11:34:30.603205: step 4460/164800 (epoch 3/80),jp_loss = 0.009125, trig_loss = 0.020462, rela_loss = 0.000007, bind_loss = 0.000000 (0.588 sec/batch), lr: 0.000100
2021-07-12 11:35:02.206801: step 4480/164800 (epoch 3/80),jp_loss = 0.008743, trig_loss = 0.699524, rela_loss = 0.000005, bind_loss = 0.000000 (0.685 sec/batch), lr: 0.000100
2021-07-12 11:35:21.990707: step 4500/164800 (epoch 3/80),jp_loss = 4.516113, trig_loss = 16.099030, rela_loss = 2.706640, bind_loss = 0.061709 (1.781 sec/batch), lr: 0.000100
2021-07-12 11:35:43.208348: step 4520/164800 (epoch 3/80),jp_loss = 4.588196, trig_loss = 4.777924, rela_loss = 0.001025, bind_loss = 0.000000 (0.709 sec/batch), lr: 0.000100
2021-07-12 11:36:21.354143: step 4540/164800 (epoch 3/80),jp_loss = 2.370575, trig_loss = 7.766846, rela_loss = 5.980131, bind_loss = 0.000000 (2.351 sec/batch), lr: 0.000100
2021-07-12 11:36:46.700407: step 4560/164800 (epoch 3/80),jp_loss = 0.017456, trig_loss = 0.661346, rela_loss = 0.000562, bind_loss = 0.000000 (0.904 sec/batch), lr: 0.000100
2021-07-12 11:37:07.794646: step 4580/164800 (epoch 3/80),jp_loss = 0.013161, trig_loss = 0.032043, rela_loss = 0.156683, bind_loss = 0.003640 (0.951 sec/batch), lr: 0.000100
2021-07-12 11:37:51.565287: step 4600/164800 (epoch 3/80),jp_loss = 5.699402, trig_loss = 0.293457, rela_loss = 0.008411, bind_loss = 0.000000 (5.964 sec/batch), lr: 0.000100
2021-07-12 11:38:10.578750: step 4620/164800 (epoch 3/80),jp_loss = 0.003281, trig_loss = 0.141815, rela_loss = 0.000004, bind_loss = 0.000000 (0.584 sec/batch), lr: 0.000100
2021-07-12 11:38:35.375940: step 4640/164800 (epoch 3/80),jp_loss = 0.010803, trig_loss = 0.009735, rela_loss = 0.000115, bind_loss = 0.000000 (0.658 sec/batch), lr: 0.000100
2021-07-12 11:39:09.074067: step 4660/164800 (epoch 3/80),jp_loss = 0.004272, trig_loss = 0.011536, rela_loss = 0.003818, bind_loss = 0.000000 (0.771 sec/batch), lr: 0.000100
2021-07-12 11:39:42.801938: step 4680/164800 (epoch 3/80),jp_loss = 10.309067, trig_loss = 16.408356, rela_loss = 0.044400, bind_loss = 0.000000 (3.265 sec/batch), lr: 0.000100
2021-07-12 11:40:17.648900: step 4700/164800 (epoch 3/80),jp_loss = 0.006653, trig_loss = 18.687042, rela_loss = 0.000966, bind_loss = 0.000000 (1.442 sec/batch), lr: 0.000100
2021-07-12 11:40:39.547664: step 4720/164800 (epoch 3/80),jp_loss = 0.012512, trig_loss = 0.016846, rela_loss = 0.000660, bind_loss = 0.000000 (1.142 sec/batch), lr: 0.000100
2021-07-12 11:41:02.350077: step 4740/164800 (epoch 3/80),jp_loss = 20.781906, trig_loss = 2.383331, rela_loss = 0.639996, bind_loss = 0.007807 (1.709 sec/batch), lr: 0.000100
2021-07-12 11:41:32.842059: step 4760/164800 (epoch 3/80),jp_loss = 0.006546, trig_loss = 0.087158, rela_loss = 0.008574, bind_loss = 0.000000 (1.477 sec/batch), lr: 0.000100
2021-07-12 11:41:55.182636: step 4780/164800 (epoch 3/80),jp_loss = 0.006516, trig_loss = 0.048706, rela_loss = 0.000011, bind_loss = 0.000000 (0.678 sec/batch), lr: 0.000100
2021-07-12 11:42:18.035583: step 4800/164800 (epoch 3/80),jp_loss = 0.141006, trig_loss = 0.220612, rela_loss = 0.002039, bind_loss = 0.000000 (0.977 sec/batch), lr: 0.000100
2021-07-12 11:42:42.435701: step 4820/164800 (epoch 3/80),jp_loss = 0.002258, trig_loss = 8.473969, rela_loss = 0.000001, bind_loss = 0.000000 (1.031 sec/batch), lr: 0.000100
2021-07-12 11:43:07.133905: step 4840/164800 (epoch 3/80),jp_loss = 0.003098, trig_loss = 0.198441, rela_loss = 0.002410, bind_loss = 0.000000 (0.520 sec/batch), lr: 0.000100
2021-07-12 11:43:31.160123: step 4860/164800 (epoch 3/80),jp_loss = 0.008453, trig_loss = 0.080536, rela_loss = 0.000038, bind_loss = 0.000000 (1.169 sec/batch), lr: 0.000100
2021-07-12 11:44:00.821395: step 4880/164800 (epoch 3/80),jp_loss = 1.054565, trig_loss = 4.266815, rela_loss = 0.002115, bind_loss = 0.000000 (0.683 sec/batch), lr: 0.000100
2021-07-12 11:44:31.529587: step 4900/164800 (epoch 3/80),jp_loss = 0.001144, trig_loss = 0.006760, rela_loss = 0.000823, bind_loss = 0.000000 (0.356 sec/batch), lr: 0.000100
2021-07-12 11:45:13.385679: step 4920/164800 (epoch 3/80),jp_loss = 0.002777, trig_loss = 0.391998, rela_loss = 0.000006, bind_loss = 0.000000 (0.795 sec/batch), lr: 0.000100
2021-07-12 11:45:38.897696: step 4940/164800 (epoch 3/80),jp_loss = 0.004517, trig_loss = 1.114990, rela_loss = 0.000548, bind_loss = 0.000000 (1.092 sec/batch), lr: 0.000100
2021-07-12 11:46:09.825878: step 4960/164800 (epoch 3/80),jp_loss = 5.823929, trig_loss = 0.062195, rela_loss = 0.001186, bind_loss = 1.834310 (4.029 sec/batch), lr: 0.000100
2021-07-12 11:46:32.901043: step 4980/164800 (epoch 3/80),jp_loss = 0.005066, trig_loss = 0.008179, rela_loss = 0.000563, bind_loss = 0.000000 (1.029 sec/batch), lr: 0.000100
2021-07-12 11:46:58.817830: step 5000/164800 (epoch 3/80),jp_loss = 0.025909, trig_loss = 1.358612, rela_loss = 0.656047, bind_loss = 0.000000 (2.786 sec/batch), lr: 0.000100
2021-07-12 11:47:22.229986: step 5020/164800 (epoch 3/80),jp_loss = 0.009651, trig_loss = 0.043457, rela_loss = 0.000898, bind_loss = 0.000000 (0.514 sec/batch), lr: 0.000100
2021-07-12 11:47:52.268752: step 5040/164800 (epoch 3/80),jp_loss = 0.060577, trig_loss = 0.030945, rela_loss = 0.000285, bind_loss = 0.000000 (0.664 sec/batch), lr: 0.000100
2021-07-12 11:48:26.118035: step 5060/164800 (epoch 3/80),jp_loss = 0.029297, trig_loss = 4.221588, rela_loss = 0.000299, bind_loss = 0.000000 (0.667 sec/batch), lr: 0.000100
2021-07-12 11:48:54.365515: step 5080/164800 (epoch 3/80),jp_loss = 0.005997, trig_loss = 0.005890, rela_loss = 0.001073, bind_loss = 0.000000 (2.150 sec/batch), lr: 0.000100
2021-07-12 11:49:23.540860: step 5100/164800 (epoch 3/80),jp_loss = 0.008316, trig_loss = 8.750641, rela_loss = 0.000002, bind_loss = 0.000000 (0.541 sec/batch), lr: 0.000100
2021-07-12 11:49:59.956784: step 5120/164800 (epoch 3/80),jp_loss = 20.412964, trig_loss = 0.103973, rela_loss = 0.003282, bind_loss = 0.000000 (0.898 sec/batch), lr: 0.000100
2021-07-12 11:50:29.442818: step 5140/164800 (epoch 3/80),jp_loss = 0.002686, trig_loss = 2.189209, rela_loss = 0.000010, bind_loss = 0.000000 (1.971 sec/batch), lr: 0.000100
2021-07-12 11:50:55.978649: step 5160/164800 (epoch 3/80),jp_loss = 0.060852, trig_loss = 0.005005, rela_loss = 0.000012, bind_loss = 0.000000 (1.067 sec/batch), lr: 0.000100
2021-07-12 11:51:18.080328: step 5180/164800 (epoch 3/80),jp_loss = 0.009674, trig_loss = 0.025848, rela_loss = 0.000936, bind_loss = 0.000000 (0.767 sec/batch), lr: 0.000100
2021-07-12 11:51:45.836592: step 5200/164800 (epoch 3/80),jp_loss = 0.000488, trig_loss = 0.017853, rela_loss = 0.002801, bind_loss = 0.000000 (0.995 sec/batch), lr: 0.000100
2021-07-12 11:52:04.833086: step 5220/164800 (epoch 3/80),jp_loss = 3.579163, trig_loss = 6.173279, rela_loss = 0.103877, bind_loss = 0.006133 (1.356 sec/batch), lr: 0.000100
2021-07-12 11:52:39.643463: step 5240/164800 (epoch 3/80),jp_loss = 0.002281, trig_loss = 0.007751, rela_loss = 0.002824, bind_loss = 0.000000 (1.320 sec/batch), lr: 0.000100
2021-07-12 11:53:10.430301: step 5260/164800 (epoch 3/80),jp_loss = 0.001572, trig_loss = 0.225433, rela_loss = 0.000001, bind_loss = 0.000000 (0.520 sec/batch), lr: 0.000100
2021-07-12 11:53:37.718415: step 5280/164800 (epoch 3/80),jp_loss = 0.001526, trig_loss = 0.005936, rela_loss = 0.000001, bind_loss = 0.051048 (0.591 sec/batch), lr: 0.000100
2021-07-12 11:54:01.626804: step 5300/164800 (epoch 3/80),jp_loss = 0.003601, trig_loss = 0.009979, rela_loss = 0.052368, bind_loss = 0.008864 (1.218 sec/batch), lr: 0.000100
2021-07-12 11:54:24.216728: step 5320/164800 (epoch 3/80),jp_loss = 0.000870, trig_loss = 0.004074, rela_loss = 0.000000, bind_loss = 0.000000 (0.505 sec/batch), lr: 0.000100
2021-07-12 11:54:49.098740: step 5340/164800 (epoch 3/80),jp_loss = 0.005737, trig_loss = 0.003784, rela_loss = 0.001358, bind_loss = 1.235611 (2.457 sec/batch), lr: 0.000100
2021-07-12 11:55:21.984098: step 5360/164800 (epoch 3/80),jp_loss = 0.005043, trig_loss = 7.680984, rela_loss = 0.000056, bind_loss = 0.000000 (2.538 sec/batch), lr: 0.000100
2021-07-12 11:55:47.517652: step 5380/164800 (epoch 3/80),jp_loss = 0.002701, trig_loss = 0.719391, rela_loss = 0.000172, bind_loss = 0.000000 (1.160 sec/batch), lr: 0.000100
2021-07-12 11:56:18.391981: step 5400/164800 (epoch 3/80),jp_loss = 0.003906, trig_loss = 0.061066, rela_loss = 0.000119, bind_loss = 0.024835 (1.716 sec/batch), lr: 0.000100
2021-07-12 11:56:43.306030: step 5420/164800 (epoch 3/80),jp_loss = 0.008606, trig_loss = 6.490845, rela_loss = 0.000001, bind_loss = 0.000000 (1.089 sec/batch), lr: 0.000100
2021-07-12 11:57:19.983384: step 5440/164800 (epoch 3/80),jp_loss = 0.006088, trig_loss = 17.035812, rela_loss = 1.115847, bind_loss = 0.000000 (2.692 sec/batch), lr: 0.000100
2021-07-12 11:57:41.745069: step 5460/164800 (epoch 3/80),jp_loss = 5.062607, trig_loss = 0.516846, rela_loss = 0.000051, bind_loss = 0.000000 (0.942 sec/batch), lr: 0.000100
2021-07-12 11:58:08.859875: step 5480/164800 (epoch 3/80),jp_loss = 0.019867, trig_loss = 0.029968, rela_loss = 0.000100, bind_loss = 0.000000 (0.695 sec/batch), lr: 0.000100
2021-07-12 11:58:45.343841: step 5500/164800 (epoch 3/80),jp_loss = 0.022339, trig_loss = 0.187897, rela_loss = 0.000011, bind_loss = 0.020007 (1.651 sec/batch), lr: 0.000100
2021-07-12 11:59:19.286310: step 5520/164800 (epoch 3/80),jp_loss = 0.026932, trig_loss = 11.394211, rela_loss = 0.001374, bind_loss = 0.000000 (1.062 sec/batch), lr: 0.000100
2021-07-12 11:59:43.935534: step 5540/164800 (epoch 3/80),jp_loss = 0.002975, trig_loss = 1.515350, rela_loss = 0.001121, bind_loss = 0.000000 (1.153 sec/batch), lr: 0.000100
2021-07-12 12:00:05.541578: step 5560/164800 (epoch 3/80),jp_loss = 0.009064, trig_loss = 0.003601, rela_loss = 0.000016, bind_loss = 0.000000 (1.149 sec/batch), lr: 0.000100
2021-07-12 12:00:26.827351: step 5580/164800 (epoch 3/80),jp_loss = 0.006195, trig_loss = 0.211319, rela_loss = 0.054439, bind_loss = 0.026801 (1.651 sec/batch), lr: 0.000100
2021-07-12 12:00:52.556689: step 5600/164800 (epoch 3/80),jp_loss = 0.003296, trig_loss = 0.005920, rela_loss = 0.090271, bind_loss = 0.000000 (1.579 sec/batch), lr: 0.000100
2021-07-12 12:01:16.100020: step 5620/164800 (epoch 3/80),jp_loss = 0.002151, trig_loss = 0.005157, rela_loss = 0.015328, bind_loss = 0.000000 (0.648 sec/batch), lr: 0.000100
2021-07-12 12:01:46.521665: step 5640/164800 (epoch 3/80),jp_loss = 0.005459, trig_loss = 0.027863, rela_loss = 0.276814, bind_loss = 0.000000 (0.826 sec/batch), lr: 0.000100
2021-07-12 12:02:04.195161: step 5660/164800 (epoch 3/80),jp_loss = 0.004059, trig_loss = 9.990173, rela_loss = 0.083841, bind_loss = 0.000000 (1.526 sec/batch), lr: 0.000100
2021-07-12 12:02:45.150468: step 5680/164800 (epoch 3/80),jp_loss = 0.002441, trig_loss = 0.053040, rela_loss = 0.119791, bind_loss = 0.000000 (2.897 sec/batch), lr: 0.000100
2021-07-12 12:03:07.322428: step 5700/164800 (epoch 3/80),jp_loss = 0.002869, trig_loss = 0.013245, rela_loss = 0.085304, bind_loss = 0.000000 (0.978 sec/batch), lr: 0.000100
2021-07-12 12:03:33.330044: step 5720/164800 (epoch 3/80),jp_loss = 0.006393, trig_loss = 0.025299, rela_loss = 0.000791, bind_loss = 0.000000 (1.360 sec/batch), lr: 0.000100
2021-07-12 12:03:55.481014: step 5740/164800 (epoch 3/80),jp_loss = 0.006332, trig_loss = 0.003120, rela_loss = 0.000000, bind_loss = 0.000000 (0.394 sec/batch), lr: 0.000100
2021-07-12 12:04:30.129086: step 5760/164800 (epoch 3/80),jp_loss = 0.007568, trig_loss = 0.090027, rela_loss = 1.438586, bind_loss = 0.000000 (1.824 sec/batch), lr: 0.000100
2021-07-12 12:04:58.955069: step 5780/164800 (epoch 3/80),jp_loss = 0.005524, trig_loss = 0.003143, rela_loss = 0.000043, bind_loss = 0.000000 (1.064 sec/batch), lr: 0.000100
2021-07-12 12:05:16.592614: step 5800/164800 (epoch 3/80),jp_loss = 0.003860, trig_loss = 0.053360, rela_loss = 0.001392, bind_loss = 0.000000 (0.739 sec/batch), lr: 0.000100
2021-07-12 12:05:40.051973: step 5820/164800 (epoch 3/80),jp_loss = 0.005859, trig_loss = 0.038971, rela_loss = 0.000002, bind_loss = 0.000000 (1.631 sec/batch), lr: 0.000100
2021-07-12 12:06:02.158354: step 5840/164800 (epoch 3/80),jp_loss = 0.001251, trig_loss = 0.006378, rela_loss = 0.000000, bind_loss = 0.000000 (0.564 sec/batch), lr: 0.000100
2021-07-12 12:06:27.576308: step 5860/164800 (epoch 3/80),jp_loss = 0.006821, trig_loss = 0.230972, rela_loss = 0.000129, bind_loss = 0.000000 (2.128 sec/batch), lr: 0.000100
2021-07-12 12:06:50.998845: step 5880/164800 (epoch 3/80),jp_loss = 0.006836, trig_loss = 0.137726, rela_loss = 0.655074, bind_loss = 0.000000 (1.457 sec/batch), lr: 0.000100
2021-07-12 12:07:18.144972: step 5900/164800 (epoch 3/80),jp_loss = 5.266846, trig_loss = 0.006104, rela_loss = 0.840526, bind_loss = 0.000000 (1.562 sec/batch), lr: 0.000100
2021-07-12 12:07:54.224874: step 5920/164800 (epoch 3/80),jp_loss = 0.026550, trig_loss = 0.055862, rela_loss = 0.003151, bind_loss = 0.005068 (3.296 sec/batch), lr: 0.000100
2021-07-12 12:08:18.090571: step 5940/164800 (epoch 3/80),jp_loss = 0.023926, trig_loss = 0.932251, rela_loss = 0.002681, bind_loss = 0.000000 (0.799 sec/batch), lr: 0.000100
2021-07-12 12:08:44.750489: step 5960/164800 (epoch 3/80),jp_loss = 3.682510, trig_loss = 0.021210, rela_loss = 0.763746, bind_loss = 0.000000 (3.172 sec/batch), lr: 0.000100
2021-07-12 12:09:26.025339: step 5980/164800 (epoch 3/80),jp_loss = 0.004272, trig_loss = 0.024963, rela_loss = 0.002830, bind_loss = 0.000000 (1.484 sec/batch), lr: 0.000100
2021-07-12 12:09:49.437166: step 6000/164800 (epoch 3/80),jp_loss = 0.006866, trig_loss = 0.200058, rela_loss = 0.172020, bind_loss = 0.000000 (1.747 sec/batch), lr: 0.000100
2021-07-12 12:10:33.323418: step 6020/164800 (epoch 3/80),jp_loss = 0.002777, trig_loss = 0.004211, rela_loss = 0.000037, bind_loss = 0.000000 (0.778 sec/batch), lr: 0.000100
2021-07-12 12:10:56.352757: step 6040/164800 (epoch 3/80),jp_loss = 1.579254, trig_loss = 7.843933, rela_loss = 0.381787, bind_loss = 0.000000 (3.678 sec/batch), lr: 0.000100
2021-07-12 12:11:23.394338: step 6060/164800 (epoch 3/80),jp_loss = 0.001465, trig_loss = 0.007416, rela_loss = 0.000117, bind_loss = 0.000000 (0.716 sec/batch), lr: 0.000100
2021-07-12 12:11:48.681197: step 6080/164800 (epoch 3/80),jp_loss = 0.011230, trig_loss = 5.649323, rela_loss = 0.000004, bind_loss = 0.025536 (3.461 sec/batch), lr: 0.000100
2021-07-12 12:12:09.745091: step 6100/164800 (epoch 3/80),jp_loss = 0.020218, trig_loss = 0.006561, rela_loss = 0.000086, bind_loss = 0.000000 (0.829 sec/batch), lr: 0.000100
2021-07-12 12:12:34.963389: step 6120/164800 (epoch 3/80),jp_loss = 0.012894, trig_loss = 0.112839, rela_loss = 0.000192, bind_loss = 0.000000 (1.235 sec/batch), lr: 0.000100
2021-07-12 12:12:58.227167: step 6140/164800 (epoch 3/80),jp_loss = 0.001770, trig_loss = 0.003296, rela_loss = 0.000001, bind_loss = 0.000000 (0.944 sec/batch), lr: 0.000100
2021-07-12 12:13:23.764267: step 6160/164800 (epoch 3/80),jp_loss = 0.007393, trig_loss = 0.016907, rela_loss = 0.773585, bind_loss = 0.068466 (1.251 sec/batch), lr: 0.000100
2021-07-12 12:13:49.112930: step 6180/164800 (epoch 3/80),jp_loss = 0.001892, trig_loss = 0.499756, rela_loss = 0.003102, bind_loss = 0.000000 (1.084 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  96.93%  R:  97.15%  F1:  97.04%  #: 2174

Final Score:
Precision (micro): 96.925%
   Recall (micro): 97.148%
       F1 (micro): 97.037%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  91.53%  R:  94.61%  F1:  93.05%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  93.14%  R:  92.53%  F1:  92.83%  #: 455
Localization         P:  93.01%  R:  97.19%  F1:  95.05%  #: 178
Negative_regulation  P:  85.04%  R:  90.50%  F1:  87.69%  #: 421
Phosphorylation      P:  94.44%  R:  98.71%  F1:  96.53%  #: 155
Positive_regulation  P:  88.89%  R:  81.66%  F1:  85.12%  #: 627
Protein_catabolism   P:  73.68%  R:  93.33%  F1:  82.35%  #: 30
Regulation           P:  82.49%  R:  70.87%  F1:  76.24%  #: 206
Transcription        P:  47.42%  R:  68.66%  F1:  56.10%  #: 67

Final Score:
Precision (micro): 87.638%
   Recall (micro): 87.710%
       F1 (micro): 87.674%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  84.95%  R:  87.91%  F1:  86.40%  #: 488
Gene_expression      P:  91.28%  R:  91.91%  F1:  91.60%  #: 581
Localization         P:  88.12%  R:  92.71%  F1:  90.36%  #: 192
Negative_regulation  P:  69.62%  R:  81.65%  F1:  75.16%  #: 654
Phosphorylation      P:  88.63%  R:  94.92%  F1:  91.67%  #: 197
Positive_regulation  P:  75.25%  R:  72.39%  F1:  73.80%  #: 920
Protein_catabolism   P:  70.00%  R:  93.33%  F1:  80.00%  #: 30
Regulation           P:  61.09%  R:  62.81%  F1:  61.94%  #: 285
Transcription        P:  45.16%  R:  62.92%  F1:  52.58%  #: 89

Final Score:
Precision (micro): 77.270%
   Recall (micro): 81.228%
       F1 (micro): 79.200%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  55.88%  R:  76.44%  F1:  64.56%  #: 174

Final Score:
Precision (micro): 55.882%
   Recall (micro): 76.437%
       F1 (micro): 64.563%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  60.89%  R:  73.65%  F1:  66.67%  #: 353

Gene_expression      P:  91.28%  R:  91.91%  F1:  91.60%  #: 581

Localization         P:  89.00%  R:  92.71%  F1:  90.82%  #: 192

Negative_regulation  P:  61.80%  R:  62.16%  F1:  61.98%  #: 518

Phosphorylation      P:  83.17%  R:  87.96%  F1:  85.50%  #: 191

Positive_regulation  P:  70.40%  R:  55.48%  F1:  62.06%  #: 849

Protein_catabolism   P:  71.79%  R:  93.33%  F1:  81.16%  #: 30

Regulation           P:  55.96%  R:  45.52%  F1:  50.21%  #: 268

Transcription        P:  46.28%  R:  62.92%  F1:  53.33%  #: 89

Final Score:
Precision (micro): 71.730%
   Recall (micro): 69.652%
       F1 (micro): 70.676%
epoch 3: train_loss = 0.467134, dev_loss = 0.000000, dev_rela_f1 = 0.7068
0.7067569800099124 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_3.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.7067569800099124 ---- 3

2021-07-12 12:26:26.532995: step 6200/164800 (epoch 4/80),jp_loss = 0.006104, trig_loss = 4.762604, rela_loss = 0.030443, bind_loss = 0.000000 (1.742 sec/batch), lr: 0.000100
2021-07-12 12:26:56.612615: step 6220/164800 (epoch 4/80),jp_loss = 0.005585, trig_loss = 25.348877, rela_loss = 4.945602, bind_loss = 0.000000 (0.720 sec/batch), lr: 0.000100
2021-07-12 12:27:32.546272: step 6240/164800 (epoch 4/80),jp_loss = 0.004257, trig_loss = 0.230713, rela_loss = 0.000000, bind_loss = 0.000000 (0.699 sec/batch), lr: 0.000100
2021-07-12 12:27:57.312756: step 6260/164800 (epoch 4/80),jp_loss = 0.002090, trig_loss = 0.022491, rela_loss = 0.000003, bind_loss = 0.000000 (0.640 sec/batch), lr: 0.000100
2021-07-12 12:28:34.254131: step 6280/164800 (epoch 4/80),jp_loss = 0.004745, trig_loss = 0.339462, rela_loss = 0.260050, bind_loss = 0.000000 (0.726 sec/batch), lr: 0.000100
2021-07-12 12:29:03.994758: step 6300/164800 (epoch 4/80),jp_loss = 0.007019, trig_loss = 0.004089, rela_loss = 0.001455, bind_loss = 0.000000 (1.296 sec/batch), lr: 0.000100
2021-07-12 12:29:36.703676: step 6320/164800 (epoch 4/80),jp_loss = 0.003471, trig_loss = 0.002426, rela_loss = 0.000106, bind_loss = 0.007765 (0.625 sec/batch), lr: 0.000100
2021-07-12 12:29:59.621814: step 6340/164800 (epoch 4/80),jp_loss = 0.001709, trig_loss = 0.003632, rela_loss = 0.002790, bind_loss = 0.000000 (0.806 sec/batch), lr: 0.000100
2021-07-12 12:30:33.459704: step 6360/164800 (epoch 4/80),jp_loss = 0.364655, trig_loss = 4.908691, rela_loss = 0.125626, bind_loss = 0.000000 (1.134 sec/batch), lr: 0.000100
2021-07-12 12:30:56.269688: step 6380/164800 (epoch 4/80),jp_loss = 0.004791, trig_loss = 2.445404, rela_loss = 1.623470, bind_loss = 0.000000 (1.344 sec/batch), lr: 0.000100
2021-07-12 12:31:23.118617: step 6400/164800 (epoch 4/80),jp_loss = 0.001633, trig_loss = 7.937698, rela_loss = 0.000939, bind_loss = 0.000000 (0.678 sec/batch), lr: 0.000100
2021-07-12 12:31:58.563282: step 6420/164800 (epoch 4/80),jp_loss = 0.052017, trig_loss = 0.229156, rela_loss = 0.001249, bind_loss = 0.000000 (0.687 sec/batch), lr: 0.000100
2021-07-12 12:32:23.921059: step 6440/164800 (epoch 4/80),jp_loss = 0.002319, trig_loss = 0.006958, rela_loss = 0.000072, bind_loss = 0.000000 (1.348 sec/batch), lr: 0.000100
2021-07-12 12:32:57.593691: step 6460/164800 (epoch 4/80),jp_loss = 0.001274, trig_loss = 0.002647, rela_loss = 0.000006, bind_loss = 0.000000 (0.389 sec/batch), lr: 0.000100
2021-07-12 12:33:29.602960: step 6480/164800 (epoch 4/80),jp_loss = 0.002182, trig_loss = 0.004913, rela_loss = 0.000000, bind_loss = 0.000000 (0.522 sec/batch), lr: 0.000100
2021-07-12 12:33:56.311315: step 6500/164800 (epoch 4/80),jp_loss = 0.003723, trig_loss = 12.600647, rela_loss = 0.001736, bind_loss = 0.000000 (0.863 sec/batch), lr: 0.000100
2021-07-12 12:34:27.272943: step 6520/164800 (epoch 4/80),jp_loss = 0.004822, trig_loss = 0.002060, rela_loss = 0.000000, bind_loss = 0.000000 (0.677 sec/batch), lr: 0.000100
2021-07-12 12:34:58.939421: step 6540/164800 (epoch 4/80),jp_loss = 0.011368, trig_loss = 0.085236, rela_loss = 0.938923, bind_loss = 0.000000 (0.701 sec/batch), lr: 0.000100
2021-07-12 12:35:19.556512: step 6560/164800 (epoch 4/80),jp_loss = 9.579147, trig_loss = 6.326904, rela_loss = 0.010694, bind_loss = 0.018339 (1.674 sec/batch), lr: 0.000100
2021-07-12 12:35:40.447643: step 6580/164800 (epoch 4/80),jp_loss = 0.002869, trig_loss = 1.590942, rela_loss = 0.000034, bind_loss = 0.000000 (0.669 sec/batch), lr: 0.000100
2021-07-12 12:36:17.910849: step 6600/164800 (epoch 4/80),jp_loss = 0.005341, trig_loss = 6.713562, rela_loss = 7.275750, bind_loss = 0.000000 (2.152 sec/batch), lr: 0.000100
2021-07-12 12:36:43.379022: step 6620/164800 (epoch 4/80),jp_loss = 0.003113, trig_loss = 2.525757, rela_loss = 0.001565, bind_loss = 0.000000 (0.914 sec/batch), lr: 0.000100
2021-07-12 12:37:06.311924: step 6640/164800 (epoch 4/80),jp_loss = 0.036072, trig_loss = 0.026863, rela_loss = 1.306490, bind_loss = 0.008009 (1.057 sec/batch), lr: 0.000100
2021-07-12 12:37:54.651250: step 6660/164800 (epoch 4/80),jp_loss = 6.859161, trig_loss = 7.721191, rela_loss = 0.008495, bind_loss = 0.000000 (6.541 sec/batch), lr: 0.000100
2021-07-12 12:38:15.932994: step 6680/164800 (epoch 4/80),jp_loss = 0.001129, trig_loss = 0.004120, rela_loss = 0.000268, bind_loss = 0.000000 (0.556 sec/batch), lr: 0.000100
2021-07-12 12:38:41.923761: step 6700/164800 (epoch 4/80),jp_loss = 0.003021, trig_loss = 0.004852, rela_loss = 0.000154, bind_loss = 0.000000 (0.647 sec/batch), lr: 0.000100
2021-07-12 12:39:17.194051: step 6720/164800 (epoch 4/80),jp_loss = 0.001068, trig_loss = 0.006378, rela_loss = 0.000003, bind_loss = 0.000000 (0.770 sec/batch), lr: 0.000100
2021-07-12 12:39:51.588559: step 6740/164800 (epoch 4/80),jp_loss = 0.008636, trig_loss = 7.252594, rela_loss = 1.486137, bind_loss = 0.000000 (3.312 sec/batch), lr: 0.000100
2021-07-12 12:40:27.813235: step 6760/164800 (epoch 4/80),jp_loss = 0.003204, trig_loss = 8.506958, rela_loss = 0.004995, bind_loss = 0.000000 (1.554 sec/batch), lr: 0.000100
2021-07-12 12:40:50.767054: step 6780/164800 (epoch 4/80),jp_loss = 0.003311, trig_loss = 0.007324, rela_loss = 0.003557, bind_loss = 0.000000 (1.413 sec/batch), lr: 0.000100
2021-07-12 12:41:15.681501: step 6800/164800 (epoch 4/80),jp_loss = 11.710846, trig_loss = 0.081573, rela_loss = 0.000087, bind_loss = 0.002038 (1.830 sec/batch), lr: 0.000100
2021-07-12 12:41:46.851228: step 6820/164800 (epoch 4/80),jp_loss = 0.009293, trig_loss = 0.068069, rela_loss = 0.000041, bind_loss = 0.000000 (1.314 sec/batch), lr: 0.000100
2021-07-12 12:42:10.104468: step 6840/164800 (epoch 4/80),jp_loss = 0.003693, trig_loss = 0.003052, rela_loss = 0.000001, bind_loss = 0.000000 (0.673 sec/batch), lr: 0.000100
2021-07-12 12:42:33.127576: step 6860/164800 (epoch 4/80),jp_loss = 0.003815, trig_loss = 2.842865, rela_loss = 2.279596, bind_loss = 0.000000 (1.015 sec/batch), lr: 0.000100
2021-07-12 12:42:57.144397: step 6880/164800 (epoch 4/80),jp_loss = 0.002869, trig_loss = 2.794861, rela_loss = 5.254626, bind_loss = 0.000000 (1.067 sec/batch), lr: 0.000100
2021-07-12 12:43:23.129712: step 6900/164800 (epoch 4/80),jp_loss = 0.000412, trig_loss = 0.006805, rela_loss = 0.000431, bind_loss = 0.000000 (0.625 sec/batch), lr: 0.000100
2021-07-12 12:43:47.402758: step 6920/164800 (epoch 4/80),jp_loss = 0.001984, trig_loss = 0.006653, rela_loss = 0.000000, bind_loss = 0.000000 (1.306 sec/batch), lr: 0.000100
2021-07-12 12:44:17.969516: step 6940/164800 (epoch 4/80),jp_loss = 0.000778, trig_loss = 0.200378, rela_loss = 0.002868, bind_loss = 0.000000 (0.728 sec/batch), lr: 0.000100
2021-07-12 12:44:49.056870: step 6960/164800 (epoch 4/80),jp_loss = 0.001076, trig_loss = 0.001465, rela_loss = 0.000253, bind_loss = 0.000000 (0.354 sec/batch), lr: 0.000100
2021-07-12 12:45:28.839351: step 6980/164800 (epoch 4/80),jp_loss = 0.001129, trig_loss = 0.011444, rela_loss = 0.000002, bind_loss = 0.000000 (0.864 sec/batch), lr: 0.000100
2021-07-12 12:45:54.944956: step 7000/164800 (epoch 4/80),jp_loss = 0.002090, trig_loss = 0.690338, rela_loss = 0.000105, bind_loss = 0.000000 (1.234 sec/batch), lr: 0.000100
2021-07-12 12:46:27.632932: step 7020/164800 (epoch 4/80),jp_loss = 5.914368, trig_loss = 0.020966, rela_loss = 0.000137, bind_loss = 0.530397 (4.203 sec/batch), lr: 0.000100
2021-07-12 12:46:50.310844: step 7040/164800 (epoch 4/80),jp_loss = 0.005463, trig_loss = 0.002808, rela_loss = 0.000008, bind_loss = 0.000000 (1.003 sec/batch), lr: 0.000100
2021-07-12 12:47:15.562258: step 7060/164800 (epoch 4/80),jp_loss = 0.004425, trig_loss = 0.600342, rela_loss = 0.032233, bind_loss = 0.000000 (2.758 sec/batch), lr: 0.000100
2021-07-12 12:47:38.069079: step 7080/164800 (epoch 4/80),jp_loss = 0.004364, trig_loss = 0.017471, rela_loss = 0.000036, bind_loss = 0.000000 (0.452 sec/batch), lr: 0.000100
2021-07-12 12:48:06.423073: step 7100/164800 (epoch 4/80),jp_loss = 0.003143, trig_loss = 2.058258, rela_loss = 0.000045, bind_loss = 0.000000 (0.664 sec/batch), lr: 0.000100
2021-07-12 12:48:38.880332: step 7120/164800 (epoch 4/80),jp_loss = 0.129059, trig_loss = 0.009430, rela_loss = 0.000258, bind_loss = 0.000000 (0.761 sec/batch), lr: 0.000100
2021-07-12 12:49:06.161087: step 7140/164800 (epoch 4/80),jp_loss = 0.002930, trig_loss = 0.004974, rela_loss = 0.000041, bind_loss = 0.000000 (1.909 sec/batch), lr: 0.000100
2021-07-12 12:49:32.858843: step 7160/164800 (epoch 4/80),jp_loss = 0.002563, trig_loss = 7.950409, rela_loss = 0.000084, bind_loss = 0.000000 (0.548 sec/batch), lr: 0.000100
2021-07-12 12:50:06.400628: step 7180/164800 (epoch 4/80),jp_loss = 18.265015, trig_loss = 0.008209, rela_loss = 0.000085, bind_loss = 0.000000 (0.814 sec/batch), lr: 0.000100
2021-07-12 12:50:33.733900: step 7200/164800 (epoch 4/80),jp_loss = 0.002991, trig_loss = 11.272797, rela_loss = 0.002666, bind_loss = 0.000000 (1.871 sec/batch), lr: 0.000100
2021-07-12 12:50:58.957507: step 7220/164800 (epoch 4/80),jp_loss = 1.740448, trig_loss = 0.003174, rela_loss = 0.000000, bind_loss = 0.000000 (1.001 sec/batch), lr: 0.000100
2021-07-12 12:51:19.837456: step 7240/164800 (epoch 4/80),jp_loss = 0.004776, trig_loss = 0.001190, rela_loss = 0.000313, bind_loss = 0.000000 (0.703 sec/batch), lr: 0.000100
2021-07-12 12:51:45.634923: step 7260/164800 (epoch 4/80),jp_loss = 0.000427, trig_loss = 0.005676, rela_loss = 0.000353, bind_loss = 0.000000 (1.041 sec/batch), lr: 0.000100
2021-07-12 12:52:04.615798: step 7280/164800 (epoch 4/80),jp_loss = 1.578491, trig_loss = 0.003021, rela_loss = 0.143300, bind_loss = 0.007836 (1.444 sec/batch), lr: 0.000100
2021-07-12 12:52:37.820807: step 7300/164800 (epoch 4/80),jp_loss = 0.001541, trig_loss = 0.002594, rela_loss = 0.000744, bind_loss = 0.000000 (0.900 sec/batch), lr: 0.000100
2021-07-12 12:53:07.126002: step 7320/164800 (epoch 4/80),jp_loss = 0.001175, trig_loss = 0.206573, rela_loss = 0.000164, bind_loss = 0.000000 (0.492 sec/batch), lr: 0.000100
2021-07-12 12:53:32.934712: step 7340/164800 (epoch 4/80),jp_loss = 0.002686, trig_loss = 4.938477, rela_loss = 0.002150, bind_loss = 0.014769 (0.558 sec/batch), lr: 0.000100
2021-07-12 12:53:55.678173: step 7360/164800 (epoch 4/80),jp_loss = 0.052460, trig_loss = 0.129395, rela_loss = 0.008419, bind_loss = 0.001810 (1.243 sec/batch), lr: 0.000100
2021-07-12 12:54:17.798436: step 7380/164800 (epoch 4/80),jp_loss = 0.000687, trig_loss = 0.000626, rela_loss = 0.000000, bind_loss = 0.000000 (0.451 sec/batch), lr: 0.000100
2021-07-12 12:54:41.053315: step 7400/164800 (epoch 4/80),jp_loss = 0.005371, trig_loss = 0.002380, rela_loss = 0.673428, bind_loss = 0.388656 (2.183 sec/batch), lr: 0.000100
2021-07-12 12:55:12.911815: step 7420/164800 (epoch 4/80),jp_loss = 0.003853, trig_loss = 9.611710, rela_loss = 0.000007, bind_loss = 0.000000 (2.577 sec/batch), lr: 0.000100
2021-07-12 12:55:38.110095: step 7440/164800 (epoch 4/80),jp_loss = 0.002304, trig_loss = 0.033142, rela_loss = 0.000009, bind_loss = 0.000000 (1.126 sec/batch), lr: 0.000100
2021-07-12 12:56:07.284040: step 7460/164800 (epoch 4/80),jp_loss = 0.003845, trig_loss = 0.003662, rela_loss = 0.000350, bind_loss = 0.010279 (1.582 sec/batch), lr: 0.000100
2021-07-12 12:56:30.297031: step 7480/164800 (epoch 4/80),jp_loss = 0.006134, trig_loss = 6.975342, rela_loss = 0.000000, bind_loss = 0.000000 (0.959 sec/batch), lr: 0.000100
2021-07-12 12:57:05.787461: step 7500/164800 (epoch 4/80),jp_loss = 0.003113, trig_loss = 8.771271, rela_loss = 2.725557, bind_loss = 0.000000 (2.429 sec/batch), lr: 0.000100
2021-07-12 12:57:27.534651: step 7520/164800 (epoch 4/80),jp_loss = 0.003815, trig_loss = 0.084076, rela_loss = 0.035192, bind_loss = 0.000000 (1.011 sec/batch), lr: 0.000100
2021-07-12 12:57:54.896850: step 7540/164800 (epoch 4/80),jp_loss = 0.001968, trig_loss = 0.239471, rela_loss = 0.001096, bind_loss = 0.000000 (0.698 sec/batch), lr: 0.000100
2021-07-12 12:58:31.280560: step 7560/164800 (epoch 4/80),jp_loss = 0.032074, trig_loss = 0.369507, rela_loss = 0.000004, bind_loss = 0.014267 (1.599 sec/batch), lr: 0.000100
2021-07-12 12:59:03.739814: step 7580/164800 (epoch 4/80),jp_loss = 0.006622, trig_loss = 11.204025, rela_loss = 0.002800, bind_loss = 0.000000 (1.044 sec/batch), lr: 0.000100
2021-07-12 12:59:28.143279: step 7600/164800 (epoch 4/80),jp_loss = 0.003494, trig_loss = 0.297272, rela_loss = 0.000295, bind_loss = 0.000000 (0.867 sec/batch), lr: 0.000100
2021-07-12 12:59:49.711660: step 7620/164800 (epoch 4/80),jp_loss = 0.000885, trig_loss = 0.005127, rela_loss = 0.000063, bind_loss = 0.000000 (1.131 sec/batch), lr: 0.000100
2021-07-12 13:00:10.503455: step 7640/164800 (epoch 4/80),jp_loss = 6.878769, trig_loss = 0.071274, rela_loss = 0.000154, bind_loss = 0.014836 (1.477 sec/batch), lr: 0.000100
2021-07-12 13:00:35.527031: step 7660/164800 (epoch 4/80),jp_loss = 0.004608, trig_loss = 0.003357, rela_loss = 0.000437, bind_loss = 0.000000 (1.444 sec/batch), lr: 0.000100
2021-07-12 13:00:59.316093: step 7680/164800 (epoch 4/80),jp_loss = 0.003769, trig_loss = 1.482788, rela_loss = 0.000172, bind_loss = 0.000000 (0.705 sec/batch), lr: 0.000100
2021-07-12 13:01:31.713242: step 7700/164800 (epoch 4/80),jp_loss = 0.006115, trig_loss = 0.011368, rela_loss = 0.141529, bind_loss = 0.000000 (0.911 sec/batch), lr: 0.000100
2021-07-12 13:01:49.603519: step 7720/164800 (epoch 4/80),jp_loss = 0.001862, trig_loss = 5.707458, rela_loss = 0.007092, bind_loss = 0.000000 (1.464 sec/batch), lr: 0.000100
2021-07-12 13:02:28.490298: step 7740/164800 (epoch 4/80),jp_loss = 0.001587, trig_loss = 0.015869, rela_loss = 0.004454, bind_loss = 0.000000 (2.706 sec/batch), lr: 0.000100
2021-07-12 13:02:51.285630: step 7760/164800 (epoch 4/80),jp_loss = 0.002289, trig_loss = 0.007538, rela_loss = 0.071076, bind_loss = 0.000000 (1.064 sec/batch), lr: 0.000100
2021-07-12 13:03:16.355164: step 7780/164800 (epoch 4/80),jp_loss = 0.001678, trig_loss = 0.007568, rela_loss = 0.003032, bind_loss = 0.000000 (1.382 sec/batch), lr: 0.000100
2021-07-12 13:03:37.500186: step 7800/164800 (epoch 4/80),jp_loss = 0.001770, trig_loss = 0.000565, rela_loss = 0.000007, bind_loss = 0.000000 (0.415 sec/batch), lr: 0.000100
2021-07-12 13:04:11.937433: step 7820/164800 (epoch 4/80),jp_loss = 0.003296, trig_loss = 1.962677, rela_loss = 0.178311, bind_loss = 0.000000 (1.743 sec/batch), lr: 0.000100
2021-07-12 13:04:41.336218: step 7840/164800 (epoch 4/80),jp_loss = 0.002533, trig_loss = 0.001343, rela_loss = 0.000779, bind_loss = 0.000000 (1.297 sec/batch), lr: 0.000100
2021-07-12 13:04:58.594993: step 7860/164800 (epoch 4/80),jp_loss = 0.002274, trig_loss = 0.012054, rela_loss = 0.000201, bind_loss = 0.000000 (0.690 sec/batch), lr: 0.000100
2021-07-12 13:05:21.700691: step 7880/164800 (epoch 4/80),jp_loss = 0.002472, trig_loss = 0.013977, rela_loss = 0.000006, bind_loss = 0.000000 (1.642 sec/batch), lr: 0.000100
2021-07-12 13:05:42.618106: step 7900/164800 (epoch 4/80),jp_loss = 0.002533, trig_loss = 0.002197, rela_loss = 0.000106, bind_loss = 0.000000 (0.615 sec/batch), lr: 0.000100
2021-07-12 13:06:07.686988: step 7920/164800 (epoch 4/80),jp_loss = 0.005417, trig_loss = 0.303177, rela_loss = 0.000065, bind_loss = 0.000000 (2.317 sec/batch), lr: 0.000100
2021-07-12 13:06:31.709443: step 7940/164800 (epoch 4/80),jp_loss = 0.009460, trig_loss = 0.038300, rela_loss = 0.038156, bind_loss = 0.000000 (1.378 sec/batch), lr: 0.000100
2021-07-12 13:06:59.142175: step 7960/164800 (epoch 4/80),jp_loss = 0.002319, trig_loss = 0.016663, rela_loss = 0.001677, bind_loss = 0.000000 (1.530 sec/batch), lr: 0.000100
2021-07-12 13:07:34.129642: step 7980/164800 (epoch 4/80),jp_loss = 0.007980, trig_loss = 0.007599, rela_loss = 0.000745, bind_loss = 0.003904 (3.018 sec/batch), lr: 0.000100
2021-07-12 13:07:57.654746: step 8000/164800 (epoch 4/80),jp_loss = 3.721924, trig_loss = 9.230286, rela_loss = 0.000651, bind_loss = 0.000000 (0.691 sec/batch), lr: 0.000100
2021-07-12 13:08:23.161198: step 8020/164800 (epoch 4/80),jp_loss = 0.117584, trig_loss = 0.013885, rela_loss = 1.588476, bind_loss = 0.000000 (3.081 sec/batch), lr: 0.000100
2021-07-12 13:09:02.294637: step 8040/164800 (epoch 4/80),jp_loss = 0.006256, trig_loss = 0.154114, rela_loss = 0.016567, bind_loss = 0.000000 (1.693 sec/batch), lr: 0.000100
2021-07-12 13:09:26.217299: step 8060/164800 (epoch 4/80),jp_loss = 0.010529, trig_loss = 0.044083, rela_loss = 0.000332, bind_loss = 0.000000 (1.797 sec/batch), lr: 0.000100
2021-07-12 13:10:11.605872: step 8080/164800 (epoch 4/80),jp_loss = 0.001953, trig_loss = 1.730713, rela_loss = 0.000008, bind_loss = 0.000000 (0.710 sec/batch), lr: 0.000100
2021-07-12 13:10:35.422459: step 8100/164800 (epoch 4/80),jp_loss = 0.013885, trig_loss = 7.669312, rela_loss = 0.085690, bind_loss = 0.000000 (3.989 sec/batch), lr: 0.000100
2021-07-12 13:11:03.785969: step 8120/164800 (epoch 4/80),jp_loss = 0.001877, trig_loss = 0.003448, rela_loss = 0.000015, bind_loss = 0.000000 (0.671 sec/batch), lr: 0.000100
2021-07-12 13:11:30.101335: step 8140/164800 (epoch 4/80),jp_loss = 0.005585, trig_loss = 4.257751, rela_loss = 0.003290, bind_loss = 0.002830 (3.636 sec/batch), lr: 0.000100
2021-07-12 13:11:52.687152: step 8160/164800 (epoch 4/80),jp_loss = 0.005875, trig_loss = 0.002655, rela_loss = 0.000000, bind_loss = 0.000000 (0.898 sec/batch), lr: 0.000100
2021-07-12 13:12:20.035260: step 8180/164800 (epoch 4/80),jp_loss = 0.006393, trig_loss = 0.083649, rela_loss = 0.000335, bind_loss = 0.000000 (1.436 sec/batch), lr: 0.000100
2021-07-12 13:12:44.754679: step 8200/164800 (epoch 4/80),jp_loss = 0.003418, trig_loss = 0.001160, rela_loss = 0.000000, bind_loss = 0.000000 (1.084 sec/batch), lr: 0.000100
2021-07-12 13:13:12.364936: step 8220/164800 (epoch 4/80),jp_loss = 0.005890, trig_loss = 0.004913, rela_loss = 0.000035, bind_loss = 0.001529 (1.387 sec/batch), lr: 0.000100
2021-07-12 13:13:39.466375: step 8240/164800 (epoch 4/80),jp_loss = 0.001678, trig_loss = 1.629089, rela_loss = 0.002288, bind_loss = 0.000000 (1.180 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  94.40%  R:  99.26%  F1:  96.77%  #: 2174

Final Score:
Precision (micro): 94.401%
   Recall (micro): 99.264%
       F1 (micro): 96.771%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  91.26%  R:  94.95%  F1:  93.07%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  91.35%  R:  95.16%  F1:  93.22%  #: 455
Localization         P:  93.58%  R:  98.31%  F1:  95.89%  #: 178
Negative_regulation  P:  90.23%  R:  94.30%  F1:  92.22%  #: 421
Phosphorylation      P:  95.03%  R:  98.71%  F1:  96.84%  #: 155
Positive_regulation  P:  91.35%  R:  89.31%  F1:  90.32%  #: 627
Protein_catabolism   P:  84.85%  R:  93.33%  F1:  88.89%  #: 30
Regulation           P:  88.08%  R:  82.52%  F1:  85.21%  #: 206
Transcription        P:  63.53%  R:  80.60%  F1:  71.05%  #: 67

Final Score:
Precision (micro): 90.261%
   Recall (micro): 92.257%
       F1 (micro): 91.248%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  88.20%  R:  87.30%  F1:  87.74%  #: 488
Gene_expression      P:  90.05%  R:  93.46%  F1:  91.72%  #: 581
Localization         P:  91.00%  R:  94.79%  F1:  92.86%  #: 192
Negative_regulation  P:  76.88%  R:  88.85%  F1:  82.44%  #: 655
Phosphorylation      P:  92.65%  R:  95.94%  F1:  94.26%  #: 197
Positive_regulation  P:  74.90%  R:  82.45%  F1:  78.49%  #: 923
Protein_catabolism   P:  77.78%  R:  93.33%  F1:  84.85%  #: 30
Regulation           P:  72.58%  R:  75.87%  F1:  74.19%  #: 286
Transcription        P:  59.62%  R:  69.66%  F1:  64.25%  #: 89

Final Score:
Precision (micro): 80.767%
   Recall (micro): 86.893%
       F1 (micro): 83.718%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  75.82%  R:  79.77%  F1:  77.75%  #: 173

Final Score:
Precision (micro): 75.824%
   Recall (micro): 79.769%
       F1 (micro): 77.746%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  73.58%  R:  77.34%  F1:  75.41%  #: 353

Gene_expression      P:  90.65%  R:  93.46%  F1:  92.03%  #: 581

Localization         P:  91.92%  R:  94.79%  F1:  93.33%  #: 192

Negative_regulation  P:  71.22%  R:  67.24%  F1:  69.18%  #: 519

Phosphorylation      P:  87.77%  R:  86.39%  F1:  87.07%  #: 191

Positive_regulation  P:  68.85%  R:  58.10%  F1:  63.02%  #: 852

Protein_catabolism   P:  84.85%  R:  93.33%  F1:  88.89%  #: 30

Regulation           P:  69.09%  R:  56.51%  F1:  62.17%  #: 269

Transcription        P:  63.27%  R:  69.66%  F1:  66.31%  #: 89

Final Score:
Precision (micro): 77.126%
   Recall (micro): 73.114%
       F1 (micro): 75.067%
epoch 4: train_loss = 0.365734, dev_loss = 0.000000, dev_rela_f1 = 0.7507
0.7506675567423231 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_4.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.7506675567423231 ---- 4

2021-07-12 13:26:28.017731: step 8260/164800 (epoch 5/80),jp_loss = 0.005554, trig_loss = 0.573517, rela_loss = 0.000183, bind_loss = 0.000000 (1.929 sec/batch), lr: 0.000100
2021-07-12 13:26:56.757000: step 8280/164800 (epoch 5/80),jp_loss = 0.001678, trig_loss = 18.897858, rela_loss = 2.641701, bind_loss = 0.000000 (0.749 sec/batch), lr: 0.000100
2021-07-12 13:27:32.927211: step 8300/164800 (epoch 5/80),jp_loss = 4.751175, trig_loss = 0.010132, rela_loss = 0.294534, bind_loss = 0.000000 (0.705 sec/batch), lr: 0.000100
2021-07-12 13:27:56.168077: step 8320/164800 (epoch 5/80),jp_loss = 0.000732, trig_loss = 0.008636, rela_loss = 0.000000, bind_loss = 0.000000 (0.658 sec/batch), lr: 0.000100
2021-07-12 13:28:30.789257: step 8340/164800 (epoch 5/80),jp_loss = 0.001801, trig_loss = 0.253632, rela_loss = 0.444005, bind_loss = 0.000000 (0.683 sec/batch), lr: 0.000100
2021-07-12 13:28:58.991061: step 8360/164800 (epoch 5/80),jp_loss = 0.001251, trig_loss = 0.007202, rela_loss = 0.000113, bind_loss = 0.000000 (1.317 sec/batch), lr: 0.000100
2021-07-12 13:29:30.114546: step 8380/164800 (epoch 5/80),jp_loss = 0.000984, trig_loss = 0.002800, rela_loss = 0.000047, bind_loss = 0.000689 (0.570 sec/batch), lr: 0.000100
2021-07-12 13:29:53.153647: step 8400/164800 (epoch 5/80),jp_loss = 0.001053, trig_loss = 0.002533, rela_loss = 0.006153, bind_loss = 0.000000 (1.001 sec/batch), lr: 0.000100
2021-07-12 13:30:26.563785: step 8420/164800 (epoch 5/80),jp_loss = 0.693375, trig_loss = 4.627869, rela_loss = 0.020964, bind_loss = 0.000000 (1.190 sec/batch), lr: 0.000100
2021-07-12 13:30:52.242906: step 8440/164800 (epoch 5/80),jp_loss = 9.642853, trig_loss = 1.317200, rela_loss = 0.247464, bind_loss = 0.000000 (1.332 sec/batch), lr: 0.000100
2021-07-12 13:31:22.214890: step 8460/164800 (epoch 5/80),jp_loss = 0.001480, trig_loss = 6.058044, rela_loss = 0.000774, bind_loss = 0.000000 (0.685 sec/batch), lr: 0.000100
2021-07-12 13:32:02.205493: step 8480/164800 (epoch 5/80),jp_loss = 0.004242, trig_loss = 0.001282, rela_loss = 0.000004, bind_loss = 0.000000 (0.951 sec/batch), lr: 0.000100
2021-07-12 13:32:31.371634: step 8500/164800 (epoch 5/80),jp_loss = 0.001648, trig_loss = 0.001648, rela_loss = 0.000029, bind_loss = 0.000000 (1.485 sec/batch), lr: 0.000100
2021-07-12 13:33:06.930012: step 8520/164800 (epoch 5/80),jp_loss = 0.001213, trig_loss = 0.005173, rela_loss = 0.000083, bind_loss = 0.000000 (0.421 sec/batch), lr: 0.000100
2021-07-12 13:33:42.464687: step 8540/164800 (epoch 5/80),jp_loss = 0.001129, trig_loss = 0.003052, rela_loss = 0.000004, bind_loss = 0.000000 (0.651 sec/batch), lr: 0.000100
2021-07-12 13:34:14.236663: step 8560/164800 (epoch 5/80),jp_loss = 0.002930, trig_loss = 13.168564, rela_loss = 0.540205, bind_loss = 0.000000 (1.248 sec/batch), lr: 0.000100
2021-07-12 13:34:50.693940: step 8580/164800 (epoch 5/80),jp_loss = 0.001190, trig_loss = 0.001419, rela_loss = 0.000000, bind_loss = 0.000000 (0.667 sec/batch), lr: 0.000100
2021-07-12 13:35:28.230871: step 8600/164800 (epoch 5/80),jp_loss = 0.003464, trig_loss = 0.008026, rela_loss = 0.000281, bind_loss = 0.000000 (0.928 sec/batch), lr: 0.000100
2021-07-12 13:35:53.607654: step 8620/164800 (epoch 5/80),jp_loss = 5.440369, trig_loss = 5.619934, rela_loss = 0.013211, bind_loss = 0.001550 (1.971 sec/batch), lr: 0.000100
2021-07-12 13:36:19.013563: step 8640/164800 (epoch 5/80),jp_loss = 0.040344, trig_loss = 5.188446, rela_loss = 0.000875, bind_loss = 0.000000 (1.016 sec/batch), lr: 0.000100
2021-07-12 13:37:03.209637: step 8660/164800 (epoch 5/80),jp_loss = 0.001251, trig_loss = 4.273956, rela_loss = 0.519193, bind_loss = 0.000000 (2.498 sec/batch), lr: 0.000100
2021-07-12 13:37:33.772492: step 8680/164800 (epoch 5/80),jp_loss = 0.002869, trig_loss = 2.042450, rela_loss = 0.000322, bind_loss = 0.000000 (1.186 sec/batch), lr: 0.000100
2021-07-12 13:38:02.004038: step 8700/164800 (epoch 5/80),jp_loss = 0.004135, trig_loss = 0.007172, rela_loss = 0.001434, bind_loss = 0.001094 (1.285 sec/batch), lr: 0.000100
2021-07-12 13:38:54.751247: step 8720/164800 (epoch 5/80),jp_loss = 2.104858, trig_loss = 0.082397, rela_loss = 0.000225, bind_loss = 0.000000 (6.526 sec/batch), lr: 0.000100
2021-07-12 13:39:21.061938: step 8740/164800 (epoch 5/80),jp_loss = 0.000641, trig_loss = 0.001678, rela_loss = 0.000000, bind_loss = 0.000000 (0.634 sec/batch), lr: 0.000100
2021-07-12 13:39:52.384506: step 8760/164800 (epoch 5/80),jp_loss = 0.005051, trig_loss = 0.003021, rela_loss = 0.000479, bind_loss = 0.000000 (0.974 sec/batch), lr: 0.000100
2021-07-12 13:40:33.661682: step 8780/164800 (epoch 5/80),jp_loss = 0.000977, trig_loss = 0.004150, rela_loss = 0.000002, bind_loss = 0.000000 (0.940 sec/batch), lr: 0.000100
2021-07-12 13:41:15.713379: step 8800/164800 (epoch 5/80),jp_loss = 0.003448, trig_loss = 5.525970, rela_loss = 0.002222, bind_loss = 0.000000 (3.694 sec/batch), lr: 0.000100
2021-07-12 13:41:58.097670: step 8820/164800 (epoch 5/80),jp_loss = 0.002258, trig_loss = 7.244354, rela_loss = 0.002316, bind_loss = 0.000000 (1.665 sec/batch), lr: 0.000100
2021-07-12 13:42:26.346272: step 8840/164800 (epoch 5/80),jp_loss = 0.004364, trig_loss = 0.004898, rela_loss = 0.098517, bind_loss = 0.000000 (2.078 sec/batch), lr: 0.000100
2021-07-12 13:42:56.113776: step 8860/164800 (epoch 5/80),jp_loss = 18.840363, trig_loss = 0.032196, rela_loss = 0.015470, bind_loss = 0.004975 (2.192 sec/batch), lr: 0.000100
2021-07-12 13:43:32.386181: step 8880/164800 (epoch 5/80),jp_loss = 8.398468, trig_loss = 0.213562, rela_loss = 0.000174, bind_loss = 0.000000 (1.747 sec/batch), lr: 0.000100
2021-07-12 13:44:00.516052: step 8900/164800 (epoch 5/80),jp_loss = 0.001831, trig_loss = 0.004089, rela_loss = 0.000016, bind_loss = 0.000000 (0.673 sec/batch), lr: 0.000100
2021-07-12 13:44:28.381821: step 8920/164800 (epoch 5/80),jp_loss = 0.005310, trig_loss = 0.012024, rela_loss = 0.048009, bind_loss = 0.000000 (1.211 sec/batch), lr: 0.000100
2021-07-12 13:44:57.842870: step 8940/164800 (epoch 5/80),jp_loss = 0.000519, trig_loss = 1.130234, rela_loss = 8.526989, bind_loss = 0.000000 (1.335 sec/batch), lr: 0.000100
2021-07-12 13:45:28.889100: step 8960/164800 (epoch 5/80),jp_loss = 0.001038, trig_loss = 0.002747, rela_loss = 0.000554, bind_loss = 0.000000 (1.005 sec/batch), lr: 0.000100
2021-07-12 13:45:58.795260: step 8980/164800 (epoch 5/80),jp_loss = 0.004486, trig_loss = 0.001373, rela_loss = 0.000001, bind_loss = 0.000000 (1.367 sec/batch), lr: 0.000100
2021-07-12 13:46:36.316056: step 9000/164800 (epoch 5/80),jp_loss = 0.001831, trig_loss = 0.007141, rela_loss = 0.000016, bind_loss = 0.000000 (0.994 sec/batch), lr: 0.000100
2021-07-12 13:47:13.188074: step 9020/164800 (epoch 5/80),jp_loss = 0.001831, trig_loss = 0.000427, rela_loss = 0.000008, bind_loss = 0.000000 (0.418 sec/batch), lr: 0.000100
2021-07-12 13:48:00.343988: step 9040/164800 (epoch 5/80),jp_loss = 0.001007, trig_loss = 0.001801, rela_loss = 0.000002, bind_loss = 0.000000 (0.985 sec/batch), lr: 0.000100
2021-07-12 13:48:32.343484: step 9060/164800 (epoch 5/80),jp_loss = 0.003403, trig_loss = 0.010590, rela_loss = 0.000011, bind_loss = 0.000000 (1.656 sec/batch), lr: 0.000100
2021-07-12 13:49:10.213078: step 9080/164800 (epoch 5/80),jp_loss = 0.072113, trig_loss = 0.014282, rela_loss = 0.000051, bind_loss = 0.397936 (5.028 sec/batch), lr: 0.000100
2021-07-12 13:49:38.543279: step 9100/164800 (epoch 5/80),jp_loss = 0.004608, trig_loss = 0.002502, rela_loss = 0.000137, bind_loss = 0.000000 (1.102 sec/batch), lr: 0.000100
2021-07-12 13:50:11.823665: step 9120/164800 (epoch 5/80),jp_loss = 0.002350, trig_loss = 0.020569, rela_loss = 0.003438, bind_loss = 0.000000 (3.294 sec/batch), lr: 0.000100
2021-07-12 13:50:39.441200: step 9140/164800 (epoch 5/80),jp_loss = 0.007286, trig_loss = 0.000793, rela_loss = 0.000017, bind_loss = 0.000000 (0.549 sec/batch), lr: 0.000100
2021-07-12 13:51:14.546139: step 9160/164800 (epoch 5/80),jp_loss = 0.000824, trig_loss = 0.001282, rela_loss = 0.000098, bind_loss = 0.000000 (0.781 sec/batch), lr: 0.000100
2021-07-12 13:51:54.076177: step 9180/164800 (epoch 5/80),jp_loss = 0.000763, trig_loss = 0.002747, rela_loss = 0.000041, bind_loss = 0.000000 (0.800 sec/batch), lr: 0.000100
2021-07-12 13:52:27.537697: step 9200/164800 (epoch 5/80),jp_loss = 0.003296, trig_loss = 0.003723, rela_loss = 0.000325, bind_loss = 0.000000 (2.465 sec/batch), lr: 0.000100
2021-07-12 13:53:01.012744: step 9220/164800 (epoch 5/80),jp_loss = 0.000580, trig_loss = 3.211639, rela_loss = 0.000020, bind_loss = 0.000000 (0.688 sec/batch), lr: 0.000100
2021-07-12 13:53:43.206090: step 9240/164800 (epoch 5/80),jp_loss = 0.297974, trig_loss = 0.002655, rela_loss = 0.001122, bind_loss = 0.000000 (1.117 sec/batch), lr: 0.000100
2021-07-12 13:54:18.200547: step 9260/164800 (epoch 5/80),jp_loss = 0.007050, trig_loss = 0.754608, rela_loss = 0.000097, bind_loss = 0.000000 (2.161 sec/batch), lr: 0.000100
2021-07-12 13:54:50.499571: step 9280/164800 (epoch 5/80),jp_loss = 0.025085, trig_loss = 1.332489, rela_loss = 0.000000, bind_loss = 0.000000 (1.316 sec/batch), lr: 0.000100
2021-07-12 13:55:18.255859: step 9300/164800 (epoch 5/80),jp_loss = 0.007965, trig_loss = 0.000519, rela_loss = 0.000055, bind_loss = 0.000000 (0.871 sec/batch), lr: 0.000100
2021-07-12 13:55:51.703896: step 9320/164800 (epoch 5/80),jp_loss = 0.001221, trig_loss = 0.006165, rela_loss = 0.000212, bind_loss = 0.000000 (1.563 sec/batch), lr: 0.000100
2021-07-12 13:56:16.088269: step 9340/164800 (epoch 5/80),jp_loss = 0.001251, trig_loss = 0.000763, rela_loss = 0.000157, bind_loss = 0.000683 (1.697 sec/batch), lr: 0.000100
2021-07-12 13:56:56.166769: step 9360/164800 (epoch 5/80),jp_loss = 0.002289, trig_loss = 0.001190, rela_loss = 0.000022, bind_loss = 0.000000 (1.081 sec/batch), lr: 0.000100
2021-07-12 13:57:31.333599: step 9380/164800 (epoch 5/80),jp_loss = 0.001266, trig_loss = 0.354385, rela_loss = 0.000001, bind_loss = 0.000000 (0.537 sec/batch), lr: 0.000100
2021-07-12 13:58:02.526081: step 9400/164800 (epoch 5/80),jp_loss = 0.001099, trig_loss = 0.001251, rela_loss = 0.000000, bind_loss = 0.127203 (0.704 sec/batch), lr: 0.000100
2021-07-12 13:58:30.672478: step 9420/164800 (epoch 5/80),jp_loss = 0.000885, trig_loss = 0.001862, rela_loss = 0.002405, bind_loss = 0.001093 (1.565 sec/batch), lr: 0.000100
2021-07-12 13:58:57.136797: step 9440/164800 (epoch 5/80),jp_loss = 0.000290, trig_loss = 0.000824, rela_loss = 0.000001, bind_loss = 0.000000 (0.472 sec/batch), lr: 0.000100
2021-07-12 13:59:27.897795: step 9460/164800 (epoch 5/80),jp_loss = 0.002563, trig_loss = 0.001343, rela_loss = 0.000002, bind_loss = 0.117109 (3.067 sec/batch), lr: 0.000100
2021-07-12 14:00:06.848825: step 9480/164800 (epoch 5/80),jp_loss = 0.006454, trig_loss = 7.686829, rela_loss = 0.000106, bind_loss = 0.000000 (3.261 sec/batch), lr: 0.000100
2021-07-12 14:00:38.291362: step 9500/164800 (epoch 5/80),jp_loss = 0.001022, trig_loss = 0.024384, rela_loss = 0.000207, bind_loss = 0.000000 (1.353 sec/batch), lr: 0.000100
2021-07-12 14:01:14.475978: step 9520/164800 (epoch 5/80),jp_loss = 0.001465, trig_loss = 0.009583, rela_loss = 0.000007, bind_loss = 0.001567 (2.128 sec/batch), lr: 0.000100
2021-07-12 14:01:43.337788: step 9540/164800 (epoch 5/80),jp_loss = 0.009827, trig_loss = 0.151917, rela_loss = 0.118562, bind_loss = 0.000000 (1.401 sec/batch), lr: 0.000100
2021-07-12 14:02:26.077696: step 9560/164800 (epoch 5/80),jp_loss = 0.007187, trig_loss = 19.864853, rela_loss = 2.746569, bind_loss = 0.000000 (3.010 sec/batch), lr: 0.000100
2021-07-12 14:02:52.646492: step 9580/164800 (epoch 5/80),jp_loss = 0.014221, trig_loss = 0.011353, rela_loss = 0.000007, bind_loss = 0.000000 (1.351 sec/batch), lr: 0.000100
2021-07-12 14:03:26.500501: step 9600/164800 (epoch 5/80),jp_loss = 0.052200, trig_loss = 0.015747, rela_loss = 0.000006, bind_loss = 0.000000 (1.004 sec/batch), lr: 0.000100
2021-07-12 14:04:07.354022: step 9620/164800 (epoch 5/80),jp_loss = 0.002350, trig_loss = 0.012695, rela_loss = 0.000004, bind_loss = 0.023243 (1.854 sec/batch), lr: 0.000100
2021-07-12 14:04:47.226495: step 9640/164800 (epoch 5/80),jp_loss = 0.002029, trig_loss = 10.774811, rela_loss = 0.000136, bind_loss = 0.000000 (1.443 sec/batch), lr: 0.000100
2021-07-12 14:05:15.242143: step 9660/164800 (epoch 5/80),jp_loss = 0.001175, trig_loss = 0.019867, rela_loss = 0.001373, bind_loss = 0.000000 (1.104 sec/batch), lr: 0.000100
2021-07-12 14:05:41.614232: step 9680/164800 (epoch 5/80),jp_loss = 0.000427, trig_loss = 0.002747, rela_loss = 0.000017, bind_loss = 0.000000 (1.624 sec/batch), lr: 0.000100
2021-07-12 14:06:07.097286: step 9700/164800 (epoch 5/80),jp_loss = 0.003098, trig_loss = 0.015442, rela_loss = 0.000803, bind_loss = 0.001534 (1.832 sec/batch), lr: 0.000100
2021-07-12 14:06:38.463283: step 9720/164800 (epoch 5/80),jp_loss = 0.001099, trig_loss = 0.013672, rela_loss = 0.000042, bind_loss = 0.000000 (2.157 sec/batch), lr: 0.000100
2021-07-12 14:07:07.871488: step 9740/164800 (epoch 5/80),jp_loss = 0.000412, trig_loss = 0.001862, rela_loss = 0.000003, bind_loss = 0.000000 (0.841 sec/batch), lr: 0.000100
2021-07-12 14:07:45.154449: step 9760/164800 (epoch 5/80),jp_loss = 0.001022, trig_loss = 0.004051, rela_loss = 0.000425, bind_loss = 0.000000 (0.883 sec/batch), lr: 0.000100
2021-07-12 14:08:06.358756: step 9780/164800 (epoch 5/80),jp_loss = 0.000580, trig_loss = 0.409088, rela_loss = 0.000244, bind_loss = 0.000000 (1.933 sec/batch), lr: 0.000100
2021-07-12 14:08:54.231526: step 9800/164800 (epoch 5/80),jp_loss = 0.001221, trig_loss = 0.008728, rela_loss = 0.043148, bind_loss = 0.000000 (3.444 sec/batch), lr: 0.000100
2021-07-12 14:09:22.536025: step 9820/164800 (epoch 5/80),jp_loss = 0.000626, trig_loss = 0.007568, rela_loss = 0.359736, bind_loss = 0.000000 (1.518 sec/batch), lr: 0.000100
2021-07-12 14:09:54.345025: step 9840/164800 (epoch 5/80),jp_loss = 0.000916, trig_loss = 0.003052, rela_loss = 0.000039, bind_loss = 0.000000 (1.679 sec/batch), lr: 0.000100
2021-07-12 14:10:21.576679: step 9860/164800 (epoch 5/80),jp_loss = 0.001022, trig_loss = 0.000885, rela_loss = 0.000000, bind_loss = 0.000000 (0.484 sec/batch), lr: 0.000100
2021-07-12 14:11:00.676615: step 9880/164800 (epoch 5/80),jp_loss = 0.001282, trig_loss = 0.012024, rela_loss = 0.000679, bind_loss = 0.000000 (1.996 sec/batch), lr: 0.000100
2021-07-12 14:11:35.000856: step 9900/164800 (epoch 5/80),jp_loss = 0.001862, trig_loss = 0.000977, rela_loss = 0.000016, bind_loss = 0.000000 (1.393 sec/batch), lr: 0.000100
2021-07-12 14:11:56.355493: step 9920/164800 (epoch 5/80),jp_loss = 0.001328, trig_loss = 0.006454, rela_loss = 0.000018, bind_loss = 0.000000 (1.037 sec/batch), lr: 0.000100
2021-07-12 14:12:24.167964: step 9940/164800 (epoch 5/80),jp_loss = 0.001160, trig_loss = 0.006012, rela_loss = 0.000026, bind_loss = 0.000000 (2.005 sec/batch), lr: 0.000100
2021-07-12 14:12:49.653752: step 9960/164800 (epoch 5/80),jp_loss = 0.000549, trig_loss = 0.001587, rela_loss = 0.000000, bind_loss = 0.000000 (0.780 sec/batch), lr: 0.000100
2021-07-12 14:13:20.198243: step 9980/164800 (epoch 5/80),jp_loss = 0.001740, trig_loss = 3.781723, rela_loss = 0.000003, bind_loss = 0.000000 (2.754 sec/batch), lr: 0.000100
2021-07-12 14:13:49.597479: step 10000/164800 (epoch 5/80),jp_loss = 0.001984, trig_loss = 0.315430, rela_loss = 0.006566, bind_loss = 0.000000 (1.738 sec/batch), lr: 0.000100
2021-07-12 14:14:21.752150: step 10020/164800 (epoch 5/80),jp_loss = 0.085815, trig_loss = 0.004761, rela_loss = 0.014436, bind_loss = 0.000000 (2.149 sec/batch), lr: 0.000100
2021-07-12 14:15:04.334831: step 10040/164800 (epoch 5/80),jp_loss = 0.003067, trig_loss = 0.005676, rela_loss = 0.009798, bind_loss = 0.001435 (3.382 sec/batch), lr: 0.000100
2021-07-12 14:15:33.580805: step 10060/164800 (epoch 5/80),jp_loss = 3.932617, trig_loss = 0.310730, rela_loss = 0.000112, bind_loss = 0.000000 (0.848 sec/batch), lr: 0.000100
2021-07-12 14:16:04.487540: step 10080/164800 (epoch 5/80),jp_loss = 20.674576, trig_loss = 0.006592, rela_loss = 1.836685, bind_loss = 0.000000 (3.430 sec/batch), lr: 0.000100
2021-07-12 14:16:51.370024: step 10100/164800 (epoch 5/80),jp_loss = 0.001160, trig_loss = 0.005737, rela_loss = 0.000328, bind_loss = 0.000000 (1.815 sec/batch), lr: 0.000100
2021-07-12 14:17:20.816357: step 10120/164800 (epoch 5/80),jp_loss = 0.003189, trig_loss = 0.017487, rela_loss = 0.067835, bind_loss = 0.000000 (2.361 sec/batch), lr: 0.000100
2021-07-12 14:18:09.418690: step 10140/164800 (epoch 5/80),jp_loss = 0.003052, trig_loss = 0.001556, rela_loss = 0.000019, bind_loss = 0.000000 (0.805 sec/batch), lr: 0.000100
2021-07-12 14:18:38.422453: step 10160/164800 (epoch 5/80),jp_loss = 0.005127, trig_loss = 1.026062, rela_loss = 0.013080, bind_loss = 0.000000 (4.260 sec/batch), lr: 0.000100
2021-07-12 14:19:10.688951: step 10180/164800 (epoch 5/80),jp_loss = 0.000931, trig_loss = 0.000671, rela_loss = 0.000000, bind_loss = 0.000000 (0.869 sec/batch), lr: 0.000100
2021-07-12 14:19:43.119054: step 10200/164800 (epoch 5/80),jp_loss = 0.002350, trig_loss = 5.665314, rela_loss = 0.000008, bind_loss = 0.003466 (4.206 sec/batch), lr: 0.000100
2021-07-12 14:20:10.718152: step 10220/164800 (epoch 5/80),jp_loss = 1.153671, trig_loss = 0.002106, rela_loss = 0.000000, bind_loss = 0.000000 (0.880 sec/batch), lr: 0.000100
2021-07-12 14:20:43.117416: step 10240/164800 (epoch 5/80),jp_loss = 0.004166, trig_loss = 0.020676, rela_loss = 0.000030, bind_loss = 0.000000 (1.978 sec/batch), lr: 0.000100
2021-07-12 14:21:12.945870: step 10260/164800 (epoch 5/80),jp_loss = 0.000305, trig_loss = 0.000916, rela_loss = 0.000005, bind_loss = 0.000000 (1.234 sec/batch), lr: 0.000100
2021-07-12 14:21:46.825034: step 10280/164800 (epoch 5/80),jp_loss = 0.001297, trig_loss = 0.001968, rela_loss = 0.017105, bind_loss = 0.000755 (1.585 sec/batch), lr: 0.000100
2021-07-12 14:22:18.034028: step 10300/164800 (epoch 5/80),jp_loss = 0.000519, trig_loss = 0.022797, rela_loss = 0.000001, bind_loss = 0.000000 (1.619 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  98.71%  R:  98.67%  F1:  98.69%  #: 2174

Final Score:
Precision (micro): 98.711%
   Recall (micro): 98.666%
       F1 (micro): 98.689%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  93.42%  R:  95.62%  F1:  94.51%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  97.32%  R:  95.60%  F1:  96.45%  #: 455
Localization         P:  96.72%  R:  99.44%  F1:  98.06%  #: 178
Negative_regulation  P:  94.15%  R:  95.49%  F1:  94.81%  #: 421
Phosphorylation      P:  95.62%  R:  98.71%  F1:  97.14%  #: 155
Positive_regulation  P:  93.11%  R:  90.59%  F1:  91.84%  #: 627
Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30
Regulation           P:  88.89%  R:  85.44%  F1:  87.13%  #: 206
Transcription        P:  63.64%  R:  83.58%  F1:  72.26%  #: 67

Final Score:
Precision (micro): 93.099%
   Recall (micro): 93.404%
       F1 (micro): 93.252%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  89.04%  R:  91.60%  F1:  90.30%  #: 488
Gene_expression      P:  96.63%  R:  93.47%  F1:  95.02%  #: 582
Localization         P:  94.82%  R:  95.31%  F1:  95.06%  #: 192
Negative_regulation  P:  87.85%  R:  86.11%  F1:  86.97%  #: 655
Phosphorylation      P:  95.00%  R:  96.45%  F1:  95.72%  #: 197
Positive_regulation  P:  84.95%  R:  80.72%  F1:  82.78%  #: 923
Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30
Regulation           P:  80.87%  R:  78.32%  F1:  79.57%  #: 286
Transcription        P:  63.30%  R:  77.53%  F1:  69.70%  #: 89

Final Score:
Precision (micro): 88.218%
   Recall (micro): 87.013%
       F1 (micro): 87.612%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  71.01%  R:  86.47%  F1:  77.98%  #: 170

Final Score:
Precision (micro): 71.014%
   Recall (micro): 86.471%
       F1 (micro): 77.984%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  72.70%  R:  83.00%  F1:  77.51%  #: 353

Gene_expression      P:  96.97%  R:  93.47%  F1:  95.19%  #: 582

Localization         P:  94.82%  R:  95.31%  F1:  95.06%  #: 192

Negative_regulation  P:  79.34%  R:  69.56%  F1:  74.13%  #: 519

Phosphorylation      P:  89.36%  R:  87.96%  F1:  88.65%  #: 191

Positive_regulation  P:  80.47%  R:  67.72%  F1:  73.55%  #: 852

Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30

Regulation           P:  73.49%  R:  58.74%  F1:  65.29%  #: 269

Transcription        P:  63.30%  R:  77.53%  F1:  69.70%  #: 89

Final Score:
Precision (micro): 82.910%
   Recall (micro): 77.413%
       F1 (micro): 80.067%
epoch 5: train_loss = 0.254645, dev_loss = 0.000000, dev_rela_f1 = 0.8007
0.800672268907563 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_5.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.800672268907563 ---- 5

2021-07-12 14:34:40.948015: step 10320/164800 (epoch 6/80),jp_loss = 0.002563, trig_loss = 1.800171, rela_loss = 0.008731, bind_loss = 0.000000 (2.341 sec/batch), lr: 0.000100
2021-07-12 14:35:17.131598: step 10340/164800 (epoch 6/80),jp_loss = 0.000641, trig_loss = 19.177582, rela_loss = 2.637643, bind_loss = 0.000000 (1.127 sec/batch), lr: 0.000100
2021-07-12 14:36:02.484283: step 10360/164800 (epoch 6/80),jp_loss = 0.017593, trig_loss = 0.001160, rela_loss = 0.000009, bind_loss = 0.000000 (0.817 sec/batch), lr: 0.000100
2021-07-12 14:36:31.619468: step 10380/164800 (epoch 6/80),jp_loss = 0.001175, trig_loss = 0.028015, rela_loss = 0.000208, bind_loss = 0.000000 (0.755 sec/batch), lr: 0.000100
2021-07-12 14:37:13.683231: step 10400/164800 (epoch 6/80),jp_loss = 0.001053, trig_loss = 0.014755, rela_loss = 0.000002, bind_loss = 0.000000 (0.845 sec/batch), lr: 0.000100
2021-07-12 14:37:47.646443: step 10420/164800 (epoch 6/80),jp_loss = 0.001465, trig_loss = 0.001465, rela_loss = 0.000013, bind_loss = 0.000000 (1.852 sec/batch), lr: 0.000100
2021-07-12 14:38:27.031354: step 10440/164800 (epoch 6/80),jp_loss = 0.000717, trig_loss = 0.000557, rela_loss = 0.000575, bind_loss = 0.000577 (0.694 sec/batch), lr: 0.000100
2021-07-12 14:38:54.700296: step 10460/164800 (epoch 6/80),jp_loss = 0.001373, trig_loss = 0.001083, rela_loss = 0.000049, bind_loss = 0.000000 (0.851 sec/batch), lr: 0.000100
2021-07-12 14:39:30.939210: step 10480/164800 (epoch 6/80),jp_loss = 0.001816, trig_loss = 4.143372, rela_loss = 0.202262, bind_loss = 0.000000 (1.492 sec/batch), lr: 0.000100
2021-07-12 14:39:58.952316: step 10500/164800 (epoch 6/80),jp_loss = 0.001846, trig_loss = 0.120132, rela_loss = 1.704500, bind_loss = 0.000000 (2.168 sec/batch), lr: 0.000100
2021-07-12 14:40:30.016353: step 10520/164800 (epoch 6/80),jp_loss = 0.000336, trig_loss = 0.429871, rela_loss = 0.004908, bind_loss = 0.000000 (0.819 sec/batch), lr: 0.000100
2021-07-12 14:41:10.990973: step 10540/164800 (epoch 6/80),jp_loss = 0.002548, trig_loss = 0.001190, rela_loss = 0.000001, bind_loss = 0.000000 (0.913 sec/batch), lr: 0.000100
2021-07-12 14:41:41.440076: step 10560/164800 (epoch 6/80),jp_loss = 0.001038, trig_loss = 0.001221, rela_loss = 0.000005, bind_loss = 0.000000 (1.397 sec/batch), lr: 0.000100
2021-07-12 14:42:18.710081: step 10580/164800 (epoch 6/80),jp_loss = 0.001801, trig_loss = 0.003448, rela_loss = 0.000049, bind_loss = 0.000000 (0.492 sec/batch), lr: 0.000100
2021-07-12 14:42:55.120729: step 10600/164800 (epoch 6/80),jp_loss = 0.000427, trig_loss = 0.001160, rela_loss = 0.000001, bind_loss = 0.000000 (0.682 sec/batch), lr: 0.000100
2021-07-12 14:43:26.884604: step 10620/164800 (epoch 6/80),jp_loss = 0.001389, trig_loss = 0.778473, rela_loss = 0.018033, bind_loss = 0.000000 (1.255 sec/batch), lr: 0.000100
2021-07-12 14:44:03.034456: step 10640/164800 (epoch 6/80),jp_loss = 0.000839, trig_loss = 0.020355, rela_loss = 0.000000, bind_loss = 0.000000 (0.737 sec/batch), lr: 0.000100
2021-07-12 14:44:39.638957: step 10660/164800 (epoch 6/80),jp_loss = 0.006790, trig_loss = 1.802582, rela_loss = 0.000021, bind_loss = 0.000000 (0.832 sec/batch), lr: 0.000100
2021-07-12 14:45:03.353142: step 10680/164800 (epoch 6/80),jp_loss = 9.441269, trig_loss = 3.853943, rela_loss = 0.000952, bind_loss = 0.004460 (1.922 sec/batch), lr: 0.000100
2021-07-12 14:45:27.738201: step 10700/164800 (epoch 6/80),jp_loss = 0.057877, trig_loss = 0.002106, rela_loss = 0.000010, bind_loss = 0.000000 (0.805 sec/batch), lr: 0.000100
2021-07-12 14:46:09.636668: step 10720/164800 (epoch 6/80),jp_loss = 0.002655, trig_loss = 3.365662, rela_loss = 0.176155, bind_loss = 0.000000 (2.559 sec/batch), lr: 0.000100
2021-07-12 14:46:39.282920: step 10740/164800 (epoch 6/80),jp_loss = 0.007599, trig_loss = 1.486389, rela_loss = 0.103855, bind_loss = 0.000000 (1.013 sec/batch), lr: 0.000100
2021-07-12 14:47:06.207453: step 10760/164800 (epoch 6/80),jp_loss = 0.003334, trig_loss = 1.590446, rela_loss = 0.004812, bind_loss = 0.001092 (1.256 sec/batch), lr: 0.000100
2021-07-12 14:47:58.919041: step 10780/164800 (epoch 6/80),jp_loss = 10.320801, trig_loss = 8.726562, rela_loss = 0.002051, bind_loss = 0.000000 (6.706 sec/batch), lr: 0.000100
2021-07-12 14:48:26.140729: step 10800/164800 (epoch 6/80),jp_loss = 0.000656, trig_loss = 0.001862, rela_loss = 0.000150, bind_loss = 0.000000 (0.746 sec/batch), lr: 0.000100
2021-07-12 14:48:58.465395: step 10820/164800 (epoch 6/80),jp_loss = 0.001648, trig_loss = 0.001495, rela_loss = 0.765580, bind_loss = 0.000000 (1.041 sec/batch), lr: 0.000100
2021-07-12 14:49:40.196854: step 10840/164800 (epoch 6/80),jp_loss = 0.000397, trig_loss = 0.001099, rela_loss = 0.000006, bind_loss = 0.000000 (0.970 sec/batch), lr: 0.000100
2021-07-12 14:50:20.391252: step 10860/164800 (epoch 6/80),jp_loss = 5.802429, trig_loss = 12.908356, rela_loss = 0.219756, bind_loss = 0.000000 (3.908 sec/batch), lr: 0.000100
2021-07-12 14:51:01.934209: step 10880/164800 (epoch 6/80),jp_loss = 0.001984, trig_loss = 4.904327, rela_loss = 0.000327, bind_loss = 0.000000 (1.827 sec/batch), lr: 0.000100
2021-07-12 14:51:30.297535: step 10900/164800 (epoch 6/80),jp_loss = 0.003693, trig_loss = 0.022095, rela_loss = 0.003678, bind_loss = 0.000000 (1.806 sec/batch), lr: 0.000100
2021-07-12 14:52:00.783446: step 10920/164800 (epoch 6/80),jp_loss = 5.641174, trig_loss = 1.456543, rela_loss = 0.000451, bind_loss = 0.001337 (2.372 sec/batch), lr: 0.000100
2021-07-12 14:52:37.054258: step 10940/164800 (epoch 6/80),jp_loss = 0.002045, trig_loss = 0.026123, rela_loss = 0.000047, bind_loss = 0.000000 (1.747 sec/batch), lr: 0.000100
2021-07-12 14:53:04.499702: step 10960/164800 (epoch 6/80),jp_loss = 0.001373, trig_loss = 0.000793, rela_loss = 0.000002, bind_loss = 0.000000 (0.745 sec/batch), lr: 0.000100
2021-07-12 14:53:32.636905: step 10980/164800 (epoch 6/80),jp_loss = 0.116745, trig_loss = 0.007019, rela_loss = 0.005890, bind_loss = 0.000000 (1.278 sec/batch), lr: 0.000100
2021-07-12 14:54:03.475934: step 11000/164800 (epoch 6/80),jp_loss = 0.000641, trig_loss = 0.089935, rela_loss = 7.697521, bind_loss = 0.000000 (1.332 sec/batch), lr: 0.000100
2021-07-12 14:54:35.456400: step 11020/164800 (epoch 6/80),jp_loss = 0.000999, trig_loss = 0.007782, rela_loss = 0.000100, bind_loss = 0.000000 (0.710 sec/batch), lr: 0.000100
2021-07-12 14:55:05.693495: step 11040/164800 (epoch 6/80),jp_loss = 0.014008, trig_loss = 0.019989, rela_loss = 0.000063, bind_loss = 0.000000 (1.627 sec/batch), lr: 0.000100
2021-07-12 14:55:42.209165: step 11060/164800 (epoch 6/80),jp_loss = 0.000763, trig_loss = 0.860474, rela_loss = 0.000088, bind_loss = 0.000000 (0.958 sec/batch), lr: 0.000100
2021-07-12 14:56:19.979547: step 11080/164800 (epoch 6/80),jp_loss = 0.000488, trig_loss = 0.001114, rela_loss = 0.000001, bind_loss = 0.000000 (0.424 sec/batch), lr: 0.000100
2021-07-12 14:57:07.263815: step 11100/164800 (epoch 6/80),jp_loss = 0.000504, trig_loss = 0.021118, rela_loss = 0.000009, bind_loss = 0.000000 (1.033 sec/batch), lr: 0.000100
2021-07-12 14:57:39.418734: step 11120/164800 (epoch 6/80),jp_loss = 0.002228, trig_loss = 2.289154, rela_loss = 0.000012, bind_loss = 0.000000 (1.810 sec/batch), lr: 0.000100
2021-07-12 14:58:17.786798: step 11140/164800 (epoch 6/80),jp_loss = 0.011932, trig_loss = 0.005493, rela_loss = 0.000041, bind_loss = 0.267368 (5.134 sec/batch), lr: 0.000100
2021-07-12 14:58:47.916576: step 11160/164800 (epoch 6/80),jp_loss = 0.000916, trig_loss = 0.000671, rela_loss = 0.000119, bind_loss = 0.000000 (1.004 sec/batch), lr: 0.000100
2021-07-12 14:59:20.009544: step 11180/164800 (epoch 6/80),jp_loss = 0.001801, trig_loss = 0.076660, rela_loss = 0.022244, bind_loss = 0.000000 (3.244 sec/batch), lr: 0.000100
2021-07-12 14:59:48.352008: step 11200/164800 (epoch 6/80),jp_loss = 0.001686, trig_loss = 0.001099, rela_loss = 0.000001, bind_loss = 0.000000 (0.602 sec/batch), lr: 0.000100
2021-07-12 15:00:24.763260: step 11220/164800 (epoch 6/80),jp_loss = 0.000732, trig_loss = 0.001282, rela_loss = 0.000063, bind_loss = 0.000000 (0.845 sec/batch), lr: 0.000100
2021-07-12 15:01:04.082549: step 11240/164800 (epoch 6/80),jp_loss = 0.000122, trig_loss = 0.001404, rela_loss = 0.000004, bind_loss = 0.000000 (0.735 sec/batch), lr: 0.000100
2021-07-12 15:01:37.674212: step 11260/164800 (epoch 6/80),jp_loss = 0.003281, trig_loss = 0.005859, rela_loss = 0.001515, bind_loss = 0.000000 (2.493 sec/batch), lr: 0.000100
2021-07-12 15:02:12.720088: step 11280/164800 (epoch 6/80),jp_loss = 0.000275, trig_loss = 0.928345, rela_loss = 0.000043, bind_loss = 0.000000 (0.636 sec/batch), lr: 0.000100
2021-07-12 15:02:53.426694: step 11300/164800 (epoch 6/80),jp_loss = 0.103394, trig_loss = 0.002502, rela_loss = 0.000413, bind_loss = 0.000000 (1.111 sec/batch), lr: 0.000100
2021-07-12 15:03:28.556795: step 11320/164800 (epoch 6/80),jp_loss = 0.000854, trig_loss = 2.500275, rela_loss = 0.000059, bind_loss = 0.000000 (2.220 sec/batch), lr: 0.000100
2021-07-12 15:04:01.250923: step 11340/164800 (epoch 6/80),jp_loss = 0.004227, trig_loss = 0.001312, rela_loss = 0.000001, bind_loss = 0.000000 (1.426 sec/batch), lr: 0.000100
2021-07-12 15:04:28.506231: step 11360/164800 (epoch 6/80),jp_loss = 0.000763, trig_loss = 0.000732, rela_loss = 0.000016, bind_loss = 0.000000 (0.915 sec/batch), lr: 0.000100
2021-07-12 15:05:01.267702: step 11380/164800 (epoch 6/80),jp_loss = 0.000305, trig_loss = 0.004211, rela_loss = 0.000089, bind_loss = 0.000000 (1.324 sec/batch), lr: 0.000100
2021-07-12 15:05:26.241506: step 11400/164800 (epoch 6/80),jp_loss = 0.003357, trig_loss = 0.002747, rela_loss = 0.000151, bind_loss = 0.000581 (1.797 sec/batch), lr: 0.000100
2021-07-12 15:06:05.440060: step 11420/164800 (epoch 6/80),jp_loss = 0.001007, trig_loss = 0.001144, rela_loss = 0.001009, bind_loss = 0.000000 (1.132 sec/batch), lr: 0.000100
2021-07-12 15:06:41.482180: step 11440/164800 (epoch 6/80),jp_loss = 0.000229, trig_loss = 0.002121, rela_loss = 0.052468, bind_loss = 0.000000 (0.683 sec/batch), lr: 0.000100
2021-07-12 15:07:12.829536: step 11460/164800 (epoch 6/80),jp_loss = 0.000504, trig_loss = 0.000992, rela_loss = 0.023973, bind_loss = 0.199975 (0.839 sec/batch), lr: 0.000100
2021-07-12 15:07:40.783726: step 11480/164800 (epoch 6/80),jp_loss = 0.000885, trig_loss = 0.003967, rela_loss = 0.000030, bind_loss = 0.000226 (1.640 sec/batch), lr: 0.000100
2021-07-12 15:08:08.097673: step 11500/164800 (epoch 6/80),jp_loss = 0.000626, trig_loss = 0.000687, rela_loss = 0.000004, bind_loss = 0.000000 (0.464 sec/batch), lr: 0.000100
2021-07-12 15:08:38.843353: step 11520/164800 (epoch 6/80),jp_loss = 0.001709, trig_loss = 0.000977, rela_loss = 0.000001, bind_loss = 0.107246 (3.090 sec/batch), lr: 0.000100
2021-07-12 15:09:18.619541: step 11540/164800 (epoch 6/80),jp_loss = 3.706947, trig_loss = 2.403870, rela_loss = 0.000390, bind_loss = 0.000000 (2.880 sec/batch), lr: 0.000100
2021-07-12 15:09:51.007607: step 11560/164800 (epoch 6/80),jp_loss = 0.001343, trig_loss = 0.029633, rela_loss = 0.000582, bind_loss = 0.000000 (1.373 sec/batch), lr: 0.000100
2021-07-12 15:10:27.633973: step 11580/164800 (epoch 6/80),jp_loss = 0.000854, trig_loss = 0.001251, rela_loss = 0.000002, bind_loss = 0.000871 (1.955 sec/batch), lr: 0.000100
2021-07-12 15:10:56.361748: step 11600/164800 (epoch 6/80),jp_loss = 0.000549, trig_loss = 0.007538, rela_loss = 0.000394, bind_loss = 0.000000 (1.365 sec/batch), lr: 0.000100
2021-07-12 15:11:40.978426: step 11620/164800 (epoch 6/80),jp_loss = 0.000885, trig_loss = 15.817139, rela_loss = 0.000703, bind_loss = 0.000000 (2.800 sec/batch), lr: 0.000100
2021-07-12 15:12:08.935603: step 11640/164800 (epoch 6/80),jp_loss = 0.000565, trig_loss = 2.229401, rela_loss = 0.000005, bind_loss = 0.000000 (1.357 sec/batch), lr: 0.000100
2021-07-12 15:12:43.408529: step 11660/164800 (epoch 6/80),jp_loss = 0.000397, trig_loss = 0.004913, rela_loss = 0.000868, bind_loss = 0.000000 (0.901 sec/batch), lr: 0.000100
2021-07-12 15:13:25.523849: step 11680/164800 (epoch 6/80),jp_loss = 0.002808, trig_loss = 0.001801, rela_loss = 0.000000, bind_loss = 0.160481 (2.242 sec/batch), lr: 0.000100
2021-07-12 15:14:05.643866: step 11700/164800 (epoch 6/80),jp_loss = 0.000824, trig_loss = 2.629684, rela_loss = 1.807056, bind_loss = 0.000000 (1.430 sec/batch), lr: 0.000100
2021-07-12 15:14:34.725569: step 11720/164800 (epoch 6/80),jp_loss = 0.001099, trig_loss = 0.066162, rela_loss = 0.000024, bind_loss = 0.000000 (1.146 sec/batch), lr: 0.000100
2021-07-12 15:15:01.053356: step 11740/164800 (epoch 6/80),jp_loss = 0.000366, trig_loss = 0.001953, rela_loss = 0.000002, bind_loss = 0.000000 (1.752 sec/batch), lr: 0.000100
2021-07-12 15:15:26.904999: step 11760/164800 (epoch 6/80),jp_loss = 0.002762, trig_loss = 0.007050, rela_loss = 0.066987, bind_loss = 0.002059 (1.773 sec/batch), lr: 0.000100
2021-07-12 15:15:58.168039: step 11780/164800 (epoch 6/80),jp_loss = 0.000763, trig_loss = 0.002991, rela_loss = 0.000140, bind_loss = 0.000000 (2.039 sec/batch), lr: 0.000100
2021-07-12 15:16:29.026796: step 11800/164800 (epoch 6/80),jp_loss = 0.001511, trig_loss = 0.001190, rela_loss = 0.000003, bind_loss = 0.000000 (0.702 sec/batch), lr: 0.000100
2021-07-12 15:17:06.084812: step 11820/164800 (epoch 6/80),jp_loss = 0.003490, trig_loss = 0.022621, rela_loss = 0.000027, bind_loss = 0.000000 (0.892 sec/batch), lr: 0.000100
2021-07-12 15:17:29.168005: step 11840/164800 (epoch 6/80),jp_loss = 0.001221, trig_loss = 0.589569, rela_loss = 0.512472, bind_loss = 0.000000 (1.961 sec/batch), lr: 0.000100
2021-07-12 15:18:15.289743: step 11860/164800 (epoch 6/80),jp_loss = 0.001953, trig_loss = 0.003967, rela_loss = 1.183839, bind_loss = 0.000000 (3.429 sec/batch), lr: 0.000100
2021-07-12 15:18:43.171444: step 11880/164800 (epoch 6/80),jp_loss = 0.000656, trig_loss = 0.002258, rela_loss = 0.000057, bind_loss = 0.000000 (1.523 sec/batch), lr: 0.000100
2021-07-12 15:19:14.012813: step 11900/164800 (epoch 6/80),jp_loss = 0.001083, trig_loss = 0.003448, rela_loss = 0.000036, bind_loss = 0.000000 (1.731 sec/batch), lr: 0.000100
2021-07-12 15:19:40.020110: step 11920/164800 (epoch 6/80),jp_loss = 0.002060, trig_loss = 0.000610, rela_loss = 0.000001, bind_loss = 0.000000 (0.446 sec/batch), lr: 0.000100
2021-07-12 15:20:19.610427: step 11940/164800 (epoch 6/80),jp_loss = 0.024933, trig_loss = 0.027130, rela_loss = 0.000773, bind_loss = 0.000000 (2.006 sec/batch), lr: 0.000100
2021-07-12 15:20:53.336707: step 11960/164800 (epoch 6/80),jp_loss = 0.004181, trig_loss = 0.000580, rela_loss = 0.000242, bind_loss = 0.000000 (1.353 sec/batch), lr: 0.000100
2021-07-12 15:21:15.134457: step 11980/164800 (epoch 6/80),jp_loss = 0.004150, trig_loss = 0.008743, rela_loss = 0.000053, bind_loss = 0.000000 (1.042 sec/batch), lr: 0.000100
2021-07-12 15:21:41.847271: step 12000/164800 (epoch 6/80),jp_loss = 0.001984, trig_loss = 0.005981, rela_loss = 0.000014, bind_loss = 0.000000 (1.744 sec/batch), lr: 0.000100
2021-07-12 15:22:07.251217: step 12020/164800 (epoch 6/80),jp_loss = 0.001923, trig_loss = 0.004608, rela_loss = 0.000000, bind_loss = 0.000000 (0.698 sec/batch), lr: 0.000100
2021-07-12 15:22:37.364650: step 12040/164800 (epoch 6/80),jp_loss = 0.002213, trig_loss = 0.032135, rela_loss = 0.000009, bind_loss = 0.000000 (2.687 sec/batch), lr: 0.000100
2021-07-12 15:23:05.153678: step 12060/164800 (epoch 6/80),jp_loss = 0.002106, trig_loss = 0.001923, rela_loss = 0.000685, bind_loss = 0.000000 (1.801 sec/batch), lr: 0.000100
2021-07-12 15:23:37.186080: step 12080/164800 (epoch 6/80),jp_loss = 0.001648, trig_loss = 7.171509, rela_loss = 0.000095, bind_loss = 0.000000 (1.880 sec/batch), lr: 0.000100
2021-07-12 15:24:18.476611: step 12100/164800 (epoch 6/80),jp_loss = 0.004120, trig_loss = 0.021164, rela_loss = 0.000613, bind_loss = 0.000239 (3.324 sec/batch), lr: 0.000100
2021-07-12 15:24:47.035987: step 12120/164800 (epoch 6/80),jp_loss = 0.013580, trig_loss = 7.326691, rela_loss = 0.000010, bind_loss = 0.000000 (0.860 sec/batch), lr: 0.000100
2021-07-12 15:25:17.013259: step 12140/164800 (epoch 6/80),jp_loss = 0.311432, trig_loss = 0.103607, rela_loss = 0.912276, bind_loss = 0.000000 (3.495 sec/batch), lr: 0.000100
2021-07-12 15:26:02.799013: step 12160/164800 (epoch 6/80),jp_loss = 0.003876, trig_loss = 0.042786, rela_loss = 0.000000, bind_loss = 0.000000 (1.893 sec/batch), lr: 0.000100
2021-07-12 15:26:32.019415: step 12180/164800 (epoch 6/80),jp_loss = 0.001389, trig_loss = 0.438950, rela_loss = 1.577951, bind_loss = 0.000000 (2.173 sec/batch), lr: 0.000100
2021-07-12 15:27:20.206573: step 12200/164800 (epoch 6/80),jp_loss = 0.000763, trig_loss = 0.000946, rela_loss = 0.001264, bind_loss = 0.000000 (0.729 sec/batch), lr: 0.000100
2021-07-12 15:27:48.788707: step 12220/164800 (epoch 6/80),jp_loss = 0.006104, trig_loss = 6.651489, rela_loss = 0.024491, bind_loss = 0.000000 (4.372 sec/batch), lr: 0.000100
2021-07-12 15:28:22.622381: step 12240/164800 (epoch 6/80),jp_loss = 0.000778, trig_loss = 0.001129, rela_loss = 0.000036, bind_loss = 0.000000 (0.892 sec/batch), lr: 0.000100
2021-07-12 15:28:53.701144: step 12260/164800 (epoch 6/80),jp_loss = 9.692413, trig_loss = 17.833679, rela_loss = 0.000002, bind_loss = 0.000690 (3.782 sec/batch), lr: 0.000100
2021-07-12 15:29:21.358998: step 12280/164800 (epoch 6/80),jp_loss = 1.142914, trig_loss = 0.000427, rela_loss = 0.000012, bind_loss = 0.000000 (1.004 sec/batch), lr: 0.000100
2021-07-12 15:29:54.581067: step 12300/164800 (epoch 6/80),jp_loss = 0.002594, trig_loss = 0.040268, rela_loss = 0.000005, bind_loss = 0.000000 (1.648 sec/batch), lr: 0.000100
2021-07-12 15:30:23.538436: step 12320/164800 (epoch 6/80),jp_loss = 0.000702, trig_loss = 0.000427, rela_loss = 0.000004, bind_loss = 0.000000 (1.384 sec/batch), lr: 0.000100
2021-07-12 15:30:55.774635: step 12340/164800 (epoch 6/80),jp_loss = 3.389709, trig_loss = 0.000671, rela_loss = 0.000342, bind_loss = 0.000942 (1.553 sec/batch), lr: 0.000100
2021-07-12 15:31:27.422626: step 12360/164800 (epoch 6/80),jp_loss = 0.000732, trig_loss = 0.006348, rela_loss = 0.000139, bind_loss = 0.000000 (1.433 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  98.13%  R:  98.94%  F1:  98.53%  #: 2174

Final Score:
Precision (micro): 98.130%
   Recall (micro): 98.942%
       F1 (micro): 98.534%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  91.59%  R:  95.29%  F1:  93.40%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  94.47%  R:  97.58%  F1:  96.00%  #: 455
Localization         P:  98.33%  R:  99.44%  F1:  98.88%  #: 178
Negative_regulation  P:  93.90%  R:  95.01%  F1:  94.45%  #: 421
Phosphorylation      P:  96.23%  R:  98.71%  F1:  97.45%  #: 155
Positive_regulation  P:  94.66%  R:  93.30%  F1:  93.98%  #: 627
Protein_catabolism   P:  87.88%  R:  96.67%  F1:  92.06%  #: 30
Regulation           P:  90.45%  R:  87.38%  F1:  88.89%  #: 206
Transcription        P:  90.00%  R:  80.60%  F1:  85.04%  #: 67

Final Score:
Precision (micro): 93.928%
   Recall (micro): 94.429%
       F1 (micro): 94.178%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  90.52%  R:  90.14%  F1:  90.33%  #: 487
Gene_expression      P:  93.67%  R:  96.90%  F1:  95.25%  #: 580
Localization         P:  95.81%  R:  95.31%  F1:  95.56%  #: 192
Negative_regulation  P:  86.41%  R:  89.31%  F1:  87.84%  #: 655
Phosphorylation      P:  94.03%  R:  95.94%  F1:  94.97%  #: 197
Positive_regulation  P:  86.34%  R:  84.94%  F1:  85.64%  #: 923
Protein_catabolism   P:  87.50%  R:  93.33%  F1:  90.32%  #: 30
Regulation           P:  81.31%  R:  82.17%  F1:  81.74%  #: 286
Transcription        P:  92.31%  R:  80.90%  F1:  86.23%  #: 89

Final Score:
Precision (micro): 88.905%
   Recall (micro): 89.474%
       F1 (micro): 89.188%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  82.56%  R:  82.08%  F1:  82.32%  #: 173

Final Score:
Precision (micro): 82.558%
   Recall (micro): 82.081%
       F1 (micro): 82.319%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  78.14%  R:  81.25%  F1:  79.67%  #: 352

Gene_expression      P:  94.14%  R:  96.90%  F1:  95.50%  #: 580

Localization         P:  95.81%  R:  95.31%  F1:  95.56%  #: 192

Negative_regulation  P:  79.57%  R:  70.52%  F1:  74.77%  #: 519

Phosphorylation      P:  88.24%  R:  86.39%  F1:  87.30%  #: 191

Positive_regulation  P:  83.38%  R:  65.38%  F1:  73.29%  #: 852

Protein_catabolism   P:  93.33%  R:  93.33%  F1:  93.33%  #: 30

Regulation           P:  76.13%  R:  62.83%  F1:  68.84%  #: 269

Transcription        P:  92.31%  R:  80.90%  F1:  86.23%  #: 89

Final Score:
Precision (micro): 85.316%
   Recall (micro): 77.684%
       F1 (micro): 81.321%
epoch 6: train_loss = 0.214402, dev_loss = 0.000000, dev_rela_f1 = 0.8132
0.8132130086838073 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_6.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8132130086838073 ---- 6

2021-07-12 15:44:01.475200: step 12380/164800 (epoch 7/80),jp_loss = 0.001556, trig_loss = 0.027649, rela_loss = 0.010301, bind_loss = 0.000000 (2.236 sec/batch), lr: 0.000100
2021-07-12 15:44:37.856663: step 12400/164800 (epoch 7/80),jp_loss = 0.000397, trig_loss = 21.913574, rela_loss = 1.848164, bind_loss = 0.000000 (1.156 sec/batch), lr: 0.000100
2021-07-12 15:45:23.606335: step 12420/164800 (epoch 7/80),jp_loss = 0.002045, trig_loss = 0.003479, rela_loss = 0.000002, bind_loss = 0.000000 (0.822 sec/batch), lr: 0.000100
2021-07-12 15:45:54.301996: step 12440/164800 (epoch 7/80),jp_loss = 0.028381, trig_loss = 0.006409, rela_loss = 0.000000, bind_loss = 0.000000 (0.762 sec/batch), lr: 0.000100
2021-07-12 15:46:37.029620: step 12460/164800 (epoch 7/80),jp_loss = 0.000427, trig_loss = 3.988495, rela_loss = 0.000007, bind_loss = 0.000000 (0.809 sec/batch), lr: 0.000100
2021-07-12 15:47:12.223299: step 12480/164800 (epoch 7/80),jp_loss = 0.001099, trig_loss = 0.000244, rela_loss = 0.000125, bind_loss = 0.000000 (1.794 sec/batch), lr: 0.000100
2021-07-12 15:47:51.275995: step 12500/164800 (epoch 7/80),jp_loss = 0.000610, trig_loss = 0.000427, rela_loss = 0.000010, bind_loss = 0.001189 (0.731 sec/batch), lr: 0.000100
2021-07-12 15:48:19.240071: step 12520/164800 (epoch 7/80),jp_loss = 0.000427, trig_loss = 0.000717, rela_loss = 0.000010, bind_loss = 0.000000 (1.027 sec/batch), lr: 0.000100
2021-07-12 15:48:56.473416: step 12540/164800 (epoch 7/80),jp_loss = 0.003983, trig_loss = 5.614594, rela_loss = 1.422179, bind_loss = 0.000000 (1.492 sec/batch), lr: 0.000100
2021-07-12 15:49:23.512186: step 12560/164800 (epoch 7/80),jp_loss = 6.353348, trig_loss = 7.891678, rela_loss = 1.400352, bind_loss = 0.000000 (1.530 sec/batch), lr: 0.000100
2021-07-12 15:49:55.334491: step 12580/164800 (epoch 7/80),jp_loss = 0.000992, trig_loss = 0.065018, rela_loss = 0.000376, bind_loss = 0.000000 (0.799 sec/batch), lr: 0.000100
2021-07-12 15:50:36.939057: step 12600/164800 (epoch 7/80),jp_loss = 0.001328, trig_loss = 0.000732, rela_loss = 0.000004, bind_loss = 0.000000 (0.885 sec/batch), lr: 0.000100
2021-07-12 15:51:08.442022: step 12620/164800 (epoch 7/80),jp_loss = 0.000977, trig_loss = 0.000244, rela_loss = 0.000011, bind_loss = 0.000000 (1.863 sec/batch), lr: 0.000100
2021-07-12 15:51:47.935016: step 12640/164800 (epoch 7/80),jp_loss = 0.000397, trig_loss = 0.002731, rela_loss = 0.000036, bind_loss = 0.000000 (0.717 sec/batch), lr: 0.000100
2021-07-12 15:52:24.336781: step 12660/164800 (epoch 7/80),jp_loss = 0.013397, trig_loss = 0.000397, rela_loss = 0.000004, bind_loss = 0.000000 (0.610 sec/batch), lr: 0.000100
2021-07-12 15:52:57.132765: step 12680/164800 (epoch 7/80),jp_loss = 0.015198, trig_loss = 0.674622, rela_loss = 0.398645, bind_loss = 0.000000 (1.205 sec/batch), lr: 0.000100
2021-07-12 15:53:31.540073: step 12700/164800 (epoch 7/80),jp_loss = 0.001389, trig_loss = 0.000183, rela_loss = 0.000001, bind_loss = 0.000000 (0.640 sec/batch), lr: 0.000100
2021-07-12 15:54:08.230083: step 12720/164800 (epoch 7/80),jp_loss = 0.000641, trig_loss = 0.037964, rela_loss = 0.000491, bind_loss = 0.000000 (0.846 sec/batch), lr: 0.000100
2021-07-12 15:54:31.805380: step 12740/164800 (epoch 7/80),jp_loss = 1.842133, trig_loss = 4.186035, rela_loss = 0.000066, bind_loss = 0.000638 (1.943 sec/batch), lr: 0.000100
2021-07-12 15:54:55.792704: step 12760/164800 (epoch 7/80),jp_loss = 0.000671, trig_loss = 0.000427, rela_loss = 0.000402, bind_loss = 0.000000 (0.754 sec/batch), lr: 0.000100
2021-07-12 15:55:38.101922: step 12780/164800 (epoch 7/80),jp_loss = 0.001068, trig_loss = 0.055298, rela_loss = 1.084693, bind_loss = 0.000000 (2.426 sec/batch), lr: 0.000100
2021-07-12 15:56:08.367994: step 12800/164800 (epoch 7/80),jp_loss = 0.001465, trig_loss = 0.030457, rela_loss = 0.000001, bind_loss = 0.000000 (1.002 sec/batch), lr: 0.000100
2021-07-12 15:56:34.744220: step 12820/164800 (epoch 7/80),jp_loss = 0.002884, trig_loss = 0.002708, rela_loss = 0.219981, bind_loss = 0.000185 (1.140 sec/batch), lr: 0.000100
2021-07-12 15:57:26.118475: step 12840/164800 (epoch 7/80),jp_loss = 0.002869, trig_loss = 8.357117, rela_loss = 0.340121, bind_loss = 0.000000 (6.776 sec/batch), lr: 0.000100
2021-07-12 15:57:51.583635: step 12860/164800 (epoch 7/80),jp_loss = 0.000595, trig_loss = 0.000427, rela_loss = 0.000000, bind_loss = 0.000000 (0.712 sec/batch), lr: 0.000100
2021-07-12 15:58:22.065924: step 12880/164800 (epoch 7/80),jp_loss = 0.000824, trig_loss = 0.002228, rela_loss = 0.000000, bind_loss = 0.000000 (0.800 sec/batch), lr: 0.000100
2021-07-12 15:59:03.386040: step 12900/164800 (epoch 7/80),jp_loss = 0.000488, trig_loss = 0.000671, rela_loss = 0.000000, bind_loss = 0.000000 (1.050 sec/batch), lr: 0.000100
2021-07-12 15:59:42.341704: step 12920/164800 (epoch 7/80),jp_loss = 0.896866, trig_loss = 1.483765, rela_loss = 0.186455, bind_loss = 0.000000 (3.600 sec/batch), lr: 0.000100
2021-07-12 16:00:24.428477: step 12940/164800 (epoch 7/80),jp_loss = 0.000549, trig_loss = 0.497742, rela_loss = 0.000748, bind_loss = 0.000000 (1.708 sec/batch), lr: 0.000100
2021-07-12 16:00:51.890876: step 12960/164800 (epoch 7/80),jp_loss = 0.001160, trig_loss = 0.000885, rela_loss = 0.000026, bind_loss = 0.000000 (1.762 sec/batch), lr: 0.000100
2021-07-12 16:01:21.061702: step 12980/164800 (epoch 7/80),jp_loss = 6.122818, trig_loss = 0.012360, rela_loss = 0.000001, bind_loss = 0.000814 (2.324 sec/batch), lr: 0.000100
2021-07-12 16:01:56.973355: step 13000/164800 (epoch 7/80),jp_loss = 0.001526, trig_loss = 0.003906, rela_loss = 0.000007, bind_loss = 0.000000 (2.232 sec/batch), lr: 0.000100
2021-07-12 16:02:23.068971: step 13020/164800 (epoch 7/80),jp_loss = 0.001617, trig_loss = 0.000977, rela_loss = 0.005473, bind_loss = 0.000000 (0.722 sec/batch), lr: 0.000100
2021-07-12 16:02:50.301463: step 13040/164800 (epoch 7/80),jp_loss = 0.002014, trig_loss = 0.036713, rela_loss = 0.000009, bind_loss = 0.000000 (1.258 sec/batch), lr: 0.000100
2021-07-12 16:03:18.775794: step 13060/164800 (epoch 7/80),jp_loss = 0.000122, trig_loss = 0.036636, rela_loss = 0.000120, bind_loss = 0.000000 (1.187 sec/batch), lr: 0.000100
2021-07-12 16:03:49.387008: step 13080/164800 (epoch 7/80),jp_loss = 0.000427, trig_loss = 0.001602, rela_loss = 0.000002, bind_loss = 0.000000 (0.700 sec/batch), lr: 0.000100
2021-07-12 16:04:19.261931: step 13100/164800 (epoch 7/80),jp_loss = 0.047577, trig_loss = 0.074738, rela_loss = 0.000002, bind_loss = 0.000000 (1.497 sec/batch), lr: 0.000100
2021-07-12 16:04:57.414449: step 13120/164800 (epoch 7/80),jp_loss = 0.000626, trig_loss = 0.000214, rela_loss = 0.000427, bind_loss = 0.000000 (0.930 sec/batch), lr: 0.000100
2021-07-12 16:05:34.204764: step 13140/164800 (epoch 7/80),jp_loss = 0.000359, trig_loss = 0.000404, rela_loss = 0.000000, bind_loss = 0.000000 (0.421 sec/batch), lr: 0.000100
2021-07-12 16:06:21.946233: step 13160/164800 (epoch 7/80),jp_loss = 0.000656, trig_loss = 0.004333, rela_loss = 0.005108, bind_loss = 0.000000 (1.075 sec/batch), lr: 0.000100
2021-07-12 16:06:53.306950: step 13180/164800 (epoch 7/80),jp_loss = 0.001587, trig_loss = 0.016388, rela_loss = 0.000001, bind_loss = 0.000000 (1.515 sec/batch), lr: 0.000100
2021-07-12 16:07:30.520446: step 13200/164800 (epoch 7/80),jp_loss = 0.004578, trig_loss = 0.003723, rela_loss = 0.000216, bind_loss = 0.667187 (5.044 sec/batch), lr: 0.000100
2021-07-12 16:07:59.912829: step 13220/164800 (epoch 7/80),jp_loss = 0.001678, trig_loss = 0.000305, rela_loss = 0.000073, bind_loss = 0.000000 (1.142 sec/batch), lr: 0.000100
2021-07-12 16:08:32.502562: step 13240/164800 (epoch 7/80),jp_loss = 0.001038, trig_loss = 0.004822, rela_loss = 0.000115, bind_loss = 0.000000 (3.119 sec/batch), lr: 0.000100
2021-07-12 16:09:00.520637: step 13260/164800 (epoch 7/80),jp_loss = 0.004814, trig_loss = 0.000336, rela_loss = 0.000053, bind_loss = 0.000000 (0.500 sec/batch), lr: 0.000100
2021-07-12 16:09:35.801413: step 13280/164800 (epoch 7/80),jp_loss = 0.000366, trig_loss = 0.000793, rela_loss = 0.000000, bind_loss = 0.000000 (0.864 sec/batch), lr: 0.000100
2021-07-12 16:10:15.161611: step 13300/164800 (epoch 7/80),jp_loss = 0.001312, trig_loss = 0.014008, rela_loss = 0.000020, bind_loss = 0.000000 (0.806 sec/batch), lr: 0.000100
2021-07-12 16:10:48.466340: step 13320/164800 (epoch 7/80),jp_loss = 0.001343, trig_loss = 0.001465, rela_loss = 0.000133, bind_loss = 0.000000 (2.241 sec/batch), lr: 0.000100
2021-07-12 16:11:21.560164: step 13340/164800 (epoch 7/80),jp_loss = 0.000351, trig_loss = 5.338440, rela_loss = 0.000699, bind_loss = 0.000000 (0.558 sec/batch), lr: 0.000100
2021-07-12 16:12:03.409928: step 13360/164800 (epoch 7/80),jp_loss = 0.010376, trig_loss = 0.002502, rela_loss = 0.016387, bind_loss = 0.000000 (1.070 sec/batch), lr: 0.000100
2021-07-12 16:12:37.806177: step 13380/164800 (epoch 7/80),jp_loss = 0.000366, trig_loss = 0.009155, rela_loss = 0.002449, bind_loss = 0.000000 (2.577 sec/batch), lr: 0.000100
2021-07-12 16:13:09.715474: step 13400/164800 (epoch 7/80),jp_loss = 0.002090, trig_loss = 0.001099, rela_loss = 0.199479, bind_loss = 0.000000 (1.209 sec/batch), lr: 0.000100
2021-07-12 16:13:36.151086: step 13420/164800 (epoch 7/80),jp_loss = 0.000244, trig_loss = 0.000732, rela_loss = 0.000002, bind_loss = 0.000000 (0.807 sec/batch), lr: 0.000100
2021-07-12 16:14:10.750195: step 13440/164800 (epoch 7/80),jp_loss = 0.000519, trig_loss = 0.003174, rela_loss = 0.000121, bind_loss = 0.000000 (1.594 sec/batch), lr: 0.000100
2021-07-12 16:14:35.603635: step 13460/164800 (epoch 7/80),jp_loss = 0.007050, trig_loss = 0.000732, rela_loss = 0.046621, bind_loss = 0.001572 (1.796 sec/batch), lr: 0.000100
2021-07-12 16:15:15.774953: step 13480/164800 (epoch 7/80),jp_loss = 0.000549, trig_loss = 0.000885, rela_loss = 0.269648, bind_loss = 0.000000 (1.125 sec/batch), lr: 0.000100
2021-07-12 16:15:52.698030: step 13500/164800 (epoch 7/80),jp_loss = 0.000092, trig_loss = 0.002518, rela_loss = 0.000010, bind_loss = 0.000000 (0.578 sec/batch), lr: 0.000100
2021-07-12 16:16:26.379731: step 13520/164800 (epoch 7/80),jp_loss = 0.000519, trig_loss = 0.000854, rela_loss = 0.000457, bind_loss = 0.042018 (0.681 sec/batch), lr: 0.000100
2021-07-12 16:16:55.301428: step 13540/164800 (epoch 7/80),jp_loss = 0.000488, trig_loss = 0.001465, rela_loss = 0.000005, bind_loss = 0.000477 (1.703 sec/batch), lr: 0.000100
2021-07-12 16:17:23.600190: step 13560/164800 (epoch 7/80),jp_loss = 0.000275, trig_loss = 0.001068, rela_loss = 0.000000, bind_loss = 0.000000 (0.521 sec/batch), lr: 0.000100
2021-07-12 16:17:53.422203: step 13580/164800 (epoch 7/80),jp_loss = 0.000946, trig_loss = 0.001160, rela_loss = 0.000036, bind_loss = 0.187127 (2.972 sec/batch), lr: 0.000100
2021-07-12 16:18:32.093715: step 13600/164800 (epoch 7/80),jp_loss = 0.003647, trig_loss = 0.428085, rela_loss = 0.000002, bind_loss = 0.000000 (3.029 sec/batch), lr: 0.000100
2021-07-12 16:19:03.400054: step 13620/164800 (epoch 7/80),jp_loss = 0.000351, trig_loss = 0.003601, rela_loss = 0.000149, bind_loss = 0.000000 (1.303 sec/batch), lr: 0.000100
2021-07-12 16:19:40.380845: step 13640/164800 (epoch 7/80),jp_loss = 0.000641, trig_loss = 0.001038, rela_loss = 0.000000, bind_loss = 0.000499 (1.949 sec/batch), lr: 0.000100
2021-07-12 16:20:09.449169: step 13660/164800 (epoch 7/80),jp_loss = 0.000732, trig_loss = 2.649750, rela_loss = 0.003610, bind_loss = 0.000000 (1.235 sec/batch), lr: 0.000100
2021-07-12 16:20:52.905408: step 13680/164800 (epoch 7/80),jp_loss = 0.000717, trig_loss = 19.373138, rela_loss = 0.028289, bind_loss = 0.000000 (3.091 sec/batch), lr: 0.000100
2021-07-12 16:21:19.964978: step 13700/164800 (epoch 7/80),jp_loss = 0.001083, trig_loss = 0.022980, rela_loss = 0.000003, bind_loss = 0.000000 (1.331 sec/batch), lr: 0.000100
2021-07-12 16:21:52.975301: step 13720/164800 (epoch 7/80),jp_loss = 0.054413, trig_loss = 0.004700, rela_loss = 0.000003, bind_loss = 0.000000 (0.980 sec/batch), lr: 0.000100
2021-07-12 16:22:35.754053: step 13740/164800 (epoch 7/80),jp_loss = 0.021545, trig_loss = 0.002045, rela_loss = 0.000000, bind_loss = 0.000704 (1.962 sec/batch), lr: 0.000100
2021-07-12 16:23:15.350200: step 13760/164800 (epoch 7/80),jp_loss = 0.000519, trig_loss = 5.827454, rela_loss = 0.000006, bind_loss = 0.000000 (1.361 sec/batch), lr: 0.000100
2021-07-12 16:23:44.774512: step 13780/164800 (epoch 7/80),jp_loss = 0.000366, trig_loss = 0.004272, rela_loss = 0.000013, bind_loss = 0.000000 (1.261 sec/batch), lr: 0.000100
2021-07-12 16:24:11.470471: step 13800/164800 (epoch 7/80),jp_loss = 0.000275, trig_loss = 0.001160, rela_loss = 0.000004, bind_loss = 0.000000 (1.400 sec/batch), lr: 0.000100
2021-07-12 16:24:38.725042: step 13820/164800 (epoch 7/80),jp_loss = 0.000473, trig_loss = 0.002136, rela_loss = 0.000035, bind_loss = 0.000863 (2.121 sec/batch), lr: 0.000100
2021-07-12 16:25:10.616975: step 13840/164800 (epoch 7/80),jp_loss = 0.000458, trig_loss = 0.000549, rela_loss = 0.000062, bind_loss = 0.000000 (2.475 sec/batch), lr: 0.000100
2021-07-12 16:25:41.150418: step 13860/164800 (epoch 7/80),jp_loss = 0.000809, trig_loss = 0.000458, rela_loss = 0.000058, bind_loss = 0.000000 (1.169 sec/batch), lr: 0.000100
2021-07-12 16:26:19.247212: step 13880/164800 (epoch 7/80),jp_loss = 0.001427, trig_loss = 0.002327, rela_loss = 0.001892, bind_loss = 0.000000 (0.908 sec/batch), lr: 0.000100
2021-07-12 16:26:42.334666: step 13900/164800 (epoch 7/80),jp_loss = 0.000732, trig_loss = 0.047516, rela_loss = 0.000371, bind_loss = 0.000000 (2.107 sec/batch), lr: 0.000100
2021-07-12 16:27:28.958918: step 13920/164800 (epoch 7/80),jp_loss = 0.000427, trig_loss = 5.885132, rela_loss = 0.005530, bind_loss = 0.000000 (3.354 sec/batch), lr: 0.000100
2021-07-12 16:27:56.229356: step 13940/164800 (epoch 7/80),jp_loss = 0.003555, trig_loss = 0.042175, rela_loss = 0.004578, bind_loss = 0.000000 (1.312 sec/batch), lr: 0.000100
2021-07-12 16:28:28.489589: step 13960/164800 (epoch 7/80),jp_loss = 0.000473, trig_loss = 0.007599, rela_loss = 0.007178, bind_loss = 0.000000 (1.926 sec/batch), lr: 0.000100
2021-07-12 16:28:55.231704: step 13980/164800 (epoch 7/80),jp_loss = 0.000168, trig_loss = 0.000694, rela_loss = 0.000000, bind_loss = 0.000000 (0.572 sec/batch), lr: 0.000100
2021-07-12 16:29:36.688006: step 14000/164800 (epoch 7/80),jp_loss = 0.000610, trig_loss = 0.008728, rela_loss = 0.003499, bind_loss = 0.000000 (2.083 sec/batch), lr: 0.000100
2021-07-12 16:30:09.892690: step 14020/164800 (epoch 7/80),jp_loss = 0.000427, trig_loss = 0.000427, rela_loss = 0.000092, bind_loss = 0.000000 (1.567 sec/batch), lr: 0.000100
2021-07-12 16:30:32.389766: step 14040/164800 (epoch 7/80),jp_loss = 0.000473, trig_loss = 0.005814, rela_loss = 0.001593, bind_loss = 0.000000 (1.078 sec/batch), lr: 0.000100
2021-07-12 16:31:00.530398: step 14060/164800 (epoch 7/80),jp_loss = 0.000183, trig_loss = 0.002167, rela_loss = 0.000018, bind_loss = 0.000000 (1.899 sec/batch), lr: 0.000100
2021-07-12 16:31:26.793703: step 14080/164800 (epoch 7/80),jp_loss = 0.000183, trig_loss = 0.001984, rela_loss = 0.000000, bind_loss = 0.000000 (0.656 sec/batch), lr: 0.000100
2021-07-12 16:31:57.511251: step 14100/164800 (epoch 7/80),jp_loss = 0.000549, trig_loss = 0.005249, rela_loss = 0.000015, bind_loss = 0.000000 (2.741 sec/batch), lr: 0.000100
2021-07-12 16:32:26.411772: step 14120/164800 (epoch 7/80),jp_loss = 0.000336, trig_loss = 0.002228, rela_loss = 0.561087, bind_loss = 0.000000 (1.765 sec/batch), lr: 0.000100
2021-07-12 16:32:58.598770: step 14140/164800 (epoch 7/80),jp_loss = 0.000366, trig_loss = 0.002075, rela_loss = 0.001093, bind_loss = 0.000000 (1.741 sec/batch), lr: 0.000100
2021-07-12 16:33:40.382272: step 14160/164800 (epoch 7/80),jp_loss = 0.006485, trig_loss = 0.009537, rela_loss = 0.000455, bind_loss = 0.000501 (3.267 sec/batch), lr: 0.000100
2021-07-12 16:34:08.451372: step 14180/164800 (epoch 7/80),jp_loss = 0.001160, trig_loss = 13.906647, rela_loss = 0.000197, bind_loss = 0.000000 (0.839 sec/batch), lr: 0.000100
2021-07-12 16:34:39.738672: step 14200/164800 (epoch 7/80),jp_loss = 0.004700, trig_loss = 0.001007, rela_loss = 1.818093, bind_loss = 0.000000 (3.568 sec/batch), lr: 0.000100
2021-07-12 16:35:24.510286: step 14220/164800 (epoch 7/80),jp_loss = 0.000488, trig_loss = 0.008118, rela_loss = 0.000009, bind_loss = 0.000000 (1.891 sec/batch), lr: 0.000100
2021-07-12 16:35:55.388158: step 14240/164800 (epoch 7/80),jp_loss = 0.000305, trig_loss = 0.007309, rela_loss = 0.001193, bind_loss = 0.000000 (1.950 sec/batch), lr: 0.000100
2021-07-12 16:36:46.440536: step 14260/164800 (epoch 7/80),jp_loss = 0.000671, trig_loss = 0.000916, rela_loss = 0.000134, bind_loss = 0.000000 (0.734 sec/batch), lr: 0.000100
2021-07-12 16:37:15.868016: step 14280/164800 (epoch 7/80),jp_loss = 0.001160, trig_loss = 0.209106, rela_loss = 0.267712, bind_loss = 0.000000 (4.245 sec/batch), lr: 0.000100
2021-07-12 16:37:50.887914: step 14300/164800 (epoch 7/80),jp_loss = 0.000458, trig_loss = 0.000183, rela_loss = 0.000005, bind_loss = 0.000000 (1.041 sec/batch), lr: 0.000100
2021-07-12 16:38:23.249445: step 14320/164800 (epoch 7/80),jp_loss = 0.000916, trig_loss = 3.253235, rela_loss = 0.000000, bind_loss = 0.001435 (3.934 sec/batch), lr: 0.000100
2021-07-12 16:38:52.146318: step 14340/164800 (epoch 7/80),jp_loss = 0.002411, trig_loss = 0.000488, rela_loss = 0.000016, bind_loss = 0.000000 (0.960 sec/batch), lr: 0.000100
2021-07-12 16:39:26.448079: step 14360/164800 (epoch 7/80),jp_loss = 0.001465, trig_loss = 0.031265, rela_loss = 0.000005, bind_loss = 0.000000 (2.081 sec/batch), lr: 0.000100
2021-07-12 16:39:58.470253: step 14380/164800 (epoch 7/80),jp_loss = 0.001709, trig_loss = 0.000549, rela_loss = 0.000018, bind_loss = 0.000000 (1.218 sec/batch), lr: 0.000100
2021-07-12 16:40:33.088979: step 14400/164800 (epoch 7/80),jp_loss = 0.001297, trig_loss = 0.001099, rela_loss = 0.001304, bind_loss = 0.000663 (1.853 sec/batch), lr: 0.000100
2021-07-12 16:41:06.877734: step 14420/164800 (epoch 7/80),jp_loss = 0.001556, trig_loss = 0.244507, rela_loss = 0.000000, bind_loss = 0.000000 (1.518 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.08%  R:  98.62%  F1:  98.85%  #: 2174

Final Score:
Precision (micro): 99.076%
   Recall (micro): 98.620%
       F1 (micro): 98.847%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  95.07%  R:  97.31%  F1:  96.17%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  94.04%  R:  97.14%  F1:  95.57%  #: 455
Localization         P:  97.22%  R:  98.31%  F1:  97.77%  #: 178
Negative_regulation  P:  94.13%  R:  95.25%  F1:  94.69%  #: 421
Phosphorylation      P:  97.45%  R:  98.71%  F1:  98.08%  #: 155
Positive_regulation  P:  93.63%  R:  91.39%  F1:  92.49%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  89.67%  R:  92.72%  F1:  91.17%  #: 206
Transcription        P:  80.56%  R:  86.57%  F1:  83.45%  #: 67

Final Score:
Precision (micro): 93.753%
   Recall (micro): 94.674%
       F1 (micro): 94.211%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  94.15%  R:  92.42%  F1:  93.28%  #: 488
Gene_expression      P:  92.46%  R:  94.85%  F1:  93.64%  #: 582
Localization         P:  95.74%  R:  93.75%  F1:  94.74%  #: 192
Negative_regulation  P:  88.92%  R:  88.51%  F1:  88.72%  #: 653
Phosphorylation      P:  96.89%  R:  94.92%  F1:  95.90%  #: 197
Positive_regulation  P:  87.27%  R:  83.21%  F1:  85.19%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  81.64%  R:  87.06%  F1:  84.26%  #: 286
Transcription        P:  75.86%  R:  74.16%  F1:  75.00%  #: 89

Final Score:
Precision (micro): 89.736%
   Recall (micro): 88.953%
       F1 (micro): 89.343%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  83.42%  R:  89.66%  F1:  86.43%  #: 174

Final Score:
Precision (micro): 83.422%
   Recall (micro): 89.655%
       F1 (micro): 86.427%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  81.96%  R:  87.54%  F1:  84.66%  #: 353

Gene_expression      P:  93.24%  R:  94.85%  F1:  94.04%  #: 582

Localization         P:  95.74%  R:  93.75%  F1:  94.74%  #: 192

Negative_regulation  P:  83.37%  R:  69.69%  F1:  75.92%  #: 518

Phosphorylation      P:  91.21%  R:  86.91%  F1:  89.01%  #: 191

Positive_regulation  P:  85.92%  R:  63.03%  F1:  72.71%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  81.86%  R:  65.43%  F1:  72.73%  #: 269

Transcription        P:  77.65%  R:  74.16%  F1:  75.86%  #: 89

Final Score:
Precision (micro): 87.097%
   Recall (micro): 77.243%
       F1 (micro): 81.875%
epoch 7: train_loss = 0.204433, dev_loss = 0.000000, dev_rela_f1 = 0.8187
0.8187456926257753 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_7.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8187456926257753 ---- 7

2021-07-12 16:53:45.535806: step 14440/164800 (epoch 8/80),jp_loss = 0.003418, trig_loss = 1.565765, rela_loss = 0.000000, bind_loss = 0.000000 (2.405 sec/batch), lr: 0.000100
2021-07-12 16:54:26.850664: step 14460/164800 (epoch 8/80),jp_loss = 0.000610, trig_loss = 10.911255, rela_loss = 7.252284, bind_loss = 0.000000 (1.147 sec/batch), lr: 0.000100
2021-07-12 16:55:19.904863: step 14480/164800 (epoch 8/80),jp_loss = 0.006943, trig_loss = 0.000549, rela_loss = 0.000000, bind_loss = 0.000000 (0.976 sec/batch), lr: 0.000100
2021-07-12 16:55:52.605096: step 14500/164800 (epoch 8/80),jp_loss = 0.000305, trig_loss = 0.016113, rela_loss = 0.000000, bind_loss = 0.000000 (0.799 sec/batch), lr: 0.000100
2021-07-12 16:56:38.657902: step 14520/164800 (epoch 8/80),jp_loss = 0.000336, trig_loss = 0.006500, rela_loss = 0.000143, bind_loss = 0.000000 (0.958 sec/batch), lr: 0.000100
2021-07-12 16:57:16.240210: step 14540/164800 (epoch 8/80),jp_loss = 0.002594, trig_loss = 0.000793, rela_loss = 0.000098, bind_loss = 0.000000 (2.017 sec/batch), lr: 0.000100
2021-07-12 16:57:58.885026: step 14560/164800 (epoch 8/80),jp_loss = 0.000443, trig_loss = 0.000557, rela_loss = 0.000000, bind_loss = 0.000018 (0.699 sec/batch), lr: 0.000100
2021-07-12 16:58:30.437858: step 14580/164800 (epoch 8/80),jp_loss = 0.000198, trig_loss = 0.000381, rela_loss = 0.000051, bind_loss = 0.000000 (0.964 sec/batch), lr: 0.000100
2021-07-12 16:59:10.790735: step 14600/164800 (epoch 8/80),jp_loss = 0.000488, trig_loss = 0.285278, rela_loss = 0.000184, bind_loss = 0.000000 (1.765 sec/batch), lr: 0.000100
2021-07-12 16:59:42.610819: step 14620/164800 (epoch 8/80),jp_loss = 8.503677, trig_loss = 0.080338, rela_loss = 2.021758, bind_loss = 0.000000 (1.727 sec/batch), lr: 0.000100
2021-07-12 17:00:18.361471: step 14640/164800 (epoch 8/80),jp_loss = 0.000488, trig_loss = 4.896973, rela_loss = 0.000523, bind_loss = 0.000000 (0.650 sec/batch), lr: 0.000100
2021-07-12 17:01:04.421599: step 14660/164800 (epoch 8/80),jp_loss = 0.000885, trig_loss = 0.002411, rela_loss = 0.000009, bind_loss = 0.000000 (0.889 sec/batch), lr: 0.000100
2021-07-12 17:01:38.300724: step 14680/164800 (epoch 8/80),jp_loss = 0.001221, trig_loss = 0.044800, rela_loss = 0.000002, bind_loss = 0.000000 (1.723 sec/batch), lr: 0.000100
2021-07-12 17:02:21.326389: step 14700/164800 (epoch 8/80),jp_loss = 0.001305, trig_loss = 0.000320, rela_loss = 0.000000, bind_loss = 0.000000 (0.608 sec/batch), lr: 0.000100
2021-07-12 17:03:02.822120: step 14720/164800 (epoch 8/80),jp_loss = 0.000793, trig_loss = 0.000946, rela_loss = 0.000153, bind_loss = 0.000000 (0.725 sec/batch), lr: 0.000100
2021-07-12 17:03:38.633401: step 14740/164800 (epoch 8/80),jp_loss = 0.002106, trig_loss = 8.585876, rela_loss = 0.000568, bind_loss = 0.000000 (1.392 sec/batch), lr: 0.000100
2021-07-12 17:04:18.625618: step 14760/164800 (epoch 8/80),jp_loss = 0.000427, trig_loss = 0.000427, rela_loss = 0.000003, bind_loss = 0.000000 (0.918 sec/batch), lr: 0.000100
2021-07-12 17:04:59.279145: step 14780/164800 (epoch 8/80),jp_loss = 0.000854, trig_loss = 0.028107, rela_loss = 0.394930, bind_loss = 0.000000 (1.147 sec/batch), lr: 0.000100
2021-07-12 17:05:27.301399: step 14800/164800 (epoch 8/80),jp_loss = 0.053787, trig_loss = 0.033356, rela_loss = 0.052182, bind_loss = 0.001000 (2.219 sec/batch), lr: 0.000100
2021-07-12 17:05:55.125193: step 14820/164800 (epoch 8/80),jp_loss = 0.000641, trig_loss = 0.000214, rela_loss = 0.000142, bind_loss = 0.000000 (0.915 sec/batch), lr: 0.000100
2021-07-12 17:06:42.106578: step 14840/164800 (epoch 8/80),jp_loss = 0.000793, trig_loss = 1.182434, rela_loss = 0.046153, bind_loss = 0.000000 (2.833 sec/batch), lr: 0.000100
2021-07-12 17:07:15.766059: step 14860/164800 (epoch 8/80),jp_loss = 0.000793, trig_loss = 1.387817, rela_loss = 0.000127, bind_loss = 0.000000 (1.199 sec/batch), lr: 0.000100
2021-07-12 17:07:45.622683: step 14880/164800 (epoch 8/80),jp_loss = 0.002853, trig_loss = 0.001785, rela_loss = 0.000010, bind_loss = 0.000188 (1.239 sec/batch), lr: 0.000100
2021-07-12 17:08:40.495751: step 14900/164800 (epoch 8/80),jp_loss = 2.113464, trig_loss = 3.709229, rela_loss = 0.000058, bind_loss = 0.000000 (6.938 sec/batch), lr: 0.000100
2021-07-12 17:09:10.524621: step 14920/164800 (epoch 8/80),jp_loss = 0.000778, trig_loss = 0.001587, rela_loss = 0.000005, bind_loss = 0.000000 (0.773 sec/batch), lr: 0.000100
2021-07-12 17:09:44.809736: step 14940/164800 (epoch 8/80),jp_loss = 0.000916, trig_loss = 0.000671, rela_loss = 0.000172, bind_loss = 0.000000 (1.000 sec/batch), lr: 0.000100
2021-07-12 17:10:30.191291: step 14960/164800 (epoch 8/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 0.000052, bind_loss = 0.000000 (1.006 sec/batch), lr: 0.000100
2021-07-12 17:11:14.391791: step 14980/164800 (epoch 8/80),jp_loss = 0.000732, trig_loss = 0.244263, rela_loss = 0.471684, bind_loss = 0.000000 (4.322 sec/batch), lr: 0.000100
2021-07-12 17:12:00.663045: step 15000/164800 (epoch 8/80),jp_loss = 0.000732, trig_loss = 0.103607, rela_loss = 0.000113, bind_loss = 0.000000 (2.088 sec/batch), lr: 0.000100
2021-07-12 17:12:31.112658: step 15020/164800 (epoch 8/80),jp_loss = 0.001343, trig_loss = 0.000519, rela_loss = 0.000287, bind_loss = 0.000000 (1.929 sec/batch), lr: 0.000100
2021-07-12 17:13:04.124259: step 15040/164800 (epoch 8/80),jp_loss = 0.018158, trig_loss = 0.001038, rela_loss = 0.000003, bind_loss = 0.000285 (2.506 sec/batch), lr: 0.000100
2021-07-12 17:13:43.280723: step 15060/164800 (epoch 8/80),jp_loss = 0.001801, trig_loss = 0.011108, rela_loss = 0.000003, bind_loss = 0.000000 (1.729 sec/batch), lr: 0.000100
2021-07-12 17:14:12.538376: step 15080/164800 (epoch 8/80),jp_loss = 0.000916, trig_loss = 0.000092, rela_loss = 0.000001, bind_loss = 0.000000 (0.812 sec/batch), lr: 0.000100
2021-07-12 17:14:43.326854: step 15100/164800 (epoch 8/80),jp_loss = 0.001038, trig_loss = 2.244751, rela_loss = 0.040393, bind_loss = 0.000000 (1.333 sec/batch), lr: 0.000100
2021-07-12 17:15:16.049112: step 15120/164800 (epoch 8/80),jp_loss = 0.000397, trig_loss = 0.022430, rela_loss = 0.000022, bind_loss = 0.000000 (1.429 sec/batch), lr: 0.000100
2021-07-12 17:15:49.362035: step 15140/164800 (epoch 8/80),jp_loss = 0.000229, trig_loss = 0.001709, rela_loss = 0.000083, bind_loss = 0.000000 (0.943 sec/batch), lr: 0.000100
2021-07-12 17:16:23.029757: step 15160/164800 (epoch 8/80),jp_loss = 0.000946, trig_loss = 0.001526, rela_loss = 0.000002, bind_loss = 0.000000 (1.578 sec/batch), lr: 0.000100
2021-07-12 17:17:02.297343: step 15180/164800 (epoch 8/80),jp_loss = 0.000244, trig_loss = 0.000397, rela_loss = 0.000002, bind_loss = 0.000000 (1.023 sec/batch), lr: 0.000100
2021-07-12 17:17:42.602613: step 15200/164800 (epoch 8/80),jp_loss = 0.000168, trig_loss = 0.000145, rela_loss = 0.000000, bind_loss = 0.000000 (0.397 sec/batch), lr: 0.000100
2021-07-12 17:18:30.799321: step 15220/164800 (epoch 8/80),jp_loss = 0.000366, trig_loss = 0.000732, rela_loss = 0.000355, bind_loss = 0.000000 (0.979 sec/batch), lr: 0.000100
2021-07-12 17:19:04.458981: step 15240/164800 (epoch 8/80),jp_loss = 0.000534, trig_loss = 14.671661, rela_loss = 0.000169, bind_loss = 0.000000 (1.606 sec/batch), lr: 0.000100
2021-07-12 17:19:44.042756: step 15260/164800 (epoch 8/80),jp_loss = 0.003845, trig_loss = 0.015350, rela_loss = 0.000000, bind_loss = 0.037890 (5.067 sec/batch), lr: 0.000100
2021-07-12 17:20:14.563745: step 15280/164800 (epoch 8/80),jp_loss = 0.000732, trig_loss = 0.000488, rela_loss = 0.000003, bind_loss = 0.000000 (1.231 sec/batch), lr: 0.000100
2021-07-12 17:20:49.623660: step 15300/164800 (epoch 8/80),jp_loss = 0.001526, trig_loss = 0.014160, rela_loss = 0.000472, bind_loss = 0.000000 (3.317 sec/batch), lr: 0.000100
2021-07-12 17:21:19.190044: step 15320/164800 (epoch 8/80),jp_loss = 0.001167, trig_loss = 1.413849, rela_loss = 0.000249, bind_loss = 0.000000 (0.570 sec/batch), lr: 0.000100
2021-07-12 17:21:56.306605: step 15340/164800 (epoch 8/80),jp_loss = 0.000183, trig_loss = 0.000305, rela_loss = 0.000139, bind_loss = 0.000000 (0.920 sec/batch), lr: 0.000100
2021-07-12 17:22:37.300189: step 15360/164800 (epoch 8/80),jp_loss = 0.000610, trig_loss = 0.000397, rela_loss = 0.000394, bind_loss = 0.000000 (0.787 sec/batch), lr: 0.000100
2021-07-12 17:23:11.522261: step 15380/164800 (epoch 8/80),jp_loss = 0.001038, trig_loss = 0.001404, rela_loss = 0.000224, bind_loss = 0.000000 (2.417 sec/batch), lr: 0.000100
2021-07-12 17:23:46.777423: step 15400/164800 (epoch 8/80),jp_loss = 0.000229, trig_loss = 0.624695, rela_loss = 0.000068, bind_loss = 0.000000 (0.675 sec/batch), lr: 0.000100
2021-07-12 17:24:29.678620: step 15420/164800 (epoch 8/80),jp_loss = 0.002441, trig_loss = 0.000977, rela_loss = 0.007138, bind_loss = 0.000000 (1.250 sec/batch), lr: 0.000100
2021-07-12 17:25:03.969553: step 15440/164800 (epoch 8/80),jp_loss = 0.000397, trig_loss = 0.004211, rela_loss = 0.000112, bind_loss = 0.000000 (2.349 sec/batch), lr: 0.000100
2021-07-12 17:25:39.919392: step 15460/164800 (epoch 8/80),jp_loss = 0.001404, trig_loss = 0.000519, rela_loss = 0.000000, bind_loss = 0.000000 (1.590 sec/batch), lr: 0.000100
2021-07-12 17:26:10.239033: step 15480/164800 (epoch 8/80),jp_loss = 0.000122, trig_loss = 0.000122, rela_loss = 0.000004, bind_loss = 0.000000 (0.931 sec/batch), lr: 0.000100
2021-07-12 17:26:47.814617: step 15500/164800 (epoch 8/80),jp_loss = 0.000061, trig_loss = 0.000732, rela_loss = 0.004066, bind_loss = 0.000000 (1.721 sec/batch), lr: 0.000100
2021-07-12 17:27:16.072836: step 15520/164800 (epoch 8/80),jp_loss = 0.001038, trig_loss = 0.000153, rela_loss = 0.000653, bind_loss = 0.001422 (2.013 sec/batch), lr: 0.000100
2021-07-12 17:27:57.146910: step 15540/164800 (epoch 8/80),jp_loss = 0.000298, trig_loss = 0.001404, rela_loss = 0.000024, bind_loss = 0.000000 (1.415 sec/batch), lr: 0.000100
2021-07-12 17:28:37.886568: step 15560/164800 (epoch 8/80),jp_loss = 0.000259, trig_loss = 0.000519, rela_loss = 0.000125, bind_loss = 0.000000 (0.678 sec/batch), lr: 0.000100
2021-07-12 17:29:12.848654: step 15580/164800 (epoch 8/80),jp_loss = 0.000748, trig_loss = 0.000214, rela_loss = 0.001236, bind_loss = 0.036532 (0.759 sec/batch), lr: 0.000100
2021-07-12 17:29:44.876769: step 15600/164800 (epoch 8/80),jp_loss = 0.000397, trig_loss = 0.003052, rela_loss = 0.000372, bind_loss = 0.000418 (1.767 sec/batch), lr: 0.000100
2021-07-12 17:30:14.487481: step 15620/164800 (epoch 8/80),jp_loss = 0.000168, trig_loss = 0.002640, rela_loss = 0.000008, bind_loss = 0.000000 (0.455 sec/batch), lr: 0.000100
2021-07-12 17:30:48.048255: step 15640/164800 (epoch 8/80),jp_loss = 0.001099, trig_loss = 0.000610, rela_loss = 0.000032, bind_loss = 0.180626 (3.421 sec/batch), lr: 0.000100
2021-07-12 17:31:33.653226: step 15660/164800 (epoch 8/80),jp_loss = 0.001328, trig_loss = 0.005127, rela_loss = 0.000015, bind_loss = 0.000000 (3.555 sec/batch), lr: 0.000100
2021-07-12 17:32:09.726487: step 15680/164800 (epoch 8/80),jp_loss = 0.001022, trig_loss = 0.001099, rela_loss = 0.000034, bind_loss = 0.000000 (1.586 sec/batch), lr: 0.000100
2021-07-12 17:32:51.315234: step 15700/164800 (epoch 8/80),jp_loss = 0.001373, trig_loss = 0.001221, rela_loss = 0.000003, bind_loss = 0.001399 (2.617 sec/batch), lr: 0.000100
2021-07-12 17:33:23.765885: step 15720/164800 (epoch 8/80),jp_loss = 0.004303, trig_loss = 0.001312, rela_loss = 0.000050, bind_loss = 0.000000 (1.583 sec/batch), lr: 0.000100
2021-07-12 17:34:10.741686: step 15740/164800 (epoch 8/80),jp_loss = 0.001984, trig_loss = 6.578293, rela_loss = 0.000086, bind_loss = 0.000000 (3.131 sec/batch), lr: 0.000100
2021-07-12 17:34:42.091235: step 15760/164800 (epoch 8/80),jp_loss = 0.190933, trig_loss = 0.027740, rela_loss = 0.000001, bind_loss = 0.000000 (1.686 sec/batch), lr: 0.000100
2021-07-12 17:35:17.935267: step 15780/164800 (epoch 8/80),jp_loss = 0.000595, trig_loss = 0.018555, rela_loss = 0.000036, bind_loss = 0.000000 (0.998 sec/batch), lr: 0.000100
2021-07-12 17:36:02.762691: step 15800/164800 (epoch 8/80),jp_loss = 9.958679, trig_loss = 6.824860, rela_loss = 0.000148, bind_loss = 0.000241 (2.320 sec/batch), lr: 0.000100
2021-07-12 17:36:46.222675: step 15820/164800 (epoch 8/80),jp_loss = 0.001205, trig_loss = 3.181320, rela_loss = 0.000112, bind_loss = 0.000000 (1.434 sec/batch), lr: 0.000100
2021-07-12 17:37:18.055534: step 15840/164800 (epoch 8/80),jp_loss = 0.000641, trig_loss = 0.001770, rela_loss = 0.006152, bind_loss = 0.000000 (1.494 sec/batch), lr: 0.000100
2021-07-12 17:37:48.547098: step 15860/164800 (epoch 8/80),jp_loss = 0.000427, trig_loss = 0.001282, rela_loss = 0.000004, bind_loss = 0.000000 (1.546 sec/batch), lr: 0.000100
2021-07-12 17:38:17.867010: step 15880/164800 (epoch 8/80),jp_loss = 0.001068, trig_loss = 0.001282, rela_loss = 0.000021, bind_loss = 0.001841 (2.110 sec/batch), lr: 0.000100
2021-07-12 17:38:53.258556: step 15900/164800 (epoch 8/80),jp_loss = 0.001495, trig_loss = 0.001160, rela_loss = 0.000330, bind_loss = 0.000000 (2.374 sec/batch), lr: 0.000100
2021-07-12 17:39:28.198529: step 15920/164800 (epoch 8/80),jp_loss = 0.000610, trig_loss = 0.001068, rela_loss = 0.000003, bind_loss = 0.000000 (0.883 sec/batch), lr: 0.000100
2021-07-12 17:40:10.075702: step 15940/164800 (epoch 8/80),jp_loss = 0.001789, trig_loss = 0.002640, rela_loss = 0.001136, bind_loss = 0.000000 (1.057 sec/batch), lr: 0.000100
2021-07-12 17:40:35.143813: step 15960/164800 (epoch 8/80),jp_loss = 0.000397, trig_loss = 0.474579, rela_loss = 0.002962, bind_loss = 0.000000 (1.955 sec/batch), lr: 0.000100
2021-07-12 17:41:25.653357: step 15980/164800 (epoch 8/80),jp_loss = 0.000610, trig_loss = 0.003662, rela_loss = 0.003947, bind_loss = 0.000000 (3.662 sec/batch), lr: 0.000100
2021-07-12 17:41:56.009123: step 16000/164800 (epoch 8/80),jp_loss = 0.000244, trig_loss = 0.002319, rela_loss = 0.000197, bind_loss = 0.000000 (1.585 sec/batch), lr: 0.000100
2021-07-12 17:42:30.521581: step 16020/164800 (epoch 8/80),jp_loss = 0.001419, trig_loss = 0.002289, rela_loss = 0.002588, bind_loss = 0.000000 (1.787 sec/batch), lr: 0.000100
2021-07-12 17:42:59.968207: step 16040/164800 (epoch 8/80),jp_loss = 0.001266, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (0.651 sec/batch), lr: 0.000100
2021-07-12 17:43:44.191735: step 16060/164800 (epoch 8/80),jp_loss = 0.001953, trig_loss = 0.006775, rela_loss = 0.000107, bind_loss = 0.000000 (2.417 sec/batch), lr: 0.000100
2021-07-12 17:44:21.445081: step 16080/164800 (epoch 8/80),jp_loss = 0.000366, trig_loss = 0.000214, rela_loss = 0.037260, bind_loss = 0.000000 (1.584 sec/batch), lr: 0.000100
2021-07-12 17:44:46.643987: step 16100/164800 (epoch 8/80),jp_loss = 0.000336, trig_loss = 0.001541, rela_loss = 0.000045, bind_loss = 0.000000 (1.501 sec/batch), lr: 0.000100
2021-07-12 17:45:17.617030: step 16120/164800 (epoch 8/80),jp_loss = 0.000580, trig_loss = 0.004913, rela_loss = 0.000019, bind_loss = 0.000000 (2.013 sec/batch), lr: 0.000100
2021-07-12 17:45:47.046585: step 16140/164800 (epoch 8/80),jp_loss = 0.000565, trig_loss = 0.000824, rela_loss = 0.001295, bind_loss = 0.000000 (0.630 sec/batch), lr: 0.000100
2021-07-12 17:46:22.174951: step 16160/164800 (epoch 8/80),jp_loss = 0.001617, trig_loss = 0.005203, rela_loss = 0.000020, bind_loss = 0.000000 (2.972 sec/batch), lr: 0.000100
2021-07-12 17:46:53.303796: step 16180/164800 (epoch 8/80),jp_loss = 0.000946, trig_loss = 0.051147, rela_loss = 0.441947, bind_loss = 0.000000 (1.908 sec/batch), lr: 0.000100
2021-07-12 17:47:27.874508: step 16200/164800 (epoch 8/80),jp_loss = 0.001099, trig_loss = 0.002686, rela_loss = 0.000096, bind_loss = 0.000000 (1.960 sec/batch), lr: 0.000100
2021-07-12 17:48:15.130887: step 16220/164800 (epoch 8/80),jp_loss = 0.001190, trig_loss = 0.009735, rela_loss = 0.000005, bind_loss = 0.000636 (3.671 sec/batch), lr: 0.000100
2021-07-12 17:48:47.694479: step 16240/164800 (epoch 8/80),jp_loss = 0.003967, trig_loss = 0.027069, rela_loss = 0.000014, bind_loss = 0.000000 (1.096 sec/batch), lr: 0.000100
2021-07-12 17:49:22.503043: step 16260/164800 (epoch 8/80),jp_loss = 0.006378, trig_loss = 0.000732, rela_loss = 1.174819, bind_loss = 0.000000 (3.497 sec/batch), lr: 0.000100
2021-07-12 17:50:12.620565: step 16280/164800 (epoch 8/80),jp_loss = 0.000366, trig_loss = 0.003418, rela_loss = 0.000006, bind_loss = 0.000000 (2.041 sec/batch), lr: 0.000100
2021-07-12 17:50:45.013702: step 16300/164800 (epoch 8/80),jp_loss = 0.001022, trig_loss = 1.711014, rela_loss = 0.000612, bind_loss = 0.000000 (1.969 sec/batch), lr: 0.000100
2021-07-12 17:51:38.449706: step 16320/164800 (epoch 8/80),jp_loss = 0.000092, trig_loss = 0.000671, rela_loss = 0.000005, bind_loss = 0.000000 (0.869 sec/batch), lr: 0.000100
2021-07-12 17:52:09.600439: step 16340/164800 (epoch 8/80),jp_loss = 0.000946, trig_loss = 2.929993, rela_loss = 0.000094, bind_loss = 0.000000 (4.471 sec/batch), lr: 0.000100
2021-07-12 17:52:45.420298: step 16360/164800 (epoch 8/80),jp_loss = 0.000092, trig_loss = 0.000183, rela_loss = 0.000036, bind_loss = 0.000000 (0.799 sec/batch), lr: 0.000100
2021-07-12 17:53:20.094603: step 16380/164800 (epoch 8/80),jp_loss = 0.001221, trig_loss = 1.862854, rela_loss = 0.000001, bind_loss = 0.000613 (4.461 sec/batch), lr: 0.000100
2021-07-12 17:53:49.151455: step 16400/164800 (epoch 8/80),jp_loss = 0.000748, trig_loss = 0.000366, rela_loss = 0.000029, bind_loss = 0.000000 (1.020 sec/batch), lr: 0.000100
2021-07-12 17:54:25.523952: step 16420/164800 (epoch 8/80),jp_loss = 0.000381, trig_loss = 0.005798, rela_loss = 0.000006, bind_loss = 0.000000 (1.580 sec/batch), lr: 0.000100
2021-07-12 17:54:59.326625: step 16440/164800 (epoch 8/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000007, bind_loss = 0.000000 (2.012 sec/batch), lr: 0.000100
2021-07-12 17:55:34.481465: step 16460/164800 (epoch 8/80),jp_loss = 0.000427, trig_loss = 0.000504, rela_loss = 0.002238, bind_loss = 0.000555 (1.756 sec/batch), lr: 0.000100
2021-07-12 17:56:08.103805: step 16480/164800 (epoch 8/80),jp_loss = 0.000244, trig_loss = 0.007355, rela_loss = 0.000061, bind_loss = 0.000000 (1.534 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  98.59%  R:  99.54%  F1:  99.06%  #: 2174

Final Score:
Precision (micro): 98.588%
   Recall (micro): 99.540%
       F1 (micro): 99.062%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  97.98%  R:  97.98%  F1:  97.98%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  95.86%  R:  96.70%  F1:  96.28%  #: 455
Localization         P:  98.33%  R:  99.44%  F1:  98.88%  #: 178
Negative_regulation  P:  94.95%  R:  98.34%  F1:  96.62%  #: 421
Phosphorylation      P:  96.82%  R:  98.06%  F1:  97.44%  #: 155
Positive_regulation  P:  95.18%  R:  94.58%  F1:  94.88%  #: 627
Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30
Regulation           P:  88.37%  R:  92.23%  F1:  90.26%  #: 206
Transcription        P:  90.91%  R:  89.55%  F1:  90.23%  #: 67

Final Score:
Precision (micro): 95.172%
   Recall (micro): 96.108%
       F1 (micro): 95.638%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  94.13%  R:  95.48%  F1:  94.80%  #: 487
Gene_expression      P:  93.80%  R:  96.22%  F1:  95.00%  #: 582
Localization         P:  93.91%  R:  96.35%  F1:  95.12%  #: 192
Negative_regulation  P:  86.59%  R:  92.67%  F1:  89.53%  #: 655
Phosphorylation      P:  93.20%  R:  97.46%  F1:  95.29%  #: 197
Positive_regulation  P:  88.99%  R:  87.54%  F1:  88.26%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  79.44%  R:  89.47%  F1:  84.16%  #: 285
Transcription        P:  84.62%  R:  86.52%  F1:  85.56%  #: 89

Final Score:
Precision (micro): 89.622%
   Recall (micro): 92.384%
       F1 (micro): 90.982%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  86.91%  R:  92.74%  F1:  89.73%  #: 179

Final Score:
Precision (micro): 86.911%
   Recall (micro): 92.737%
       F1 (micro): 89.730%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  85.60%  R:  89.49%  F1:  87.50%  #: 352

Gene_expression      P:  94.59%  R:  96.22%  F1:  95.40%  #: 582

Localization         P:  93.91%  R:  96.35%  F1:  95.12%  #: 192

Negative_regulation  P:  84.62%  R:  74.18%  F1:  79.06%  #: 519

Phosphorylation      P:  86.60%  R:  87.96%  F1:  87.27%  #: 191

Positive_regulation  P:  84.76%  R:  68.54%  F1:  75.79%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  76.10%  R:  71.27%  F1:  73.60%  #: 268

Transcription        P:  85.56%  R:  86.52%  F1:  86.03%  #: 89

Final Score:
Precision (micro): 86.990%
   Recall (micro): 81.106%
       F1 (micro): 83.945%
epoch 8: train_loss = 0.186442, dev_loss = 0.000000, dev_rela_f1 = 0.8394
0.8394479973073039 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_8.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8394479973073039 ---- 8

2021-07-12 18:08:54.061693: step 16500/164800 (epoch 9/80),jp_loss = 0.001312, trig_loss = 0.139099, rela_loss = 0.000026, bind_loss = 0.000000 (2.548 sec/batch), lr: 0.000100
2021-07-12 18:09:33.222564: step 16520/164800 (epoch 9/80),jp_loss = 0.000153, trig_loss = 8.047668, rela_loss = 3.618308, bind_loss = 0.000000 (0.955 sec/batch), lr: 0.000100
2021-07-12 18:10:24.172451: step 16540/164800 (epoch 9/80),jp_loss = 0.384766, trig_loss = 0.001923, rela_loss = 0.000011, bind_loss = 0.000000 (0.946 sec/batch), lr: 0.000100
2021-07-12 18:10:56.508428: step 16560/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.007721, rela_loss = 0.000000, bind_loss = 0.000000 (0.764 sec/batch), lr: 0.000100
2021-07-12 18:11:42.678681: step 16580/164800 (epoch 9/80),jp_loss = 0.000443, trig_loss = 0.011536, rela_loss = 0.152208, bind_loss = 0.000000 (0.983 sec/batch), lr: 0.000100
2021-07-12 18:12:21.135634: step 16600/164800 (epoch 9/80),jp_loss = 0.000488, trig_loss = 0.000244, rela_loss = 0.000014, bind_loss = 0.000000 (2.105 sec/batch), lr: 0.000100
2021-07-12 18:13:04.566879: step 16620/164800 (epoch 9/80),jp_loss = 0.000130, trig_loss = 0.000191, rela_loss = 0.000003, bind_loss = 0.000239 (0.824 sec/batch), lr: 0.000100
2021-07-12 18:13:36.034768: step 16640/164800 (epoch 9/80),jp_loss = 0.000580, trig_loss = 0.000198, rela_loss = 0.000009, bind_loss = 0.000000 (0.878 sec/batch), lr: 0.000100
2021-07-12 18:14:16.578514: step 16660/164800 (epoch 9/80),jp_loss = 0.001892, trig_loss = 5.156586, rela_loss = 0.007654, bind_loss = 0.000000 (1.702 sec/batch), lr: 0.000100
2021-07-12 18:14:47.593888: step 16680/164800 (epoch 9/80),jp_loss = 0.000946, trig_loss = 0.023239, rela_loss = 0.346527, bind_loss = 0.000000 (1.768 sec/batch), lr: 0.000100
2021-07-12 18:15:22.172107: step 16700/164800 (epoch 9/80),jp_loss = 0.000259, trig_loss = 0.023300, rela_loss = 0.000047, bind_loss = 0.000000 (0.985 sec/batch), lr: 0.000100
2021-07-12 18:16:07.838096: step 16720/164800 (epoch 9/80),jp_loss = 0.001282, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000000 (1.145 sec/batch), lr: 0.000100
2021-07-12 18:16:41.960232: step 16740/164800 (epoch 9/80),jp_loss = 0.000427, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (1.690 sec/batch), lr: 0.000100
2021-07-12 18:17:23.370203: step 16760/164800 (epoch 9/80),jp_loss = 0.000206, trig_loss = 0.000244, rela_loss = 0.001095, bind_loss = 0.000000 (0.551 sec/batch), lr: 0.000100
2021-07-12 18:18:03.636961: step 16780/164800 (epoch 9/80),jp_loss = 0.008484, trig_loss = 0.000549, rela_loss = 0.000004, bind_loss = 0.000000 (0.647 sec/batch), lr: 0.000100
2021-07-12 18:18:40.217750: step 16800/164800 (epoch 9/80),jp_loss = 0.000229, trig_loss = 2.256805, rela_loss = 0.000060, bind_loss = 0.000000 (1.306 sec/batch), lr: 0.000100
2021-07-12 18:19:19.284430: step 16820/164800 (epoch 9/80),jp_loss = 0.000351, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.689 sec/batch), lr: 0.000100
2021-07-12 18:20:00.024222: step 16840/164800 (epoch 9/80),jp_loss = 0.000427, trig_loss = 0.000519, rela_loss = 0.000004, bind_loss = 0.000000 (1.282 sec/batch), lr: 0.000100
2021-07-12 18:20:26.708366: step 16860/164800 (epoch 9/80),jp_loss = 1.516418, trig_loss = 0.044830, rela_loss = 0.000009, bind_loss = 0.000451 (2.279 sec/batch), lr: 0.000100
2021-07-12 18:20:52.612651: step 16880/164800 (epoch 9/80),jp_loss = 0.000092, trig_loss = 7.089203, rela_loss = 0.000508, bind_loss = 0.000000 (0.865 sec/batch), lr: 0.000100
2021-07-12 18:21:39.945534: step 16900/164800 (epoch 9/80),jp_loss = 0.000427, trig_loss = 0.009460, rela_loss = 2.661115, bind_loss = 0.000000 (2.920 sec/batch), lr: 0.000100
2021-07-12 18:22:12.741740: step 16920/164800 (epoch 9/80),jp_loss = 0.000305, trig_loss = 0.000793, rela_loss = 0.000002, bind_loss = 0.000000 (1.168 sec/batch), lr: 0.000100
2021-07-12 18:22:42.508418: step 16940/164800 (epoch 9/80),jp_loss = 0.000595, trig_loss = 0.002029, rela_loss = 0.000005, bind_loss = 0.000046 (1.524 sec/batch), lr: 0.000100
2021-07-12 18:23:40.170723: step 16960/164800 (epoch 9/80),jp_loss = 5.688721, trig_loss = 0.001892, rela_loss = 0.000381, bind_loss = 0.000000 (6.917 sec/batch), lr: 0.000100
2021-07-12 18:24:10.523162: step 16980/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.000336, rela_loss = 0.000142, bind_loss = 0.000000 (0.783 sec/batch), lr: 0.000100
2021-07-12 18:24:46.148913: step 17000/164800 (epoch 9/80),jp_loss = 0.000275, trig_loss = 0.013000, rela_loss = 0.000014, bind_loss = 0.000000 (0.943 sec/batch), lr: 0.000100
2021-07-12 18:25:32.898858: step 17020/164800 (epoch 9/80),jp_loss = 0.000092, trig_loss = 9.530792, rela_loss = 0.000003, bind_loss = 0.000000 (1.117 sec/batch), lr: 0.000100
2021-07-12 18:26:15.272719: step 17040/164800 (epoch 9/80),jp_loss = 0.010925, trig_loss = 0.048706, rela_loss = 0.019006, bind_loss = 0.000000 (3.859 sec/batch), lr: 0.000100
2021-07-12 18:27:01.468625: step 17060/164800 (epoch 9/80),jp_loss = 0.000305, trig_loss = 0.037720, rela_loss = 0.000108, bind_loss = 0.000000 (1.928 sec/batch), lr: 0.000100
2021-07-12 18:27:31.725642: step 17080/164800 (epoch 9/80),jp_loss = 0.000885, trig_loss = 0.000519, rela_loss = 0.000082, bind_loss = 0.000000 (1.874 sec/batch), lr: 0.000100
2021-07-12 18:28:04.317308: step 17100/164800 (epoch 9/80),jp_loss = 2.137878, trig_loss = 0.004578, rela_loss = 0.000021, bind_loss = 0.366747 (2.783 sec/batch), lr: 0.000100
2021-07-12 18:28:44.589452: step 17120/164800 (epoch 9/80),jp_loss = 0.002884, trig_loss = 0.001495, rela_loss = 0.000002, bind_loss = 0.000000 (1.822 sec/batch), lr: 0.000100
2021-07-12 18:29:15.456153: step 17140/164800 (epoch 9/80),jp_loss = 0.000366, trig_loss = 0.000214, rela_loss = 0.000009, bind_loss = 0.000000 (0.749 sec/batch), lr: 0.000100
2021-07-12 18:29:48.193771: step 17160/164800 (epoch 9/80),jp_loss = 0.001465, trig_loss = 0.000336, rela_loss = 0.001136, bind_loss = 0.000000 (1.473 sec/batch), lr: 0.000100
2021-07-12 18:30:21.114154: step 17180/164800 (epoch 9/80),jp_loss = 0.000183, trig_loss = 0.010651, rela_loss = 0.000004, bind_loss = 0.000000 (1.282 sec/batch), lr: 0.000100
2021-07-12 18:30:57.249298: step 17200/164800 (epoch 9/80),jp_loss = 0.000076, trig_loss = 0.000351, rela_loss = 0.000003, bind_loss = 0.000000 (0.929 sec/batch), lr: 0.000100
2021-07-12 18:31:29.824200: step 17220/164800 (epoch 9/80),jp_loss = 0.002686, trig_loss = 0.004181, rela_loss = 0.000000, bind_loss = 0.000000 (1.703 sec/batch), lr: 0.000100
2021-07-12 18:32:12.117548: step 17240/164800 (epoch 9/80),jp_loss = 0.000488, trig_loss = 0.000214, rela_loss = 0.000010, bind_loss = 0.000000 (1.224 sec/batch), lr: 0.000100
2021-07-12 18:32:52.583560: step 17260/164800 (epoch 9/80),jp_loss = 0.000214, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.490 sec/batch), lr: 0.000100
2021-07-12 18:33:43.467518: step 17280/164800 (epoch 9/80),jp_loss = 0.000137, trig_loss = 0.001556, rela_loss = 0.000002, bind_loss = 0.000000 (1.201 sec/batch), lr: 0.000100
2021-07-12 18:34:18.625972: step 17300/164800 (epoch 9/80),jp_loss = 0.000473, trig_loss = 0.004425, rela_loss = 0.000003, bind_loss = 0.000000 (2.104 sec/batch), lr: 0.000100
2021-07-12 18:34:59.820753: step 17320/164800 (epoch 9/80),jp_loss = 0.019531, trig_loss = 0.002655, rela_loss = 0.000002, bind_loss = 0.024145 (4.912 sec/batch), lr: 0.000100
2021-07-12 18:35:33.026803: step 17340/164800 (epoch 9/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 0.000012, bind_loss = 0.000000 (1.044 sec/batch), lr: 0.000100
2021-07-12 18:36:09.663059: step 17360/164800 (epoch 9/80),jp_loss = 0.000916, trig_loss = 0.014221, rela_loss = 0.000007, bind_loss = 0.000000 (3.336 sec/batch), lr: 0.000100
2021-07-12 18:36:39.465946: step 17380/164800 (epoch 9/80),jp_loss = 0.001122, trig_loss = 0.000092, rela_loss = 0.000006, bind_loss = 0.000000 (0.535 sec/batch), lr: 0.000100
2021-07-12 18:37:16.019969: step 17400/164800 (epoch 9/80),jp_loss = 0.000854, trig_loss = 0.000183, rela_loss = 0.000152, bind_loss = 0.000000 (0.836 sec/batch), lr: 0.000100
2021-07-12 18:37:56.895169: step 17420/164800 (epoch 9/80),jp_loss = 0.000244, trig_loss = 0.000641, rela_loss = 0.000010, bind_loss = 0.000000 (0.933 sec/batch), lr: 0.000100
2021-07-12 18:38:31.644397: step 17440/164800 (epoch 9/80),jp_loss = 0.000702, trig_loss = 0.000336, rela_loss = 0.002504, bind_loss = 0.000000 (2.535 sec/batch), lr: 0.000100
2021-07-12 18:39:07.434119: step 17460/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.000305, rela_loss = 0.000018, bind_loss = 0.000000 (0.627 sec/batch), lr: 0.000100
2021-07-12 18:39:51.469425: step 17480/164800 (epoch 9/80),jp_loss = 0.002411, trig_loss = 0.002594, rela_loss = 0.000116, bind_loss = 0.000000 (1.165 sec/batch), lr: 0.000100
2021-07-12 18:40:27.787110: step 17500/164800 (epoch 9/80),jp_loss = 0.000366, trig_loss = 0.004456, rela_loss = 0.000025, bind_loss = 0.000000 (2.372 sec/batch), lr: 0.000100
2021-07-12 18:41:01.993690: step 17520/164800 (epoch 9/80),jp_loss = 0.005005, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (1.609 sec/batch), lr: 0.000100
2021-07-12 18:41:31.834015: step 17540/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.000275, rela_loss = 0.000010, bind_loss = 0.000000 (0.974 sec/batch), lr: 0.000100
2021-07-12 18:42:06.909561: step 17560/164800 (epoch 9/80),jp_loss = 0.000214, trig_loss = 0.000916, rela_loss = 0.000087, bind_loss = 0.000000 (1.354 sec/batch), lr: 0.000100
2021-07-12 18:42:33.297098: step 17580/164800 (epoch 9/80),jp_loss = 0.000549, trig_loss = 0.000610, rela_loss = 0.022434, bind_loss = 0.000222 (1.955 sec/batch), lr: 0.000100
2021-07-12 18:43:15.060658: step 17600/164800 (epoch 9/80),jp_loss = 0.000702, trig_loss = 0.000351, rela_loss = 0.000292, bind_loss = 0.000000 (1.236 sec/batch), lr: 0.000100
2021-07-12 18:43:53.652366: step 17620/164800 (epoch 9/80),jp_loss = 0.000229, trig_loss = 0.000320, rela_loss = 0.001224, bind_loss = 0.000000 (0.607 sec/batch), lr: 0.000100
2021-07-12 18:44:27.330757: step 17640/164800 (epoch 9/80),jp_loss = 0.000092, trig_loss = 0.000336, rela_loss = 0.001503, bind_loss = 0.080931 (0.739 sec/batch), lr: 0.000100
2021-07-12 18:44:57.537339: step 17660/164800 (epoch 9/80),jp_loss = 0.000244, trig_loss = 0.001160, rela_loss = 0.000001, bind_loss = 0.000130 (1.757 sec/batch), lr: 0.000100
2021-07-12 18:45:27.367973: step 17680/164800 (epoch 9/80),jp_loss = 0.001251, trig_loss = 0.000275, rela_loss = 0.000001, bind_loss = 0.000000 (0.460 sec/batch), lr: 0.000100
2021-07-12 18:45:59.394449: step 17700/164800 (epoch 9/80),jp_loss = 0.000610, trig_loss = 0.000305, rela_loss = 0.000510, bind_loss = 0.006015 (3.132 sec/batch), lr: 0.000100
2021-07-12 18:46:40.319654: step 17720/164800 (epoch 9/80),jp_loss = 6.692062, trig_loss = 10.073074, rela_loss = 0.000005, bind_loss = 0.000000 (3.329 sec/batch), lr: 0.000100
2021-07-12 18:47:14.902125: step 17740/164800 (epoch 9/80),jp_loss = 0.000214, trig_loss = 0.003479, rela_loss = 0.000007, bind_loss = 0.000000 (1.607 sec/batch), lr: 0.000100
2021-07-12 18:47:55.060741: step 17760/164800 (epoch 9/80),jp_loss = 0.000641, trig_loss = 0.001251, rela_loss = 0.000000, bind_loss = 0.000995 (2.999 sec/batch), lr: 0.000100
2021-07-12 18:48:26.416197: step 17780/164800 (epoch 9/80),jp_loss = 0.000305, trig_loss = 5.962402, rela_loss = 0.000011, bind_loss = 0.000000 (1.497 sec/batch), lr: 0.000100
2021-07-12 18:49:14.868276: step 17800/164800 (epoch 9/80),jp_loss = 0.000458, trig_loss = 5.124954, rela_loss = 0.000554, bind_loss = 0.000000 (3.285 sec/batch), lr: 0.000100
2021-07-12 18:49:44.718593: step 17820/164800 (epoch 9/80),jp_loss = 0.000488, trig_loss = 0.002563, rela_loss = 0.000000, bind_loss = 0.000000 (1.607 sec/batch), lr: 0.000100
2021-07-12 18:50:20.946962: step 17840/164800 (epoch 9/80),jp_loss = 0.000214, trig_loss = 0.003601, rela_loss = 0.001968, bind_loss = 0.000000 (1.237 sec/batch), lr: 0.000100
2021-07-12 18:51:05.844274: step 17860/164800 (epoch 9/80),jp_loss = 0.001343, trig_loss = 0.000793, rela_loss = 0.000001, bind_loss = 0.244299 (2.223 sec/batch), lr: 0.000100
2021-07-12 18:51:49.405282: step 17880/164800 (epoch 9/80),jp_loss = 0.000336, trig_loss = 0.040466, rela_loss = 0.001909, bind_loss = 0.000000 (1.422 sec/batch), lr: 0.000100
2021-07-12 18:52:21.815235: step 17900/164800 (epoch 9/80),jp_loss = 0.000168, trig_loss = 8.787567, rela_loss = 0.000380, bind_loss = 0.000000 (1.389 sec/batch), lr: 0.000100
2021-07-12 18:52:52.350899: step 17920/164800 (epoch 9/80),jp_loss = 0.000122, trig_loss = 0.000305, rela_loss = 0.000002, bind_loss = 0.000000 (1.923 sec/batch), lr: 0.000100
2021-07-12 18:53:22.577202: step 17940/164800 (epoch 9/80),jp_loss = 0.000626, trig_loss = 0.001282, rela_loss = 0.000345, bind_loss = 0.000074 (2.111 sec/batch), lr: 0.000100
2021-07-12 18:53:56.065506: step 17960/164800 (epoch 9/80),jp_loss = 0.000488, trig_loss = 0.000732, rela_loss = 0.072259, bind_loss = 0.000000 (2.475 sec/batch), lr: 0.000100
2021-07-12 18:54:32.674132: step 17980/164800 (epoch 9/80),jp_loss = 0.000244, trig_loss = 0.000641, rela_loss = 0.000005, bind_loss = 0.000000 (1.010 sec/batch), lr: 0.000100
2021-07-12 18:55:16.803546: step 18000/164800 (epoch 9/80),jp_loss = 0.001274, trig_loss = 0.000435, rela_loss = 0.001442, bind_loss = 0.000000 (1.233 sec/batch), lr: 0.000100
2021-07-12 18:55:41.068445: step 18020/164800 (epoch 9/80),jp_loss = 0.000275, trig_loss = 0.011475, rela_loss = 0.002156, bind_loss = 0.000000 (2.032 sec/batch), lr: 0.000100
2021-07-12 18:56:33.418628: step 18040/164800 (epoch 9/80),jp_loss = 0.000488, trig_loss = 0.046265, rela_loss = 0.699662, bind_loss = 0.000000 (3.673 sec/batch), lr: 0.000100
2021-07-12 18:57:04.583735: step 18060/164800 (epoch 9/80),jp_loss = 0.000122, trig_loss = 0.003082, rela_loss = 0.000010, bind_loss = 0.000000 (2.167 sec/batch), lr: 0.000100
2021-07-12 18:57:40.707401: step 18080/164800 (epoch 9/80),jp_loss = 2.741852, trig_loss = 0.002167, rela_loss = 0.000040, bind_loss = 0.000000 (1.919 sec/batch), lr: 0.000100
2021-07-12 18:58:12.917656: step 18100/164800 (epoch 9/80),jp_loss = 0.000435, trig_loss = 0.000198, rela_loss = 0.000000, bind_loss = 0.000000 (0.515 sec/batch), lr: 0.000100
2021-07-12 18:58:54.331900: step 18120/164800 (epoch 9/80),jp_loss = 0.000549, trig_loss = 0.001221, rela_loss = 0.000004, bind_loss = 0.000000 (1.723 sec/batch), lr: 0.000100
2021-07-12 18:59:25.583874: step 18140/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.000366, rela_loss = 1.863536, bind_loss = 0.000000 (1.233 sec/batch), lr: 0.000100
2021-07-12 18:59:45.705627: step 18160/164800 (epoch 9/80),jp_loss = 0.000504, trig_loss = 0.001465, rela_loss = 0.000005, bind_loss = 0.000000 (0.910 sec/batch), lr: 0.000100
2021-07-12 19:00:11.653451: step 18180/164800 (epoch 9/80),jp_loss = 0.000153, trig_loss = 0.000397, rela_loss = 0.000000, bind_loss = 0.000000 (1.997 sec/batch), lr: 0.000100
2021-07-12 19:00:36.340023: step 18200/164800 (epoch 9/80),jp_loss = 0.000305, trig_loss = 0.000244, rela_loss = 0.000030, bind_loss = 0.000000 (0.661 sec/batch), lr: 0.000100
2021-07-12 19:01:03.761200: step 18220/164800 (epoch 9/80),jp_loss = 0.000443, trig_loss = 0.005737, rela_loss = 0.000006, bind_loss = 0.000000 (2.387 sec/batch), lr: 0.000100
2021-07-12 19:01:30.525772: step 18240/164800 (epoch 9/80),jp_loss = 0.003296, trig_loss = 0.000366, rela_loss = 0.000607, bind_loss = 0.000000 (1.529 sec/batch), lr: 0.000100
2021-07-12 19:02:00.201526: step 18260/164800 (epoch 9/80),jp_loss = 0.000244, trig_loss = 0.000366, rela_loss = 0.000047, bind_loss = 0.000000 (1.775 sec/batch), lr: 0.000100
2021-07-12 19:02:38.852600: step 18280/164800 (epoch 9/80),jp_loss = 0.001053, trig_loss = 0.001114, rela_loss = 0.000005, bind_loss = 0.000105 (3.182 sec/batch), lr: 0.000100
2021-07-12 19:03:10.218135: step 18300/164800 (epoch 9/80),jp_loss = 0.000183, trig_loss = 0.019409, rela_loss = 0.000013, bind_loss = 0.000000 (0.913 sec/batch), lr: 0.000100
2021-07-12 19:03:45.206756: step 18320/164800 (epoch 9/80),jp_loss = 0.003098, trig_loss = 0.000732, rela_loss = 1.038078, bind_loss = 0.000000 (3.674 sec/batch), lr: 0.000100
2021-07-12 19:04:36.001819: step 18340/164800 (epoch 9/80),jp_loss = 3.158539, trig_loss = 0.011322, rela_loss = 0.002677, bind_loss = 0.000000 (1.986 sec/batch), lr: 0.000100
2021-07-12 19:05:07.714430: step 18360/164800 (epoch 9/80),jp_loss = 0.000214, trig_loss = 0.000732, rela_loss = 0.000572, bind_loss = 0.000000 (2.370 sec/batch), lr: 0.000100
2021-07-12 19:05:58.916103: step 18380/164800 (epoch 9/80),jp_loss = 0.000244, trig_loss = 0.000305, rela_loss = 0.000482, bind_loss = 0.000000 (0.987 sec/batch), lr: 0.000100
2021-07-12 19:06:29.926868: step 18400/164800 (epoch 9/80),jp_loss = 0.000610, trig_loss = 0.027161, rela_loss = 0.000797, bind_loss = 0.000000 (4.368 sec/batch), lr: 0.000100
2021-07-12 19:07:05.613776: step 18420/164800 (epoch 9/80),jp_loss = 0.000153, trig_loss = 0.000183, rela_loss = 0.000022, bind_loss = 0.000000 (0.942 sec/batch), lr: 0.000100
2021-07-12 19:07:40.731860: step 18440/164800 (epoch 9/80),jp_loss = 0.000793, trig_loss = 8.620026, rela_loss = 0.000009, bind_loss = 0.000069 (4.225 sec/batch), lr: 0.000100
2021-07-12 19:08:10.052954: step 18460/164800 (epoch 9/80),jp_loss = 0.000473, trig_loss = 0.004822, rela_loss = 0.000001, bind_loss = 0.000000 (1.303 sec/batch), lr: 0.000100
2021-07-12 19:08:48.256691: step 18480/164800 (epoch 9/80),jp_loss = 0.000458, trig_loss = 0.022156, rela_loss = 0.000209, bind_loss = 0.000000 (1.738 sec/batch), lr: 0.000100
2021-07-12 19:09:21.162300: step 18500/164800 (epoch 9/80),jp_loss = 0.000122, trig_loss = 0.000244, rela_loss = 0.000000, bind_loss = 0.000000 (1.266 sec/batch), lr: 0.000100
2021-07-12 19:09:56.625406: step 18520/164800 (epoch 9/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 1.637497, bind_loss = 0.000518 (1.858 sec/batch), lr: 0.000100
2021-07-12 19:10:32.159852: step 18540/164800 (epoch 9/80),jp_loss = 0.000061, trig_loss = 0.005463, rela_loss = 0.000000, bind_loss = 0.000000 (2.208 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.31%  R:  99.59%  F1:  99.45%  #: 2174

Final Score:
Precision (micro): 99.312%
   Recall (micro): 99.586%
       F1 (micro): 99.449%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  97.32%  R:  97.64%  F1:  97.48%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  95.26%  R:  97.14%  F1:  96.19%  #: 455
Localization         P:  99.44%  R:  99.44%  F1:  99.44%  #: 178
Negative_regulation  P:  95.58%  R:  97.62%  F1:  96.59%  #: 421
Phosphorylation      P:  96.84%  R:  98.71%  F1:  97.76%  #: 155
Positive_regulation  P:  96.11%  R:  94.58%  F1:  95.34%  #: 627
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  91.55%  R:  94.66%  F1:  93.08%  #: 206
Transcription        P:  89.55%  R:  89.55%  F1:  89.55%  #: 67

Final Score:
Precision (micro): 95.723%
   Recall (micro): 96.272%
       F1 (micro): 95.997%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  96.07%  R:  95.29%  F1:  95.68%  #: 488
Gene_expression      P:  95.06%  R:  95.71%  F1:  95.38%  #: 583
Localization         P:  97.37%  R:  96.35%  F1:  96.86%  #: 192
Negative_regulation  P:  89.25%  R:  92.52%  F1:  90.85%  #: 655
Phosphorylation      P:  96.97%  R:  97.46%  F1:  97.22%  #: 197
Positive_regulation  P:  90.24%  R:  90.14%  F1:  90.19%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  84.52%  R:  91.61%  F1:  87.92%  #: 286
Transcription        P:  88.64%  R:  87.64%  F1:  88.14%  #: 89

Final Score:
Precision (micro): 91.917%
   Recall (micro): 93.146%
       F1 (micro): 92.527%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  87.37%  R:  92.74%  F1:  89.97%  #: 179

Final Score:
Precision (micro): 87.368%
   Recall (micro): 92.737%
       F1 (micro): 89.973%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  88.25%  R:  91.50%  F1:  89.85%  #: 353

Gene_expression      P:  95.55%  R:  95.71%  F1:  95.63%  #: 583

Localization         P:  97.37%  R:  96.35%  F1:  96.86%  #: 192

Negative_regulation  P:  87.36%  R:  73.22%  F1:  79.66%  #: 519

Phosphorylation      P:  90.32%  R:  87.96%  F1:  89.12%  #: 191

Positive_regulation  P:  89.92%  R:  75.35%  F1:  81.99%  #: 852

Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30

Regulation           P:  89.59%  R:  73.61%  F1:  80.82%  #: 269

Transcription        P:  89.66%  R:  87.64%  F1:  88.64%  #: 89

Final Score:
Precision (micro): 91.042%
   Recall (micro): 83.203%
       F1 (micro): 86.946%
epoch 9: train_loss = 0.178343, dev_loss = 0.000000, dev_rela_f1 = 0.8695
0.8694618910202002 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_9.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8694618910202002 ---- 9

2021-07-12 19:22:54.874443: step 18560/164800 (epoch 10/80),jp_loss = 0.000275, trig_loss = 0.035919, rela_loss = 0.000000, bind_loss = 0.000000 (2.216 sec/batch), lr: 0.000100
2021-07-12 19:23:31.948181: step 18580/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 7.144623, rela_loss = 0.007417, bind_loss = 0.000000 (0.998 sec/batch), lr: 0.000100
2021-07-12 19:24:20.324975: step 18600/164800 (epoch 10/80),jp_loss = 0.001648, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (0.944 sec/batch), lr: 0.000100
2021-07-12 19:24:52.556595: step 18620/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.002075, rela_loss = 0.000000, bind_loss = 0.000000 (0.815 sec/batch), lr: 0.000100
2021-07-12 19:25:37.663145: step 18640/164800 (epoch 10/80),jp_loss = 0.000046, trig_loss = 0.002686, rela_loss = 0.001038, bind_loss = 0.000000 (0.951 sec/batch), lr: 0.000100
2021-07-12 19:26:14.250364: step 18660/164800 (epoch 10/80),jp_loss = 0.000183, trig_loss = 2.989258, rela_loss = 0.000004, bind_loss = 0.000000 (1.807 sec/batch), lr: 0.000100
2021-07-12 19:26:55.097544: step 18680/164800 (epoch 10/80),jp_loss = 0.000145, trig_loss = 0.000175, rela_loss = 0.000019, bind_loss = 0.000049 (0.790 sec/batch), lr: 0.000100
2021-07-12 19:27:25.352275: step 18700/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.000153, rela_loss = 0.000025, bind_loss = 0.000000 (1.202 sec/batch), lr: 0.000100
2021-07-12 19:28:05.445463: step 18720/164800 (epoch 10/80),jp_loss = 0.000275, trig_loss = 0.006744, rela_loss = 0.003434, bind_loss = 0.000000 (1.755 sec/batch), lr: 0.000100
2021-07-12 19:28:34.477393: step 18740/164800 (epoch 10/80),jp_loss = 0.000137, trig_loss = 0.002487, rela_loss = 0.123613, bind_loss = 0.000000 (1.555 sec/batch), lr: 0.000100
2021-07-12 19:29:08.610405: step 18760/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.000702, rela_loss = 0.000019, bind_loss = 0.000000 (0.898 sec/batch), lr: 0.000100
2021-07-12 19:29:54.386040: step 18780/164800 (epoch 10/80),jp_loss = 0.000183, trig_loss = 3.953918, rela_loss = 0.000003, bind_loss = 0.000000 (1.008 sec/batch), lr: 0.000100
2021-07-12 19:30:28.868464: step 18800/164800 (epoch 10/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000006, bind_loss = 0.000000 (1.390 sec/batch), lr: 0.000100
2021-07-12 19:31:11.837444: step 18820/164800 (epoch 10/80),jp_loss = 0.000099, trig_loss = 0.000244, rela_loss = 0.000947, bind_loss = 0.000000 (0.503 sec/batch), lr: 0.000100
2021-07-12 19:31:52.111621: step 18840/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.000153, rela_loss = 0.000089, bind_loss = 0.000000 (0.806 sec/batch), lr: 0.000100
2021-07-12 19:32:27.673882: step 18860/164800 (epoch 10/80),jp_loss = 0.000076, trig_loss = 0.073090, rela_loss = 0.017712, bind_loss = 0.000000 (1.455 sec/batch), lr: 0.000100
2021-07-12 19:33:06.882727: step 18880/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (0.695 sec/batch), lr: 0.000100
2021-07-12 19:33:46.162715: step 18900/164800 (epoch 10/80),jp_loss = 0.000198, trig_loss = 0.000244, rela_loss = 0.000043, bind_loss = 0.000000 (0.958 sec/batch), lr: 0.000100
2021-07-12 19:34:13.646918: step 18920/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.057892, rela_loss = 0.000066, bind_loss = 0.000490 (2.464 sec/batch), lr: 0.000100
2021-07-12 19:34:40.650163: step 18940/164800 (epoch 10/80),jp_loss = 0.003296, trig_loss = 7.138000, rela_loss = 0.000006, bind_loss = 0.000000 (0.936 sec/batch), lr: 0.000100
2021-07-12 19:35:27.320654: step 18960/164800 (epoch 10/80),jp_loss = 0.000519, trig_loss = 0.010498, rela_loss = 0.000025, bind_loss = 0.000000 (2.620 sec/batch), lr: 0.000100
2021-07-12 19:36:01.053593: step 18980/164800 (epoch 10/80),jp_loss = 0.003235, trig_loss = 0.000977, rela_loss = 0.000000, bind_loss = 0.000000 (1.198 sec/batch), lr: 0.000100
2021-07-12 19:36:32.279390: step 19000/164800 (epoch 10/80),jp_loss = 0.002380, trig_loss = 0.000336, rela_loss = 0.000041, bind_loss = 0.000218 (1.319 sec/batch), lr: 0.000100
2021-07-12 19:37:29.848026: step 19020/164800 (epoch 10/80),jp_loss = 0.000671, trig_loss = 0.027100, rela_loss = 0.000000, bind_loss = 0.000000 (6.741 sec/batch), lr: 0.000100
2021-07-12 19:37:59.063221: step 19040/164800 (epoch 10/80),jp_loss = 0.000183, trig_loss = 0.000092, rela_loss = 0.000001, bind_loss = 0.000000 (0.776 sec/batch), lr: 0.000100
2021-07-12 19:38:34.773745: step 19060/164800 (epoch 10/80),jp_loss = 0.000244, trig_loss = 0.000061, rela_loss = 0.000018, bind_loss = 0.000000 (1.040 sec/batch), lr: 0.000100
2021-07-12 19:39:19.378934: step 19080/164800 (epoch 10/80),jp_loss = 0.000244, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000000 (0.965 sec/batch), lr: 0.000100
2021-07-12 19:40:03.416371: step 19100/164800 (epoch 10/80),jp_loss = 0.000763, trig_loss = 0.005371, rela_loss = 0.122476, bind_loss = 0.000000 (4.051 sec/batch), lr: 0.000100
2021-07-12 19:40:47.477147: step 19120/164800 (epoch 10/80),jp_loss = 0.000397, trig_loss = 0.035370, rela_loss = 0.000091, bind_loss = 0.000000 (2.076 sec/batch), lr: 0.000100
2021-07-12 19:41:18.440232: step 19140/164800 (epoch 10/80),jp_loss = 0.000412, trig_loss = 0.000336, rela_loss = 0.000033, bind_loss = 0.000000 (2.319 sec/batch), lr: 0.000100
2021-07-12 19:41:53.511224: step 19160/164800 (epoch 10/80),jp_loss = 0.004364, trig_loss = 0.000519, rela_loss = 0.000009, bind_loss = 0.000160 (3.726 sec/batch), lr: 0.000100
2021-07-12 19:42:33.870567: step 19180/164800 (epoch 10/80),jp_loss = 0.000275, trig_loss = 0.002563, rela_loss = 0.000000, bind_loss = 0.000000 (1.982 sec/batch), lr: 0.000100
2021-07-12 19:43:03.721084: step 19200/164800 (epoch 10/80),jp_loss = 0.000366, trig_loss = 0.000214, rela_loss = 0.000026, bind_loss = 0.000000 (0.673 sec/batch), lr: 0.000100
2021-07-12 19:43:34.163679: step 19220/164800 (epoch 10/80),jp_loss = 0.000580, trig_loss = 0.000610, rela_loss = 0.000003, bind_loss = 0.000000 (1.407 sec/batch), lr: 0.000100
2021-07-12 19:44:07.679114: step 19240/164800 (epoch 10/80),jp_loss = 0.000046, trig_loss = 0.013885, rela_loss = 0.000028, bind_loss = 0.000000 (1.602 sec/batch), lr: 0.000100
2021-07-12 19:44:42.718456: step 19260/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.000763, rela_loss = 0.000096, bind_loss = 0.000000 (0.939 sec/batch), lr: 0.000100
2021-07-12 19:45:17.813899: step 19280/164800 (epoch 10/80),jp_loss = 0.000885, trig_loss = 0.000488, rela_loss = 0.000000, bind_loss = 0.000000 (1.813 sec/batch), lr: 0.000100
2021-07-12 19:46:00.125780: step 19300/164800 (epoch 10/80),jp_loss = 0.002899, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (1.073 sec/batch), lr: 0.000100
2021-07-12 19:46:41.526663: step 19320/164800 (epoch 10/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000014, bind_loss = 0.000000 (0.443 sec/batch), lr: 0.000100
2021-07-12 19:47:32.033405: step 19340/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.008453, rela_loss = 0.000000, bind_loss = 0.000000 (1.280 sec/batch), lr: 0.000100
2021-07-12 19:48:07.577369: step 19360/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.003113, rela_loss = 0.000485, bind_loss = 0.000000 (1.992 sec/batch), lr: 0.000100
2021-07-12 19:48:49.326644: step 19380/164800 (epoch 10/80),jp_loss = 0.000458, trig_loss = 0.000671, rela_loss = 0.000000, bind_loss = 0.233107 (5.636 sec/batch), lr: 0.000100
2021-07-12 19:49:22.054466: step 19400/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.175 sec/batch), lr: 0.000100
2021-07-12 19:49:57.113115: step 19420/164800 (epoch 10/80),jp_loss = 0.000183, trig_loss = 0.002197, rela_loss = 0.000000, bind_loss = 0.000000 (3.250 sec/batch), lr: 0.000100
2021-07-12 19:50:28.683142: step 19440/164800 (epoch 10/80),jp_loss = 6.166580, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.660 sec/batch), lr: 0.000100
2021-07-12 19:51:06.604398: step 19460/164800 (epoch 10/80),jp_loss = 0.000000, trig_loss = 0.000305, rela_loss = 0.000010, bind_loss = 0.000000 (0.874 sec/batch), lr: 0.000100
2021-07-12 19:51:49.445633: step 19480/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.662903, rela_loss = 0.000075, bind_loss = 0.000000 (0.879 sec/batch), lr: 0.000100
2021-07-12 19:52:27.051324: step 19500/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.000275, rela_loss = 0.000180, bind_loss = 0.000000 (2.579 sec/batch), lr: 0.000100
2021-07-12 19:53:03.999807: step 19520/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.392670, rela_loss = 0.000118, bind_loss = 0.000000 (0.784 sec/batch), lr: 0.000100
2021-07-12 19:53:49.756987: step 19540/164800 (epoch 10/80),jp_loss = 0.102905, trig_loss = 0.003784, rela_loss = 0.002709, bind_loss = 0.000000 (1.079 sec/batch), lr: 0.000100
2021-07-12 19:54:28.263653: step 19560/164800 (epoch 10/80),jp_loss = 0.000366, trig_loss = 0.021576, rela_loss = 0.000026, bind_loss = 0.000000 (2.645 sec/batch), lr: 0.000100
2021-07-12 19:55:04.021306: step 19580/164800 (epoch 10/80),jp_loss = 0.000824, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (1.522 sec/batch), lr: 0.000100
2021-07-12 19:55:34.999420: step 19600/164800 (epoch 10/80),jp_loss = 0.000137, trig_loss = 0.000153, rela_loss = 0.000033, bind_loss = 0.000000 (0.922 sec/batch), lr: 0.000100
2021-07-12 19:56:11.758709: step 19620/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.026733, rela_loss = 0.000201, bind_loss = 0.000000 (1.491 sec/batch), lr: 0.000100
2021-07-12 19:56:39.372035: step 19640/164800 (epoch 10/80),jp_loss = 0.000366, trig_loss = 0.000183, rela_loss = 0.464275, bind_loss = 0.000916 (1.767 sec/batch), lr: 0.000100
2021-07-12 19:57:23.091765: step 19660/164800 (epoch 10/80),jp_loss = 0.000214, trig_loss = 0.000046, rela_loss = 0.000337, bind_loss = 0.000000 (1.604 sec/batch), lr: 0.000100
2021-07-12 19:58:03.122395: step 19680/164800 (epoch 10/80),jp_loss = 0.000015, trig_loss = 0.000381, rela_loss = 0.002392, bind_loss = 0.000000 (0.632 sec/batch), lr: 0.000100
2021-07-12 19:58:38.851592: step 19700/164800 (epoch 10/80),jp_loss = 0.000214, trig_loss = 0.000168, rela_loss = 0.000224, bind_loss = 0.175586 (0.892 sec/batch), lr: 0.000100
2021-07-12 19:59:09.670580: step 19720/164800 (epoch 10/80),jp_loss = 0.000214, trig_loss = 0.000244, rela_loss = 0.000112, bind_loss = 0.002371 (1.815 sec/batch), lr: 0.000100
2021-07-12 19:59:39.833776: step 19740/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.000153, rela_loss = 0.000127, bind_loss = 0.000000 (0.497 sec/batch), lr: 0.000100
2021-07-12 20:00:12.660936: step 19760/164800 (epoch 10/80),jp_loss = 0.001068, trig_loss = 0.000183, rela_loss = 0.000503, bind_loss = 0.105036 (4.168 sec/batch), lr: 0.000100
2021-07-12 20:00:54.313271: step 19780/164800 (epoch 10/80),jp_loss = 4.315445, trig_loss = 0.522049, rela_loss = 0.000016, bind_loss = 0.000000 (3.289 sec/batch), lr: 0.000100
2021-07-12 20:01:29.738715: step 19800/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.001251, rela_loss = 0.000307, bind_loss = 0.000000 (1.502 sec/batch), lr: 0.000100
2021-07-12 20:02:08.754618: step 19820/164800 (epoch 10/80),jp_loss = 0.000244, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000710 (2.223 sec/batch), lr: 0.000100
2021-07-12 20:02:39.818686: step 19840/164800 (epoch 10/80),jp_loss = 0.000244, trig_loss = 0.001434, rela_loss = 0.000003, bind_loss = 0.000000 (1.533 sec/batch), lr: 0.000100
2021-07-12 20:03:26.768496: step 19860/164800 (epoch 10/80),jp_loss = 0.000137, trig_loss = 11.007538, rela_loss = 0.000001, bind_loss = 0.000000 (3.713 sec/batch), lr: 0.000100
2021-07-12 20:03:55.348994: step 19880/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.003143, rela_loss = 0.000002, bind_loss = 0.000000 (1.365 sec/batch), lr: 0.000100
2021-07-12 20:04:31.392281: step 19900/164800 (epoch 10/80),jp_loss = 0.000031, trig_loss = 0.002228, rela_loss = 0.000120, bind_loss = 0.000000 (0.916 sec/batch), lr: 0.000100
2021-07-12 20:05:15.402792: step 19920/164800 (epoch 10/80),jp_loss = 0.000305, trig_loss = 0.008484, rela_loss = 0.000004, bind_loss = 0.000418 (2.200 sec/batch), lr: 0.000100
2021-07-12 20:05:57.146997: step 19940/164800 (epoch 10/80),jp_loss = 0.002747, trig_loss = 0.036636, rela_loss = 0.000275, bind_loss = 0.000000 (1.508 sec/batch), lr: 0.000100
2021-07-12 20:06:29.584777: step 19960/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 1.260971, rela_loss = 0.001160, bind_loss = 0.000000 (1.382 sec/batch), lr: 0.000100
2021-07-12 20:06:59.236010: step 19980/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.000732, rela_loss = 0.000000, bind_loss = 0.000000 (1.590 sec/batch), lr: 0.000100
2021-07-12 20:07:28.051093: step 20000/164800 (epoch 10/80),jp_loss = 0.001083, trig_loss = 0.000427, rela_loss = 0.001151, bind_loss = 0.000173 (1.975 sec/batch), lr: 0.000100
2021-07-12 20:08:01.755923: step 20020/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.000244, rela_loss = 0.000192, bind_loss = 0.000000 (2.263 sec/batch), lr: 0.000100
2021-07-12 20:08:34.344893: step 20040/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.000519, rela_loss = 0.000059, bind_loss = 0.000000 (0.858 sec/batch), lr: 0.000100
2021-07-12 20:09:12.987017: step 20060/164800 (epoch 10/80),jp_loss = 0.000496, trig_loss = 2.241592, rela_loss = 0.001748, bind_loss = 0.000000 (1.356 sec/batch), lr: 0.000100
2021-07-12 20:09:36.253384: step 20080/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 17.869293, rela_loss = 0.005390, bind_loss = 0.000000 (1.799 sec/batch), lr: 0.000100
2021-07-12 20:10:25.668763: step 20100/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.000793, rela_loss = 0.000046, bind_loss = 0.000000 (3.881 sec/batch), lr: 0.000100
2021-07-12 20:10:55.653051: step 20120/164800 (epoch 10/80),jp_loss = 0.001709, trig_loss = 0.000671, rela_loss = 0.002182, bind_loss = 0.000000 (1.365 sec/batch), lr: 0.000100
2021-07-12 20:11:33.155643: step 20140/164800 (epoch 10/80),jp_loss = 0.000183, trig_loss = 0.000488, rela_loss = 0.000048, bind_loss = 0.000000 (2.285 sec/batch), lr: 0.000100
2021-07-12 20:12:02.961497: step 20160/164800 (epoch 10/80),jp_loss = 0.000023, trig_loss = 0.000107, rela_loss = 0.000002, bind_loss = 0.000000 (0.516 sec/batch), lr: 0.000100
2021-07-12 20:12:46.430904: step 20180/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.002594, rela_loss = 0.000037, bind_loss = 0.000000 (2.304 sec/batch), lr: 0.000100
2021-07-12 20:13:23.035288: step 20200/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.001251, rela_loss = 0.052731, bind_loss = 0.000000 (1.669 sec/batch), lr: 0.000100
2021-07-12 20:13:47.480995: step 20220/164800 (epoch 10/80),jp_loss = 0.000015, trig_loss = 8.091644, rela_loss = 0.000002, bind_loss = 0.000000 (0.992 sec/batch), lr: 0.000100
2021-07-12 20:14:17.066472: step 20240/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.001160, rela_loss = 0.000000, bind_loss = 0.000000 (2.132 sec/batch), lr: 0.000100
2021-07-12 20:14:44.663839: step 20260/164800 (epoch 10/80),jp_loss = 0.000397, trig_loss = 0.000427, rela_loss = 0.000000, bind_loss = 0.000000 (0.642 sec/batch), lr: 0.000100
2021-07-12 20:15:18.968053: step 20280/164800 (epoch 10/80),jp_loss = 0.000107, trig_loss = 0.001495, rela_loss = 0.000028, bind_loss = 0.000000 (2.952 sec/batch), lr: 0.000100
2021-07-12 20:15:51.832205: step 20300/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.001007, rela_loss = 0.002131, bind_loss = 0.000000 (2.099 sec/batch), lr: 0.000100
2021-07-12 20:16:27.125970: step 20320/164800 (epoch 10/80),jp_loss = 0.223389, trig_loss = 0.028931, rela_loss = 0.000023, bind_loss = 0.000000 (1.987 sec/batch), lr: 0.000100
2021-07-12 20:17:16.138377: step 20340/164800 (epoch 10/80),jp_loss = 0.000137, trig_loss = 0.001144, rela_loss = 0.000013, bind_loss = 0.000542 (3.643 sec/batch), lr: 0.000100
2021-07-12 20:17:49.031966: step 20360/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.000793, rela_loss = 0.000002, bind_loss = 0.000000 (1.109 sec/batch), lr: 0.000100
2021-07-12 20:18:22.517106: step 20380/164800 (epoch 10/80),jp_loss = 0.000824, trig_loss = 0.002319, rela_loss = 0.213341, bind_loss = 0.000000 (3.572 sec/batch), lr: 0.000100
2021-07-12 20:19:12.895895: step 20400/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.000488, rela_loss = 0.000000, bind_loss = 0.000000 (1.965 sec/batch), lr: 0.000100
2021-07-12 20:19:45.631461: step 20420/164800 (epoch 10/80),jp_loss = 0.000153, trig_loss = 0.002670, rela_loss = 0.000090, bind_loss = 0.000000 (2.233 sec/batch), lr: 0.000100
2021-07-12 20:20:36.281340: step 20440/164800 (epoch 10/80),jp_loss = 0.000000, trig_loss = 0.000214, rela_loss = 0.000021, bind_loss = 0.000000 (0.655 sec/batch), lr: 0.000100
2021-07-12 20:21:06.388840: step 20460/164800 (epoch 10/80),jp_loss = 0.000092, trig_loss = 0.019592, rela_loss = 0.001381, bind_loss = 0.000000 (4.014 sec/batch), lr: 0.000100
2021-07-12 20:21:43.102830: step 20480/164800 (epoch 10/80),jp_loss = 0.001678, trig_loss = 0.000061, rela_loss = 0.000002, bind_loss = 0.000000 (1.102 sec/batch), lr: 0.000100
2021-07-12 20:22:17.670063: step 20500/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 13.158600, rela_loss = 0.000003, bind_loss = 0.000854 (4.657 sec/batch), lr: 0.000100
2021-07-12 20:22:47.880693: step 20520/164800 (epoch 10/80),jp_loss = 0.000122, trig_loss = 0.000275, rela_loss = 0.000001, bind_loss = 0.000000 (1.029 sec/batch), lr: 0.000100
2021-07-12 20:23:24.785971: step 20540/164800 (epoch 10/80),jp_loss = 0.000046, trig_loss = 0.004257, rela_loss = 0.000000, bind_loss = 0.000000 (1.833 sec/batch), lr: 0.000100
2021-07-12 20:23:59.319346: step 20560/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.420 sec/batch), lr: 0.000100
2021-07-12 20:24:34.374532: step 20580/164800 (epoch 10/80),jp_loss = 0.000519, trig_loss = 0.000427, rela_loss = 0.000112, bind_loss = 0.000197 (1.581 sec/batch), lr: 0.000100
2021-07-12 20:25:09.106057: step 20600/164800 (epoch 10/80),jp_loss = 0.000061, trig_loss = 0.002899, rela_loss = 0.000081, bind_loss = 0.000000 (1.616 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.27%  R:  99.72%  F1:  99.50%  #: 2174

Final Score:
Precision (micro): 99.267%
   Recall (micro): 99.724%
       F1 (micro): 99.495%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  98.98%  R:  97.64%  F1:  98.31%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  95.07%  R:  97.58%  F1:  96.31%  #: 455
Localization         P:  99.44%  R: 100.00%  F1:  99.72%  #: 178
Negative_regulation  P:  98.56%  R:  97.86%  F1:  98.21%  #: 421
Phosphorylation      P:  97.44%  R:  98.06%  F1:  97.75%  #: 155
Positive_regulation  P:  96.76%  R:  95.22%  F1:  95.98%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  91.98%  R:  94.66%  F1:  93.30%  #: 206
Transcription        P:  93.85%  R:  91.04%  F1:  92.42%  #: 67

Final Score:
Precision (micro): 96.719%
   Recall (micro): 96.600%
       F1 (micro): 96.659%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  95.88%  R:  95.49%  F1:  95.69%  #: 488
Gene_expression      P:  93.79%  R:  96.21%  F1:  94.99%  #: 581
Localization         P:  96.34%  R:  95.83%  F1:  96.08%  #: 192
Negative_regulation  P:  92.32%  R:  95.42%  F1:  93.84%  #: 655
Phosphorylation      P:  96.00%  R:  97.46%  F1:  96.73%  #: 197
Positive_regulation  P:  91.31%  R:  92.20%  F1:  91.75%  #: 923
Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30
Regulation           P:  83.33%  R:  90.91%  F1:  86.96%  #: 286
Transcription        P:  89.89%  R:  90.91%  F1:  90.40%  #: 88

Final Score:
Precision (micro): 92.347%
   Recall (micro): 94.360%
       F1 (micro): 93.343%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  86.43%  R:  96.09%  F1:  91.01%  #: 179

Final Score:
Precision (micro): 86.432%
   Recall (micro): 96.089%
       F1 (micro): 91.005%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  88.68%  R:  93.20%  F1:  90.88%  #: 353

Gene_expression      P:  94.43%  R:  96.21%  F1:  95.31%  #: 581

Localization         P:  96.34%  R:  95.83%  F1:  96.08%  #: 192

Negative_regulation  P:  89.44%  R:  76.69%  F1:  82.57%  #: 519

Phosphorylation      P:  90.81%  R:  87.96%  F1:  89.36%  #: 191

Positive_regulation  P:  90.91%  R:  73.94%  F1:  81.55%  #: 852

Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30

Regulation           P:  84.30%  R:  69.89%  F1:  76.42%  #: 269

Transcription        P:  90.91%  R:  90.91%  F1:  90.91%  #: 88

Final Score:
Precision (micro): 90.957%
   Recall (micro): 83.415%
       F1 (micro): 87.023%
epoch 10: train_loss = 0.138067, dev_loss = 0.000000, dev_rela_f1 = 0.8702
0.8702290076335879 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_10.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8702290076335879 ---- 10

2021-07-12 20:37:54.468901: step 20620/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.001495, rela_loss = 0.000000, bind_loss = 0.000000 (2.471 sec/batch), lr: 0.000100
2021-07-12 20:38:34.113556: step 20640/164800 (epoch 11/80),jp_loss = 0.000000, trig_loss = 16.719727, rela_loss = 2.405008, bind_loss = 0.000000 (0.883 sec/batch), lr: 0.000100
2021-07-12 20:39:24.854687: step 20660/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 3.457458, rela_loss = 0.000001, bind_loss = 0.000000 (0.923 sec/batch), lr: 0.000100
2021-07-12 20:39:59.265442: step 20680/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.002014, rela_loss = 0.000000, bind_loss = 0.000000 (1.079 sec/batch), lr: 0.000100
2021-07-12 20:40:45.292932: step 20700/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.001282, rela_loss = 0.000268, bind_loss = 0.000000 (0.818 sec/batch), lr: 0.000100
2021-07-12 20:41:22.383574: step 20720/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000000 (2.240 sec/batch), lr: 0.000100
2021-07-12 20:42:04.909155: step 20740/164800 (epoch 11/80),jp_loss = 0.000023, trig_loss = 0.000168, rela_loss = 0.000012, bind_loss = 0.000254 (0.699 sec/batch), lr: 0.000100
2021-07-12 20:42:34.476129: step 20760/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000013, bind_loss = 0.000000 (0.896 sec/batch), lr: 0.000100
2021-07-12 20:43:14.388984: step 20780/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.950562, rela_loss = 0.000011, bind_loss = 0.000000 (1.819 sec/batch), lr: 0.000100
2021-07-12 20:43:44.760805: step 20800/164800 (epoch 11/80),jp_loss = 0.000046, trig_loss = 0.004944, rela_loss = 0.328772, bind_loss = 0.000000 (1.943 sec/batch), lr: 0.000100
2021-07-12 20:44:18.666571: step 20820/164800 (epoch 11/80),jp_loss = 0.000015, trig_loss = 0.344833, rela_loss = 0.000019, bind_loss = 0.000000 (0.965 sec/batch), lr: 0.000100
2021-07-12 20:45:03.550238: step 20840/164800 (epoch 11/80),jp_loss = 0.000046, trig_loss = 0.002167, rela_loss = 0.000001, bind_loss = 0.000000 (0.964 sec/batch), lr: 0.000100
2021-07-12 20:45:36.822620: step 20860/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000244, rela_loss = 0.000022, bind_loss = 0.000000 (1.573 sec/batch), lr: 0.000100
2021-07-12 20:46:17.722036: step 20880/164800 (epoch 11/80),jp_loss = 0.000015, trig_loss = 0.000198, rela_loss = 0.000000, bind_loss = 0.000000 (0.541 sec/batch), lr: 0.000100
2021-07-12 20:46:57.003488: step 20900/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000008, bind_loss = 0.000000 (0.671 sec/batch), lr: 0.000100
2021-07-12 20:47:32.546943: step 20920/164800 (epoch 11/80),jp_loss = 0.000229, trig_loss = 13.042145, rela_loss = 0.000074, bind_loss = 0.000000 (1.210 sec/batch), lr: 0.000100
2021-07-12 20:48:11.260235: step 20940/164800 (epoch 11/80),jp_loss = 0.000046, trig_loss = 0.004669, rela_loss = 0.000012, bind_loss = 0.000000 (0.716 sec/batch), lr: 0.000100
2021-07-12 20:48:48.742148: step 20960/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.001282, rela_loss = 0.000000, bind_loss = 0.000000 (1.046 sec/batch), lr: 0.000100
2021-07-12 20:49:14.811165: step 20980/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.007721, rela_loss = 0.000013, bind_loss = 0.000030 (2.208 sec/batch), lr: 0.000100
2021-07-12 20:49:40.770128: step 21000/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000092, rela_loss = 0.000004, bind_loss = 0.000000 (1.060 sec/batch), lr: 0.000100
2021-07-12 20:50:25.811007: step 21020/164800 (epoch 11/80),jp_loss = 0.000916, trig_loss = 0.052582, rela_loss = 0.037242, bind_loss = 0.000000 (2.789 sec/batch), lr: 0.000100
2021-07-12 20:50:57.339883: step 21040/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.002441, rela_loss = 0.000067, bind_loss = 0.000000 (1.100 sec/batch), lr: 0.000100
2021-07-12 20:51:27.053606: step 21060/164800 (epoch 11/80),jp_loss = 0.000160, trig_loss = 0.000351, rela_loss = 0.000026, bind_loss = 0.000001 (1.198 sec/batch), lr: 0.000100
2021-07-12 20:52:20.441283: step 21080/164800 (epoch 11/80),jp_loss = 0.000671, trig_loss = 7.416687, rela_loss = 0.000002, bind_loss = 0.000000 (6.555 sec/batch), lr: 0.000100
2021-07-12 20:52:48.963573: step 21100/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000305, rela_loss = 0.018807, bind_loss = 0.000000 (0.723 sec/batch), lr: 0.000100
2021-07-12 20:53:23.791637: step 21120/164800 (epoch 11/80),jp_loss = 0.000488, trig_loss = 0.004578, rela_loss = 0.000826, bind_loss = 0.000000 (1.084 sec/batch), lr: 0.000100
2021-07-12 20:54:08.771367: step 21140/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000671, rela_loss = 0.000006, bind_loss = 0.000000 (1.117 sec/batch), lr: 0.000100
2021-07-12 20:54:50.507072: step 21160/164800 (epoch 11/80),jp_loss = 0.000214, trig_loss = 2.975006, rela_loss = 0.000403, bind_loss = 0.000000 (3.772 sec/batch), lr: 0.000100
2021-07-12 20:55:37.518015: step 21180/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.015991, rela_loss = 0.000022, bind_loss = 0.000000 (2.763 sec/batch), lr: 0.000100
2021-07-12 20:56:07.909516: step 21200/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.000549, rela_loss = 0.000003, bind_loss = 0.000000 (2.193 sec/batch), lr: 0.000100
2021-07-12 20:56:42.598263: step 21220/164800 (epoch 11/80),jp_loss = 15.604385, trig_loss = 0.065857, rela_loss = 0.000847, bind_loss = 0.002229 (3.045 sec/batch), lr: 0.000100
2021-07-12 20:57:23.533705: step 21240/164800 (epoch 11/80),jp_loss = 0.000214, trig_loss = 0.000793, rela_loss = 0.000000, bind_loss = 0.000000 (1.727 sec/batch), lr: 0.000100
2021-07-12 20:57:53.598930: step 21260/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000214, rela_loss = 0.000023, bind_loss = 0.000000 (0.686 sec/batch), lr: 0.000100
2021-07-12 20:58:25.478226: step 21280/164800 (epoch 11/80),jp_loss = 0.001495, trig_loss = 0.000488, rela_loss = 0.000006, bind_loss = 0.000000 (1.515 sec/batch), lr: 0.000100
2021-07-12 20:58:57.890498: step 21300/164800 (epoch 11/80),jp_loss = 0.000107, trig_loss = 0.008636, rela_loss = 0.001150, bind_loss = 0.000000 (1.782 sec/batch), lr: 0.000100
2021-07-12 20:59:32.672109: step 21320/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000565, rela_loss = 0.000016, bind_loss = 0.000000 (0.992 sec/batch), lr: 0.000100
2021-07-12 21:00:05.416811: step 21340/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000183, rela_loss = 0.000011, bind_loss = 0.000000 (1.624 sec/batch), lr: 0.000100
2021-07-12 21:00:45.770493: step 21360/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000366, rela_loss = 0.000038, bind_loss = 0.000000 (1.106 sec/batch), lr: 0.000100
2021-07-12 21:01:27.582370: step 21380/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000221, rela_loss = 0.000014, bind_loss = 0.000000 (0.394 sec/batch), lr: 0.000100
2021-07-12 21:02:19.472788: step 21400/164800 (epoch 11/80),jp_loss = 0.000015, trig_loss = 0.000610, rela_loss = 0.000008, bind_loss = 0.000000 (1.443 sec/batch), lr: 0.000100
2021-07-12 21:02:55.260456: step 21420/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.070038, rela_loss = 0.000019, bind_loss = 0.000000 (1.790 sec/batch), lr: 0.000100
2021-07-12 21:03:36.440996: step 21440/164800 (epoch 11/80),jp_loss = 0.000275, trig_loss = 0.012024, rela_loss = 0.000145, bind_loss = 0.006871 (5.178 sec/batch), lr: 0.000100
2021-07-12 21:04:09.471823: step 21460/164800 (epoch 11/80),jp_loss = 0.000244, trig_loss = 0.000061, rela_loss = 0.000010, bind_loss = 0.000000 (1.093 sec/batch), lr: 0.000100
2021-07-12 21:04:44.378037: step 21480/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.000977, rela_loss = 0.000001, bind_loss = 0.000000 (3.242 sec/batch), lr: 0.000100
2021-07-12 21:05:14.388679: step 21500/164800 (epoch 11/80),jp_loss = 0.000397, trig_loss = 0.000122, rela_loss = 0.000005, bind_loss = 0.000000 (0.559 sec/batch), lr: 0.000100
2021-07-12 21:05:53.810904: step 21520/164800 (epoch 11/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.000427, bind_loss = 0.000000 (0.946 sec/batch), lr: 0.000100
2021-07-12 21:06:35.652274: step 21540/164800 (epoch 11/80),jp_loss = 0.000336, trig_loss = 0.000793, rela_loss = 0.000065, bind_loss = 0.000000 (0.924 sec/batch), lr: 0.000100
2021-07-12 21:07:12.159001: step 21560/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000275, rela_loss = 0.000100, bind_loss = 0.000000 (2.930 sec/batch), lr: 0.000100
2021-07-12 21:07:49.398888: step 21580/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.201996, rela_loss = 0.015321, bind_loss = 0.000000 (0.679 sec/batch), lr: 0.000100
2021-07-12 21:08:34.846776: step 21600/164800 (epoch 11/80),jp_loss = 0.000580, trig_loss = 0.000519, rela_loss = 0.000071, bind_loss = 0.000000 (1.198 sec/batch), lr: 0.000100
2021-07-12 21:09:12.185303: step 21620/164800 (epoch 11/80),jp_loss = 0.000214, trig_loss = 0.456573, rela_loss = 0.000657, bind_loss = 0.000000 (2.493 sec/batch), lr: 0.000100
2021-07-12 21:09:48.885543: step 21640/164800 (epoch 11/80),jp_loss = 0.001602, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (1.463 sec/batch), lr: 0.000100
2021-07-12 21:10:19.007609: step 21660/164800 (epoch 11/80),jp_loss = 0.000381, trig_loss = 0.000061, rela_loss = 0.000032, bind_loss = 0.000000 (1.001 sec/batch), lr: 0.000100
2021-07-12 21:10:56.552125: step 21680/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000977, rela_loss = 0.000016, bind_loss = 0.000000 (1.607 sec/batch), lr: 0.000100
2021-07-12 21:11:23.849611: step 21700/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.001526, rela_loss = 0.038792, bind_loss = 0.000661 (1.916 sec/batch), lr: 0.000100
2021-07-12 21:12:06.726117: step 21720/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000092, rela_loss = 0.000004, bind_loss = 0.000000 (1.181 sec/batch), lr: 0.000100
2021-07-12 21:12:46.356115: step 21740/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (0.591 sec/batch), lr: 0.000100
2021-07-12 21:13:22.025235: step 21760/164800 (epoch 11/80),jp_loss = 0.000351, trig_loss = 4.773407, rela_loss = 0.155457, bind_loss = 0.000146 (0.877 sec/batch), lr: 0.000100
2021-07-12 21:13:54.122980: step 21780/164800 (epoch 11/80),jp_loss = 0.017700, trig_loss = 0.000793, rela_loss = 0.000000, bind_loss = 0.000172 (2.470 sec/batch), lr: 0.000100
2021-07-12 21:14:24.229956: step 21800/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.001144, rela_loss = 0.000000, bind_loss = 0.000000 (0.525 sec/batch), lr: 0.000100
2021-07-12 21:14:57.745575: step 21820/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.000122, rela_loss = 0.000006, bind_loss = 0.006403 (3.124 sec/batch), lr: 0.000100
2021-07-12 21:15:41.924378: step 21840/164800 (epoch 11/80),jp_loss = 0.000168, trig_loss = 0.013474, rela_loss = 0.000003, bind_loss = 0.000000 (3.434 sec/batch), lr: 0.000100
2021-07-12 21:16:16.313565: step 21860/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.000580, rela_loss = 0.000038, bind_loss = 0.000000 (1.452 sec/batch), lr: 0.000100
2021-07-12 21:16:57.568688: step 21880/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.001129, rela_loss = 0.000003, bind_loss = 0.000330 (2.315 sec/batch), lr: 0.000100
2021-07-12 21:17:28.974381: step 21900/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.042664, rela_loss = 0.000013, bind_loss = 0.000000 (1.467 sec/batch), lr: 0.000100
2021-07-12 21:18:15.976647: step 21920/164800 (epoch 11/80),jp_loss = 0.000336, trig_loss = 16.626404, rela_loss = 0.000151, bind_loss = 0.000000 (3.248 sec/batch), lr: 0.000100
2021-07-12 21:18:46.365839: step 21940/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.013184, rela_loss = 0.000004, bind_loss = 0.000000 (1.345 sec/batch), lr: 0.000100
2021-07-12 21:19:23.120220: step 21960/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.003082, rela_loss = 0.000085, bind_loss = 0.000000 (1.090 sec/batch), lr: 0.000100
2021-07-12 21:20:08.712275: step 21980/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000157 (2.167 sec/batch), lr: 0.000100
2021-07-12 21:20:52.259920: step 22000/164800 (epoch 11/80),jp_loss = 0.000015, trig_loss = 0.013306, rela_loss = 0.000031, bind_loss = 0.000000 (1.603 sec/batch), lr: 0.000100
2021-07-12 21:21:25.169002: step 22020/164800 (epoch 11/80),jp_loss = 0.000137, trig_loss = 0.140167, rela_loss = 0.001732, bind_loss = 0.000000 (1.377 sec/batch), lr: 0.000100
2021-07-12 21:21:57.085650: step 22040/164800 (epoch 11/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000000, bind_loss = 0.000000 (1.756 sec/batch), lr: 0.000100
2021-07-12 21:22:25.266444: step 22060/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.000732, rela_loss = 0.000349, bind_loss = 0.000029 (1.914 sec/batch), lr: 0.000100
2021-07-12 21:22:58.831195: step 22080/164800 (epoch 11/80),jp_loss = 10.571930, trig_loss = 0.000854, rela_loss = 0.000059, bind_loss = 0.000000 (2.156 sec/batch), lr: 0.000100
2021-07-12 21:23:30.224208: step 22100/164800 (epoch 11/80),jp_loss = 0.000076, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.779 sec/batch), lr: 0.000100
2021-07-12 21:24:10.421967: step 22120/164800 (epoch 11/80),jp_loss = 0.003750, trig_loss = 3.420067, rela_loss = 0.000059, bind_loss = 0.000000 (1.124 sec/batch), lr: 0.000100
2021-07-12 21:24:34.643305: step 22140/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.001556, rela_loss = 0.000032, bind_loss = 0.000000 (2.085 sec/batch), lr: 0.000100
2021-07-12 21:25:23.987137: step 22160/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.000916, rela_loss = 0.001378, bind_loss = 0.000000 (3.290 sec/batch), lr: 0.000100
2021-07-12 21:25:53.730674: step 22180/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.001068, rela_loss = 0.014660, bind_loss = 0.000000 (1.609 sec/batch), lr: 0.000100
2021-07-12 21:26:27.950384: step 22200/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000022, bind_loss = 0.000000 (1.823 sec/batch), lr: 0.000100
2021-07-12 21:26:57.779798: step 22220/164800 (epoch 11/80),jp_loss = 0.000076, trig_loss = 0.000275, rela_loss = 0.000006, bind_loss = 0.000000 (0.472 sec/batch), lr: 0.000100
2021-07-12 21:27:41.025312: step 22240/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 2.894135, rela_loss = 0.000019, bind_loss = 0.000000 (2.378 sec/batch), lr: 0.000100
2021-07-12 21:28:17.591558: step 22260/164800 (epoch 11/80),jp_loss = 0.000275, trig_loss = 0.000305, rela_loss = 0.000014, bind_loss = 0.000000 (1.836 sec/batch), lr: 0.000100
2021-07-12 21:28:40.930457: step 22280/164800 (epoch 11/80),jp_loss = 0.000107, trig_loss = 0.000519, rela_loss = 0.000027, bind_loss = 0.000000 (1.034 sec/batch), lr: 0.000100
2021-07-12 21:29:11.508578: step 22300/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.001190, rela_loss = 0.000072, bind_loss = 0.000000 (2.146 sec/batch), lr: 0.000100
2021-07-12 21:29:38.943110: step 22320/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.000061, rela_loss = 0.000015, bind_loss = 0.000000 (0.710 sec/batch), lr: 0.000100
2021-07-12 21:30:12.737971: step 22340/164800 (epoch 11/80),jp_loss = 0.000153, trig_loss = 0.002502, rela_loss = 0.000023, bind_loss = 0.000000 (3.118 sec/batch), lr: 0.000100
2021-07-12 21:30:43.958565: step 22360/164800 (epoch 11/80),jp_loss = 13.418396, trig_loss = 0.000336, rela_loss = 0.000846, bind_loss = 0.000000 (2.075 sec/batch), lr: 0.000100
2021-07-12 21:31:17.457319: step 22380/164800 (epoch 11/80),jp_loss = 0.000122, trig_loss = 0.000488, rela_loss = 0.000078, bind_loss = 0.000000 (1.889 sec/batch), lr: 0.000100
2021-07-12 21:32:03.163928: step 22400/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.000595, rela_loss = 0.000438, bind_loss = 0.000259 (3.594 sec/batch), lr: 0.000100
2021-07-12 21:32:34.872151: step 22420/164800 (epoch 11/80),jp_loss = 0.407715, trig_loss = 0.000153, rela_loss = 0.000006, bind_loss = 0.000000 (0.873 sec/batch), lr: 0.000100
2021-07-12 21:33:08.534130: step 22440/164800 (epoch 11/80),jp_loss = 0.001373, trig_loss = 0.000610, rela_loss = 0.007910, bind_loss = 0.000000 (3.610 sec/batch), lr: 0.000100
2021-07-12 21:33:57.838396: step 22460/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 0.001251, rela_loss = 0.000000, bind_loss = 0.000000 (1.917 sec/batch), lr: 0.000100
2021-07-12 21:34:30.213053: step 22480/164800 (epoch 11/80),jp_loss = 0.000061, trig_loss = 0.665436, rela_loss = 0.014139, bind_loss = 0.000000 (2.166 sec/batch), lr: 0.000100
2021-07-12 21:35:20.433955: step 22500/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 1.541626, rela_loss = 0.000010, bind_loss = 0.000000 (0.860 sec/batch), lr: 0.000100
2021-07-12 21:35:51.089671: step 22520/164800 (epoch 11/80),jp_loss = 0.003296, trig_loss = 0.009521, rela_loss = 0.000113, bind_loss = 0.000000 (4.619 sec/batch), lr: 0.000100
2021-07-12 21:36:27.269751: step 22540/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.874 sec/batch), lr: 0.000100
2021-07-12 21:37:01.600791: step 22560/164800 (epoch 11/80),jp_loss = 0.000092, trig_loss = 6.956055, rela_loss = 0.000170, bind_loss = 0.000142 (4.453 sec/batch), lr: 0.000100
2021-07-12 21:37:30.829435: step 22580/164800 (epoch 11/80),jp_loss = 0.000183, trig_loss = 0.000275, rela_loss = 0.000808, bind_loss = 0.000000 (1.195 sec/batch), lr: 0.000100
2021-07-12 21:38:08.354823: step 22600/164800 (epoch 11/80),jp_loss = 0.000259, trig_loss = 0.001373, rela_loss = 0.000001, bind_loss = 0.000000 (1.927 sec/batch), lr: 0.000100
2021-07-12 21:38:41.778654: step 22620/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000002, bind_loss = 0.000000 (1.603 sec/batch), lr: 0.000100
2021-07-12 21:39:17.869829: step 22640/164800 (epoch 11/80),jp_loss = 0.000214, trig_loss = 0.000305, rela_loss = 0.000081, bind_loss = 0.001582 (2.038 sec/batch), lr: 0.000100
2021-07-12 21:39:53.283455: step 22660/164800 (epoch 11/80),jp_loss = 0.000031, trig_loss = 0.111176, rela_loss = 0.000001, bind_loss = 0.000000 (1.795 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.45%  R:  99.40%  F1:  99.42%  #: 2174

Final Score:
Precision (micro): 99.448%
   Recall (micro): 99.402%
       F1 (micro): 99.425%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  98.66%  R:  99.33%  F1:  98.99%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  95.90%  R:  97.58%  F1:  96.73%  #: 455
Localization         P:  97.27%  R: 100.00%  F1:  98.61%  #: 178
Negative_regulation  P:  99.51%  R:  96.67%  F1:  98.07%  #: 421
Phosphorylation      P:  95.60%  R:  98.06%  F1:  96.82%  #: 155
Positive_regulation  P:  98.06%  R:  96.97%  F1:  97.51%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  94.34%  R:  97.09%  F1:  95.69%  #: 206
Transcription        P:  92.75%  R:  95.52%  F1:  94.12%  #: 67

Final Score:
Precision (micro): 97.219%
   Recall (micro): 97.378%
       F1 (micro): 97.298%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  93.35%  R:  97.75%  F1:  95.50%  #: 488
Gene_expression      P:  94.96%  R:  96.91%  F1:  95.93%  #: 583
Localization         P:  95.92%  R:  97.92%  F1:  96.91%  #: 192
Negative_regulation  P:  93.04%  R:  93.89%  F1:  93.47%  #: 655
Phosphorylation      P:  95.07%  R:  97.97%  F1:  96.50%  #: 197
Positive_regulation  P:  92.30%  R:  94.80%  F1:  93.53%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  90.00%  R:  94.41%  F1:  92.15%  #: 286
Transcription        P:  90.32%  R:  95.45%  F1:  92.82%  #: 88

Final Score:
Precision (micro): 93.160%
   Recall (micro): 95.758%
       F1 (micro): 94.441%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  85.57%  R:  95.03%  F1:  90.05%  #: 181

Final Score:
Precision (micro): 85.572%
   Recall (micro): 95.028%
       F1 (micro): 90.052%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  87.96%  R:  95.18%  F1:  91.43%  #: 353

Gene_expression      P:  95.28%  R:  96.91%  F1:  96.09%  #: 583

Localization         P:  95.92%  R:  97.92%  F1:  96.91%  #: 192

Negative_regulation  P:  87.47%  R:  76.69%  F1:  81.72%  #: 519

Phosphorylation      P:  88.95%  R:  88.48%  F1:  88.71%  #: 191

Positive_regulation  P:  88.07%  R:  79.69%  F1:  83.67%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  87.61%  R:  76.21%  F1:  81.51%  #: 269

Transcription        P:  92.31%  R:  95.45%  F1:  93.85%  #: 88

Final Score:
Precision (micro): 90.146%
   Recall (micro): 86.220%
       F1 (micro): 88.140%
epoch 11: train_loss = 0.134898, dev_loss = 0.000000, dev_rela_f1 = 0.8814
0.8813953488372092 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_11.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.8813953488372092 ---- 11

2021-07-12 21:52:35.085648: step 22680/164800 (epoch 12/80),jp_loss = 0.000427, trig_loss = 0.001495, rela_loss = 0.000000, bind_loss = 0.000000 (2.505 sec/batch), lr: 0.000100
2021-07-12 21:53:14.569765: step 22700/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 8.997345, rela_loss = 0.000402, bind_loss = 0.000000 (1.168 sec/batch), lr: 0.000100
2021-07-12 21:54:06.599549: step 22720/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.004150, rela_loss = 0.000001, bind_loss = 0.000000 (1.055 sec/batch), lr: 0.000100
2021-07-12 21:54:39.720370: step 22740/164800 (epoch 12/80),jp_loss = 0.000153, trig_loss = 0.000732, rela_loss = 0.000000, bind_loss = 0.000000 (0.796 sec/batch), lr: 0.000100
2021-07-12 21:55:26.659825: step 22760/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.001984, rela_loss = 0.001223, bind_loss = 0.000000 (0.823 sec/batch), lr: 0.000100
2021-07-12 21:56:04.583804: step 22780/164800 (epoch 12/80),jp_loss = 0.000305, trig_loss = 0.003174, rela_loss = 0.000004, bind_loss = 0.000000 (1.700 sec/batch), lr: 0.000100
2021-07-12 21:56:47.194215: step 22800/164800 (epoch 12/80),jp_loss = 0.000053, trig_loss = 0.000107, rela_loss = 0.000144, bind_loss = 0.000076 (0.811 sec/batch), lr: 0.000100
2021-07-12 21:57:17.421833: step 22820/164800 (epoch 12/80),jp_loss = 0.000137, trig_loss = 0.000153, rela_loss = 0.000016, bind_loss = 0.000000 (1.073 sec/batch), lr: 0.000100
2021-07-12 21:57:58.451559: step 22840/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 5.517456, rela_loss = 0.012731, bind_loss = 0.000000 (1.730 sec/batch), lr: 0.000100
2021-07-12 21:58:28.986816: step 22860/164800 (epoch 12/80),jp_loss = 0.000397, trig_loss = 0.025955, rela_loss = 0.000903, bind_loss = 0.000000 (1.798 sec/batch), lr: 0.000100
2021-07-12 21:59:04.370008: step 22880/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.028839, rela_loss = 0.000017, bind_loss = 0.000000 (0.805 sec/batch), lr: 0.000100
2021-07-12 21:59:50.785632: step 22900/164800 (epoch 12/80),jp_loss = 0.000427, trig_loss = 0.000244, rela_loss = 0.000001, bind_loss = 0.000000 (0.938 sec/batch), lr: 0.000100
2021-07-12 22:00:24.836085: step 22920/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000006, bind_loss = 0.000000 (1.718 sec/batch), lr: 0.000100
2021-07-12 22:01:07.603679: step 22940/164800 (epoch 12/80),jp_loss = 0.000046, trig_loss = 0.000137, rela_loss = 0.000010, bind_loss = 0.000000 (0.600 sec/batch), lr: 0.000100
2021-07-12 22:01:47.547479: step 22960/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000093, bind_loss = 0.000000 (0.718 sec/batch), lr: 0.000100
2021-07-12 22:02:23.533184: step 22980/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.102417, rela_loss = 0.000448, bind_loss = 0.000000 (1.405 sec/batch), lr: 0.000100
2021-07-12 22:03:03.170154: step 23000/164800 (epoch 12/80),jp_loss = 0.000137, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.719 sec/batch), lr: 0.000100
2021-07-12 22:03:41.110305: step 23020/164800 (epoch 12/80),jp_loss = 0.000458, trig_loss = 0.018280, rela_loss = 0.000094, bind_loss = 0.000000 (1.000 sec/batch), lr: 0.000100
2021-07-12 22:04:06.952057: step 23040/164800 (epoch 12/80),jp_loss = 0.000824, trig_loss = 3.238708, rela_loss = 0.000014, bind_loss = 0.000634 (2.414 sec/batch), lr: 0.000100
2021-07-12 22:04:33.098293: step 23060/164800 (epoch 12/80),jp_loss = 0.000397, trig_loss = 0.188843, rela_loss = 0.000660, bind_loss = 0.000000 (0.984 sec/batch), lr: 0.000100
2021-07-12 22:05:18.363451: step 23080/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.745300, rela_loss = 0.000076, bind_loss = 0.000000 (2.820 sec/batch), lr: 0.000100
2021-07-12 22:05:50.878257: step 23100/164800 (epoch 12/80),jp_loss = 0.000305, trig_loss = 0.000488, rela_loss = 0.000111, bind_loss = 0.000000 (1.167 sec/batch), lr: 0.000100
2021-07-12 22:06:21.249082: step 23120/164800 (epoch 12/80),jp_loss = 0.000557, trig_loss = 0.000397, rela_loss = 0.000204, bind_loss = 0.000004 (1.262 sec/batch), lr: 0.000100
2021-07-12 22:07:17.499821: step 23140/164800 (epoch 12/80),jp_loss = 0.000427, trig_loss = 0.002441, rela_loss = 0.000009, bind_loss = 0.000000 (7.069 sec/batch), lr: 0.000100
2021-07-12 22:07:46.222890: step 23160/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.000031, rela_loss = 0.000002, bind_loss = 0.000000 (0.637 sec/batch), lr: 0.000100
2021-07-12 22:08:20.411790: step 23180/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000008, bind_loss = 0.000000 (1.041 sec/batch), lr: 0.000100
2021-07-12 22:09:05.173481: step 23200/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000001, bind_loss = 0.000000 (1.152 sec/batch), lr: 0.000100
2021-07-12 22:09:46.942814: step 23220/164800 (epoch 12/80),jp_loss = 0.002167, trig_loss = 1.258148, rela_loss = 0.042129, bind_loss = 0.000000 (3.637 sec/batch), lr: 0.000100
2021-07-12 22:10:30.764486: step 23240/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 8.055939, rela_loss = 0.000001, bind_loss = 0.000000 (1.960 sec/batch), lr: 0.000100
2021-07-12 22:11:00.719591: step 23260/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.000305, rela_loss = 0.000029, bind_loss = 0.000000 (1.767 sec/batch), lr: 0.000100
2021-07-12 22:11:32.107150: step 23280/164800 (epoch 12/80),jp_loss = 0.001892, trig_loss = 0.000366, rela_loss = 0.000001, bind_loss = 0.000003 (2.398 sec/batch), lr: 0.000100
2021-07-12 22:12:11.066957: step 23300/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.004059, rela_loss = 0.000000, bind_loss = 0.000000 (1.825 sec/batch), lr: 0.000100
2021-07-12 22:12:40.766296: step 23320/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (0.756 sec/batch), lr: 0.000100
2021-07-12 22:13:09.849252: step 23340/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.000244, rela_loss = 0.025674, bind_loss = 0.000000 (1.275 sec/batch), lr: 0.000100
2021-07-12 22:13:42.032406: step 23360/164800 (epoch 12/80),jp_loss = 0.000015, trig_loss = 0.006973, rela_loss = 0.000009, bind_loss = 0.000000 (1.645 sec/batch), lr: 0.000100
2021-07-12 22:14:14.858879: step 23380/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000198, rela_loss = 0.000000, bind_loss = 0.000000 (0.802 sec/batch), lr: 0.000100
2021-07-12 22:14:47.542217: step 23400/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.427673, rela_loss = 0.000006, bind_loss = 0.000000 (1.691 sec/batch), lr: 0.000100
2021-07-12 22:15:28.619311: step 23420/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000635, bind_loss = 0.000000 (1.021 sec/batch), lr: 0.000100
2021-07-12 22:16:10.595128: step 23440/164800 (epoch 12/80),jp_loss = 0.000023, trig_loss = 0.000053, rela_loss = 0.000000, bind_loss = 0.000000 (0.447 sec/batch), lr: 0.000100
2021-07-12 22:17:00.978586: step 23460/164800 (epoch 12/80),jp_loss = 0.000137, trig_loss = 0.018188, rela_loss = 0.000000, bind_loss = 0.000000 (1.290 sec/batch), lr: 0.000100
2021-07-12 22:17:36.456722: step 23480/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 3.309174, rela_loss = 0.000001, bind_loss = 0.000000 (1.702 sec/batch), lr: 0.000100
2021-07-12 22:18:16.044570: step 23500/164800 (epoch 12/80),jp_loss = 0.004547, trig_loss = 0.001099, rela_loss = 0.000001, bind_loss = 0.328741 (4.869 sec/batch), lr: 0.000100
2021-07-12 22:18:48.121715: step 23520/164800 (epoch 12/80),jp_loss = 0.000305, trig_loss = 0.000122, rela_loss = 0.000101, bind_loss = 0.000000 (1.241 sec/batch), lr: 0.000100
2021-07-12 22:19:24.481262: step 23540/164800 (epoch 12/80),jp_loss = 0.000519, trig_loss = 0.001221, rela_loss = 0.000000, bind_loss = 0.000000 (3.410 sec/batch), lr: 0.000100
2021-07-12 22:19:55.197457: step 23560/164800 (epoch 12/80),jp_loss = 0.000984, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (0.639 sec/batch), lr: 0.000100
2021-07-12 22:20:34.399443: step 23580/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000010, bind_loss = 0.000000 (0.980 sec/batch), lr: 0.000100
2021-07-12 22:21:16.041250: step 23600/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000732, rela_loss = 0.000025, bind_loss = 0.000000 (0.786 sec/batch), lr: 0.000100
2021-07-12 22:21:51.564413: step 23620/164800 (epoch 12/80),jp_loss = 0.000122, trig_loss = 0.000061, rela_loss = 0.000028, bind_loss = 0.000000 (2.813 sec/batch), lr: 0.000100
2021-07-12 22:22:29.532669: step 23640/164800 (epoch 12/80),jp_loss = 0.000214, trig_loss = 0.015656, rela_loss = 0.000223, bind_loss = 0.000000 (0.621 sec/batch), lr: 0.000100
2021-07-12 22:23:15.123288: step 23660/164800 (epoch 12/80),jp_loss = 0.001892, trig_loss = 0.001892, rela_loss = 0.000091, bind_loss = 0.000000 (1.165 sec/batch), lr: 0.000100
2021-07-12 22:23:53.908016: step 23680/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.002838, rela_loss = 0.000003, bind_loss = 0.000000 (3.622 sec/batch), lr: 0.000100
2021-07-12 22:24:30.606847: step 23700/164800 (epoch 12/80),jp_loss = 0.003830, trig_loss = 0.000122, rela_loss = 0.000029, bind_loss = 0.000000 (1.448 sec/batch), lr: 0.000100
2021-07-12 22:25:01.905277: step 23720/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.000153, rela_loss = 0.000023, bind_loss = 0.000000 (1.148 sec/batch), lr: 0.000100
2021-07-12 22:25:37.625803: step 23740/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 4.726318, rela_loss = 0.000009, bind_loss = 0.000000 (1.406 sec/batch), lr: 0.000100
2021-07-12 22:26:04.816412: step 23760/164800 (epoch 12/80),jp_loss = 0.000275, trig_loss = 0.000122, rela_loss = 0.002423, bind_loss = 0.000874 (2.025 sec/batch), lr: 0.000100
2021-07-12 22:26:47.767120: step 23780/164800 (epoch 12/80),jp_loss = 0.002350, trig_loss = 0.000061, rela_loss = 0.002347, bind_loss = 0.000000 (1.509 sec/batch), lr: 0.000100
2021-07-12 22:27:28.263579: step 23800/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.000320, rela_loss = 0.000000, bind_loss = 0.000000 (0.690 sec/batch), lr: 0.000100
2021-07-12 22:28:04.588050: step 23820/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000046, rela_loss = 0.000518, bind_loss = 0.011168 (0.663 sec/batch), lr: 0.000100
2021-07-12 22:28:36.008327: step 23840/164800 (epoch 12/80),jp_loss = 0.000244, trig_loss = 0.000305, rela_loss = 0.000011, bind_loss = 0.000007 (2.018 sec/batch), lr: 0.000100
2021-07-12 22:29:06.973961: step 23860/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.012833, rela_loss = 0.000002, bind_loss = 0.000000 (0.526 sec/batch), lr: 0.000100
2021-07-12 22:29:39.654703: step 23880/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.000000, rela_loss = 0.000817, bind_loss = 0.008637 (3.638 sec/batch), lr: 0.000100
2021-07-12 22:30:24.685548: step 23900/164800 (epoch 12/80),jp_loss = 0.000122, trig_loss = 0.004791, rela_loss = 0.000000, bind_loss = 0.000000 (3.448 sec/batch), lr: 0.000100
2021-07-12 22:31:01.553348: step 23920/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.001648, rela_loss = 0.000002, bind_loss = 0.000000 (2.144 sec/batch), lr: 0.000100
2021-07-12 22:31:43.500839: step 23940/164800 (epoch 12/80),jp_loss = 0.000183, trig_loss = 0.000214, rela_loss = 0.000007, bind_loss = 0.000226 (2.227 sec/batch), lr: 0.000100
2021-07-12 22:32:16.416520: step 23960/164800 (epoch 12/80),jp_loss = 0.000183, trig_loss = 0.000275, rela_loss = 0.000230, bind_loss = 0.000000 (1.341 sec/batch), lr: 0.000100
2021-07-12 22:33:01.311673: step 23980/164800 (epoch 12/80),jp_loss = 0.000137, trig_loss = 9.777100, rela_loss = 0.000035, bind_loss = 0.000000 (3.312 sec/batch), lr: 0.000100
2021-07-12 22:33:31.762828: step 24000/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000763, rela_loss = 0.000182, bind_loss = 0.000000 (1.621 sec/batch), lr: 0.000100
2021-07-12 22:34:08.919444: step 24020/164800 (epoch 12/80),jp_loss = 0.000015, trig_loss = 0.004913, rela_loss = 0.000000, bind_loss = 0.000000 (0.941 sec/batch), lr: 0.000100
2021-07-12 22:34:53.868250: step 24040/164800 (epoch 12/80),jp_loss = 0.000183, trig_loss = 0.000214, rela_loss = 0.000002, bind_loss = 0.000162 (2.401 sec/batch), lr: 0.000100
2021-07-12 22:35:39.037975: step 24060/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.001541, rela_loss = 0.000012, bind_loss = 0.000000 (1.572 sec/batch), lr: 0.000100
2021-07-12 22:36:11.914422: step 24080/164800 (epoch 12/80),jp_loss = 0.000107, trig_loss = 0.000748, rela_loss = 0.000545, bind_loss = 0.000000 (1.402 sec/batch), lr: 0.000100
2021-07-12 22:36:41.750362: step 24100/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000001, bind_loss = 0.000000 (1.491 sec/batch), lr: 0.000100
2021-07-12 22:37:11.033107: step 24120/164800 (epoch 12/80),jp_loss = 0.000153, trig_loss = 0.000214, rela_loss = 0.002122, bind_loss = 0.001671 (2.258 sec/batch), lr: 0.000100
2021-07-12 22:37:45.753274: step 24140/164800 (epoch 12/80),jp_loss = 0.000702, trig_loss = 0.000061, rela_loss = 0.000017, bind_loss = 0.000000 (3.050 sec/batch), lr: 0.000100
2021-07-12 22:38:18.219388: step 24160/164800 (epoch 12/80),jp_loss = 0.000076, trig_loss = 0.001129, rela_loss = 0.000001, bind_loss = 0.000000 (1.056 sec/batch), lr: 0.000100
2021-07-12 22:38:58.788139: step 24180/164800 (epoch 12/80),jp_loss = 0.000439, trig_loss = 0.000679, rela_loss = 0.000065, bind_loss = 0.000000 (1.298 sec/batch), lr: 0.000100
2021-07-12 22:39:24.289821: step 24200/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.001770, rela_loss = 0.000226, bind_loss = 0.000000 (2.603 sec/batch), lr: 0.000100
2021-07-12 22:40:15.083297: step 24220/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.001099, rela_loss = 0.000295, bind_loss = 0.000000 (3.604 sec/batch), lr: 0.000100
2021-07-12 22:40:45.322757: step 24240/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000275, rela_loss = 0.000014, bind_loss = 0.000000 (1.685 sec/batch), lr: 0.000100
2021-07-12 22:41:21.830531: step 24260/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000610, rela_loss = 0.000003, bind_loss = 0.000000 (1.938 sec/batch), lr: 0.000100
2021-07-12 22:41:51.844517: step 24280/164800 (epoch 12/80),jp_loss = 0.000069, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.500 sec/batch), lr: 0.000100
2021-07-12 22:42:34.513090: step 24300/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.000854, rela_loss = 0.000000, bind_loss = 0.000000 (2.573 sec/batch), lr: 0.000100
2021-07-12 22:43:11.259929: step 24320/164800 (epoch 12/80),jp_loss = 0.000244, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (1.522 sec/batch), lr: 0.000100
2021-07-12 22:43:36.943474: step 24340/164800 (epoch 12/80),jp_loss = 0.000122, trig_loss = 0.001633, rela_loss = 0.000010, bind_loss = 0.000000 (1.131 sec/batch), lr: 0.000100
2021-07-12 22:44:07.603577: step 24360/164800 (epoch 12/80),jp_loss = 0.000183, trig_loss = 0.000336, rela_loss = 0.000004, bind_loss = 0.000000 (2.086 sec/batch), lr: 0.000100
2021-07-12 22:44:36.071787: step 24380/164800 (epoch 12/80),jp_loss = 0.000122, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (0.642 sec/batch), lr: 0.000100
2021-07-12 22:45:09.614478: step 24400/164800 (epoch 12/80),jp_loss = 0.000351, trig_loss = 0.001129, rela_loss = 0.001154, bind_loss = 0.000000 (2.640 sec/batch), lr: 0.000100
2021-07-12 22:45:40.632054: step 24420/164800 (epoch 12/80),jp_loss = 0.000183, trig_loss = 0.000641, rela_loss = 0.000013, bind_loss = 0.000000 (1.913 sec/batch), lr: 0.000100
2021-07-12 22:46:16.214019: step 24440/164800 (epoch 12/80),jp_loss = 0.000366, trig_loss = 0.000305, rela_loss = 0.000395, bind_loss = 0.000000 (2.336 sec/batch), lr: 0.000100
2021-07-12 22:47:02.680216: step 24460/164800 (epoch 12/80),jp_loss = 0.000259, trig_loss = 0.000687, rela_loss = 0.000044, bind_loss = 0.000518 (3.722 sec/batch), lr: 0.000100
2021-07-12 22:47:32.895831: step 24480/164800 (epoch 12/80),jp_loss = 0.000580, trig_loss = 0.002899, rela_loss = 0.000000, bind_loss = 0.000000 (0.889 sec/batch), lr: 0.000100
2021-07-12 22:48:06.108560: step 24500/164800 (epoch 12/80),jp_loss = 0.008484, trig_loss = 0.001587, rela_loss = 0.000000, bind_loss = 0.000000 (3.671 sec/batch), lr: 0.000100
2021-07-12 22:48:55.166914: step 24520/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000702, rela_loss = 0.000202, bind_loss = 0.000000 (1.871 sec/batch), lr: 0.000100
2021-07-12 22:49:27.551759: step 24540/164800 (epoch 12/80),jp_loss = 0.000092, trig_loss = 0.002075, rela_loss = 0.000019, bind_loss = 0.000000 (2.290 sec/batch), lr: 0.000100
2021-07-12 22:50:16.632942: step 24560/164800 (epoch 12/80),jp_loss = 0.000000, trig_loss = 0.000305, rela_loss = 0.002387, bind_loss = 0.000000 (0.824 sec/batch), lr: 0.000100
2021-07-12 22:50:46.862156: step 24580/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.003113, rela_loss = 0.000012, bind_loss = 0.000000 (4.442 sec/batch), lr: 0.000100
2021-07-12 22:51:22.545213: step 24600/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000017, bind_loss = 0.000000 (1.082 sec/batch), lr: 0.000100
2021-07-12 22:51:55.472787: step 24620/164800 (epoch 12/80),jp_loss = 0.000366, trig_loss = 1.529175, rela_loss = 0.000000, bind_loss = 0.000225 (3.910 sec/batch), lr: 0.000100
2021-07-12 22:52:25.285726: step 24640/164800 (epoch 12/80),jp_loss = 0.000061, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (1.306 sec/batch), lr: 0.000100
2021-07-12 22:53:00.290873: step 24660/164800 (epoch 12/80),jp_loss = 0.000046, trig_loss = 0.004517, rela_loss = 0.000002, bind_loss = 0.000000 (2.013 sec/batch), lr: 0.000100
2021-07-12 22:53:32.988298: step 24680/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (1.280 sec/batch), lr: 0.000100
2021-07-12 22:54:07.300572: step 24700/164800 (epoch 12/80),jp_loss = 0.000107, trig_loss = 0.000259, rela_loss = 2.197255, bind_loss = 0.000145 (1.672 sec/batch), lr: 0.000100
2021-07-12 22:54:41.376334: step 24720/164800 (epoch 12/80),jp_loss = 0.000031, trig_loss = 0.000519, rela_loss = 0.000000, bind_loss = 0.000000 (1.807 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.77%  R:  99.72%  F1:  99.75%  #: 2174

Final Score:
Precision (micro): 99.770%
   Recall (micro): 99.724%
       F1 (micro): 99.747%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  98.98%  R:  98.32%  F1:  98.65%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  96.35%  R:  98.68%  F1:  97.50%  #: 455
Localization         P:  98.34%  R: 100.00%  F1:  99.16%  #: 178
Negative_regulation  P:  97.65%  R:  98.57%  F1:  98.11%  #: 421
Phosphorylation      P:  94.44%  R:  98.71%  F1:  96.53%  #: 155
Positive_regulation  P:  98.40%  R:  97.93%  F1:  98.16%  #: 627
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  95.22%  R:  96.60%  F1:  95.90%  #: 206
Transcription        P:  94.12%  R:  95.52%  F1:  94.81%  #: 67

Final Score:
Precision (micro): 97.276%
   Recall (micro): 98.034%
       F1 (micro): 97.654%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  98.07%  R:  93.65%  F1:  95.81%  #: 488
Gene_expression      P:  95.65%  R:  98.11%  F1:  96.87%  #: 583
Localization         P:  95.90%  R:  97.40%  F1:  96.64%  #: 192
Negative_regulation  P:  93.35%  R:  96.49%  F1:  94.89%  #: 655
Phosphorylation      P:  96.00%  R:  97.46%  F1:  96.73%  #: 197
Positive_regulation  P:  94.63%  R:  95.45%  F1:  95.04%  #: 923
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  90.48%  R:  93.01%  F1:  91.72%  #: 286
Transcription        P:  94.25%  R:  92.13%  F1:  93.18%  #: 89

Final Score:
Precision (micro): 94.825%
   Recall (micro): 95.789%
       F1 (micro): 95.304%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  96.36%  R:  91.91%  F1:  94.08%  #: 173

Final Score:
Precision (micro): 96.364%
   Recall (micro): 91.908%
       F1 (micro): 94.083%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  92.46%  R:  90.37%  F1:  91.40%  #: 353

Gene_expression      P:  95.97%  R:  98.11%  F1:  97.03%  #: 583

Localization         P:  95.90%  R:  97.40%  F1:  96.64%  #: 192

Negative_regulation  P:  92.22%  R:  77.65%  F1:  84.31%  #: 519

Phosphorylation      P:  89.36%  R:  87.96%  F1:  88.65%  #: 191

Positive_regulation  P:  96.51%  R:  77.82%  F1:  86.16%  #: 852

Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30

Regulation           P:  90.09%  R:  74.35%  F1:  81.47%  #: 269

Transcription        P:  94.25%  R:  92.13%  F1:  93.18%  #: 89

Final Score:
Precision (micro): 94.116%
   Recall (micro): 85.218%
       F1 (micro): 89.446%
epoch 12: train_loss = 0.121894, dev_loss = 0.000000, dev_rela_f1 = 0.8945
0.894458653026428 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_12.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.894458653026428 ---- 12

2021-07-12 23:07:10.491015: step 24740/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.000397, rela_loss = 0.000005, bind_loss = 0.000000 (2.570 sec/batch), lr: 0.000100
2021-07-12 23:07:50.488566: step 24760/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 4.974365, rela_loss = 0.239269, bind_loss = 0.000000 (1.257 sec/batch), lr: 0.000100
2021-07-12 23:08:43.890167: step 24780/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.937 sec/batch), lr: 0.000100
2021-07-12 23:09:18.548619: step 24800/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.001221, rela_loss = 0.000005, bind_loss = 0.000000 (1.060 sec/batch), lr: 0.000100
2021-07-12 23:10:04.698089: step 24820/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 2.901398, rela_loss = 0.000004, bind_loss = 0.000000 (1.075 sec/batch), lr: 0.000100
2021-07-12 23:10:43.558514: step 24840/164800 (epoch 13/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 0.000003, bind_loss = 0.000000 (2.274 sec/batch), lr: 0.000100
2021-07-12 23:11:26.475038: step 24860/164800 (epoch 13/80),jp_loss = 0.000046, trig_loss = 0.000168, rela_loss = 0.000019, bind_loss = 0.000010 (0.794 sec/batch), lr: 0.000100
2021-07-12 23:11:58.285425: step 24880/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000137, rela_loss = 0.000000, bind_loss = 0.000000 (1.014 sec/batch), lr: 0.000100
2021-07-12 23:12:37.828068: step 24900/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 4.056458, rela_loss = 0.000203, bind_loss = 0.000000 (1.724 sec/batch), lr: 0.000100
2021-07-12 23:13:09.642554: step 24920/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.001129, rela_loss = 0.000001, bind_loss = 0.000000 (1.805 sec/batch), lr: 0.000100
2021-07-12 23:13:44.641094: step 24940/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000519, rela_loss = 0.000001, bind_loss = 0.000000 (0.944 sec/batch), lr: 0.000100
2021-07-12 23:14:31.276414: step 24960/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000916, rela_loss = 0.000000, bind_loss = 0.000000 (0.878 sec/batch), lr: 0.000100
2021-07-12 23:15:05.885460: step 24980/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000488, rela_loss = 0.000000, bind_loss = 0.000000 (1.471 sec/batch), lr: 0.000100
2021-07-12 23:15:48.539262: step 25000/164800 (epoch 13/80),jp_loss = 0.000130, trig_loss = 0.000328, rela_loss = 0.000002, bind_loss = 0.000000 (0.643 sec/batch), lr: 0.000100
2021-07-12 23:16:29.630348: step 25020/164800 (epoch 13/80),jp_loss = 0.000153, trig_loss = 0.000336, rela_loss = 0.000002, bind_loss = 0.000000 (0.662 sec/batch), lr: 0.000100
2021-07-12 23:17:05.978300: step 25040/164800 (epoch 13/80),jp_loss = 0.000046, trig_loss = 0.020660, rela_loss = 0.000705, bind_loss = 0.000000 (1.298 sec/batch), lr: 0.000100
2021-07-12 23:17:45.524867: step 25060/164800 (epoch 13/80),jp_loss = 0.000015, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (0.933 sec/batch), lr: 0.000100
2021-07-12 23:18:27.087769: step 25080/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.001617, rela_loss = 0.000000, bind_loss = 0.000000 (1.259 sec/batch), lr: 0.000100
2021-07-12 23:18:53.973038: step 25100/164800 (epoch 13/80),jp_loss = 0.000107, trig_loss = 0.002228, rela_loss = 0.000014, bind_loss = 0.000022 (2.386 sec/batch), lr: 0.000100
2021-07-12 23:19:20.855489: step 25120/164800 (epoch 13/80),jp_loss = 0.000732, trig_loss = 0.000214, rela_loss = 0.000096, bind_loss = 0.000000 (1.088 sec/batch), lr: 0.000100
2021-07-12 23:20:08.875618: step 25140/164800 (epoch 13/80),jp_loss = 0.000427, trig_loss = 0.000580, rela_loss = 2.315133, bind_loss = 0.000000 (2.667 sec/batch), lr: 0.000100
2021-07-12 23:20:41.275879: step 25160/164800 (epoch 13/80),jp_loss = 0.000519, trig_loss = 0.001770, rela_loss = 0.000000, bind_loss = 0.000000 (1.194 sec/batch), lr: 0.000100
2021-07-12 23:21:13.205387: step 25180/164800 (epoch 13/80),jp_loss = 0.000237, trig_loss = 0.000580, rela_loss = 0.000000, bind_loss = 0.000006 (1.411 sec/batch), lr: 0.000100
2021-07-12 23:22:11.169551: step 25200/164800 (epoch 13/80),jp_loss = 0.006897, trig_loss = 0.005005, rela_loss = 0.000005, bind_loss = 0.000000 (7.244 sec/batch), lr: 0.000100
2021-07-12 23:22:40.085062: step 25220/164800 (epoch 13/80),jp_loss = 0.000046, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (0.711 sec/batch), lr: 0.000100
2021-07-12 23:23:14.821582: step 25240/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.021 sec/batch), lr: 0.000100
2021-07-12 23:24:00.284206: step 25260/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.001862, rela_loss = 0.000044, bind_loss = 0.000000 (1.270 sec/batch), lr: 0.000100
2021-07-12 23:24:43.574407: step 25280/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.267426, rela_loss = 0.000223, bind_loss = 0.000000 (4.078 sec/batch), lr: 0.000100
2021-07-12 23:25:30.772067: step 25300/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.009247, rela_loss = 0.000001, bind_loss = 0.000000 (2.584 sec/batch), lr: 0.000100
2021-07-12 23:26:01.817277: step 25320/164800 (epoch 13/80),jp_loss = 0.000107, trig_loss = 0.000214, rela_loss = 0.000002, bind_loss = 0.000000 (1.862 sec/batch), lr: 0.000100
2021-07-12 23:26:34.789931: step 25340/164800 (epoch 13/80),jp_loss = 0.000458, trig_loss = 0.000336, rela_loss = 0.000001, bind_loss = 0.000004 (2.431 sec/batch), lr: 0.000100
2021-07-12 23:27:14.143617: step 25360/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000763, rela_loss = 0.000000, bind_loss = 0.000000 (1.809 sec/batch), lr: 0.000100
2021-07-12 23:27:43.162815: step 25380/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000008, bind_loss = 0.000000 (0.752 sec/batch), lr: 0.000100
2021-07-12 23:28:12.934180: step 25400/164800 (epoch 13/80),jp_loss = 0.000275, trig_loss = 0.000183, rela_loss = 2.196705, bind_loss = 0.000000 (1.431 sec/batch), lr: 0.000100
2021-07-12 23:28:44.467747: step 25420/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.002213, rela_loss = 0.000000, bind_loss = 0.000000 (1.469 sec/batch), lr: 0.000100
2021-07-12 23:29:18.033738: step 25440/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000656, rela_loss = 0.000000, bind_loss = 0.000000 (0.849 sec/batch), lr: 0.000100
2021-07-12 23:29:51.092146: step 25460/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000005, bind_loss = 0.000000 (1.597 sec/batch), lr: 0.000100
2021-07-12 23:30:31.518331: step 25480/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.000916, rela_loss = 0.000036, bind_loss = 0.000000 (1.196 sec/batch), lr: 0.000100
2021-07-12 23:31:12.117262: step 25500/164800 (epoch 13/80),jp_loss = 0.000046, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.441 sec/batch), lr: 0.000100
2021-07-12 23:32:01.543196: step 25520/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000488, rela_loss = 0.000000, bind_loss = 0.000000 (1.114 sec/batch), lr: 0.000100
2021-07-12 23:32:35.127528: step 25540/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000854, rela_loss = 0.000010, bind_loss = 0.000000 (1.522 sec/batch), lr: 0.000100
2021-07-12 23:33:14.601806: step 25560/164800 (epoch 13/80),jp_loss = 0.105011, trig_loss = 0.060120, rela_loss = 0.000000, bind_loss = 0.056650 (4.998 sec/batch), lr: 0.000100
2021-07-12 23:33:45.995837: step 25580/164800 (epoch 13/80),jp_loss = 0.000183, trig_loss = 0.000122, rela_loss = 0.000002, bind_loss = 0.000000 (1.212 sec/batch), lr: 0.000100
2021-07-12 23:34:21.309108: step 25600/164800 (epoch 13/80),jp_loss = 0.000549, trig_loss = 0.000671, rela_loss = 0.000000, bind_loss = 0.000000 (3.416 sec/batch), lr: 0.000100
2021-07-12 23:34:49.774168: step 25620/164800 (epoch 13/80),jp_loss = 0.000336, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.667 sec/batch), lr: 0.000100
2021-07-12 23:35:26.667277: step 25640/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000122, rela_loss = 0.000435, bind_loss = 0.000000 (0.891 sec/batch), lr: 0.000100
2021-07-12 23:36:08.127788: step 25660/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000580, rela_loss = 0.000010, bind_loss = 0.000000 (0.789 sec/batch), lr: 0.000100
2021-07-12 23:36:43.786392: step 25680/164800 (epoch 13/80),jp_loss = 0.000488, trig_loss = 0.000305, rela_loss = 0.002028, bind_loss = 0.000000 (2.417 sec/batch), lr: 0.000100
2021-07-12 23:37:19.690388: step 25700/164800 (epoch 13/80),jp_loss = 0.000168, trig_loss = 0.000549, rela_loss = 0.000024, bind_loss = 0.000000 (0.730 sec/batch), lr: 0.000100
2021-07-12 23:38:03.848897: step 25720/164800 (epoch 13/80),jp_loss = 0.000519, trig_loss = 0.000305, rela_loss = 0.000162, bind_loss = 0.000000 (1.050 sec/batch), lr: 0.000100
2021-07-12 23:38:43.958006: step 25740/164800 (epoch 13/80),jp_loss = 0.000183, trig_loss = 0.003662, rela_loss = 0.000001, bind_loss = 0.000000 (2.666 sec/batch), lr: 0.000100
2021-07-12 23:39:20.676765: step 25760/164800 (epoch 13/80),jp_loss = 0.006592, trig_loss = 0.000061, rela_loss = 0.000034, bind_loss = 0.000000 (1.775 sec/batch), lr: 0.000100
2021-07-12 23:39:51.170195: step 25780/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000153, rela_loss = 0.000006, bind_loss = 0.000000 (0.997 sec/batch), lr: 0.000100
2021-07-12 23:40:28.281501: step 25800/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000151, bind_loss = 0.000000 (1.418 sec/batch), lr: 0.000100
2021-07-12 23:40:55.668288: step 25820/164800 (epoch 13/80),jp_loss = 7.049988, trig_loss = 0.000977, rela_loss = 0.000430, bind_loss = 0.000058 (2.338 sec/batch), lr: 0.000100
2021-07-12 23:41:37.697007: step 25840/164800 (epoch 13/80),jp_loss = 0.000153, trig_loss = 0.000122, rela_loss = 0.000027, bind_loss = 0.000000 (1.477 sec/batch), lr: 0.000100
2021-07-12 23:42:16.284904: step 25860/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.000198, rela_loss = 0.000001, bind_loss = 0.000000 (0.633 sec/batch), lr: 0.000100
2021-07-12 23:42:51.542664: step 25880/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000168, rela_loss = 0.000014, bind_loss = 0.000010 (0.779 sec/batch), lr: 0.000100
2021-07-12 23:43:23.933149: step 25900/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000458, rela_loss = 0.000002, bind_loss = 0.001469 (1.931 sec/batch), lr: 0.000100
2021-07-12 23:43:53.047935: step 25920/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000046, rela_loss = 0.000079, bind_loss = 0.000000 (0.610 sec/batch), lr: 0.000100
2021-07-12 23:44:24.195751: step 25940/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000061, rela_loss = 0.000171, bind_loss = 0.002086 (2.923 sec/batch), lr: 0.000100
2021-07-12 23:45:05.859714: step 25960/164800 (epoch 13/80),jp_loss = 0.000198, trig_loss = 0.000717, rela_loss = 0.000000, bind_loss = 0.000000 (3.089 sec/batch), lr: 0.000100
2021-07-12 23:45:40.290890: step 25980/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.001160, rela_loss = 0.000011, bind_loss = 0.000000 (1.456 sec/batch), lr: 0.000100
2021-07-12 23:46:17.518990: step 26000/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000244, rela_loss = 0.000000, bind_loss = 0.000164 (2.064 sec/batch), lr: 0.000100
2021-07-12 23:46:46.609900: step 26020/164800 (epoch 13/80),jp_loss = 0.006927, trig_loss = 0.000244, rela_loss = 0.000023, bind_loss = 0.000000 (1.172 sec/batch), lr: 0.000100
2021-07-12 23:47:30.672001: step 26040/164800 (epoch 13/80),jp_loss = 0.000137, trig_loss = 26.463791, rela_loss = 0.000016, bind_loss = 0.000000 (3.328 sec/batch), lr: 0.000100
2021-07-12 23:47:58.010205: step 26060/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000824, rela_loss = 0.000001, bind_loss = 0.000000 (1.218 sec/batch), lr: 0.000100
2021-07-12 23:48:31.640645: step 26080/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.001068, rela_loss = 0.000003, bind_loss = 0.000000 (0.886 sec/batch), lr: 0.000100
2021-07-12 23:49:14.760340: step 26100/164800 (epoch 13/80),jp_loss = 0.000336, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000046 (1.943 sec/batch), lr: 0.000100
2021-07-12 23:49:53.448609: step 26120/164800 (epoch 13/80),jp_loss = 0.000168, trig_loss = 0.248184, rela_loss = 0.000000, bind_loss = 0.000000 (1.346 sec/batch), lr: 0.000100
2021-07-12 23:50:21.954380: step 26140/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000473, rela_loss = 0.002094, bind_loss = 0.000000 (1.088 sec/batch), lr: 0.000100
2021-07-12 23:50:49.802458: step 26160/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.633 sec/batch), lr: 0.000100
2021-07-12 23:51:16.164514: step 26180/164800 (epoch 13/80),jp_loss = 0.145279, trig_loss = 0.000275, rela_loss = 0.000178, bind_loss = 0.000082 (2.319 sec/batch), lr: 0.000100
2021-07-12 23:51:49.015498: step 26200/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.000122, rela_loss = 0.000421, bind_loss = 0.000000 (2.571 sec/batch), lr: 0.000100
2021-07-12 23:52:18.887826: step 26220/164800 (epoch 13/80),jp_loss = 0.000290, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.824 sec/batch), lr: 0.000100
2021-07-12 23:52:56.183632: step 26240/164800 (epoch 13/80),jp_loss = 0.000423, trig_loss = 0.000069, rela_loss = 0.000000, bind_loss = 0.000000 (0.981 sec/batch), lr: 0.000100
2021-07-12 23:53:18.716430: step 26260/164800 (epoch 13/80),jp_loss = 0.000183, trig_loss = 10.268097, rela_loss = 0.005051, bind_loss = 0.000000 (1.912 sec/batch), lr: 0.000100
2021-07-12 23:54:05.363211: step 26280/164800 (epoch 13/80),jp_loss = 0.000244, trig_loss = 7.547974, rela_loss = 0.000051, bind_loss = 0.000000 (3.237 sec/batch), lr: 0.000100
2021-07-12 23:54:32.063398: step 26300/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.000671, rela_loss = 0.002162, bind_loss = 0.000000 (1.452 sec/batch), lr: 0.000100
2021-07-12 23:55:04.355533: step 26320/164800 (epoch 13/80),jp_loss = 0.000214, trig_loss = 0.000214, rela_loss = 0.000001, bind_loss = 0.000000 (1.875 sec/batch), lr: 0.000100
2021-07-12 23:55:30.949055: step 26340/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000763, rela_loss = 0.000731, bind_loss = 0.000000 (0.454 sec/batch), lr: 0.000100
2021-07-12 23:56:10.729064: step 26360/164800 (epoch 13/80),jp_loss = 0.000153, trig_loss = 0.000244, rela_loss = 0.006379, bind_loss = 0.000000 (2.040 sec/batch), lr: 0.000100
2021-07-12 23:56:44.618522: step 26380/164800 (epoch 13/80),jp_loss = 1.361084, trig_loss = 0.000793, rela_loss = 0.001434, bind_loss = 0.000000 (1.328 sec/batch), lr: 0.000100
2021-07-12 23:57:07.324292: step 26400/164800 (epoch 13/80),jp_loss = 0.000015, trig_loss = 0.000183, rela_loss = 0.000005, bind_loss = 0.000000 (1.031 sec/batch), lr: 0.000100
2021-07-12 23:57:35.553182: step 26420/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.001617, rela_loss = 0.000000, bind_loss = 0.000000 (2.059 sec/batch), lr: 0.000100
2021-07-12 23:58:02.941847: step 26440/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000519, rela_loss = 0.000000, bind_loss = 0.000000 (0.829 sec/batch), lr: 0.000100
2021-07-12 23:58:33.616900: step 26460/164800 (epoch 13/80),jp_loss = 0.000137, trig_loss = 8.533630, rela_loss = 0.000000, bind_loss = 0.000000 (3.178 sec/batch), lr: 0.000100
2021-07-12 23:59:03.760479: step 26480/164800 (epoch 13/80),jp_loss = 0.000275, trig_loss = 0.000732, rela_loss = 0.007366, bind_loss = 0.000000 (1.735 sec/batch), lr: 0.000100
2021-07-12 23:59:36.879374: step 26500/164800 (epoch 13/80),jp_loss = 0.001404, trig_loss = 0.000671, rela_loss = 0.097092, bind_loss = 0.000000 (1.881 sec/batch), lr: 0.000100
2021-07-13 00:00:19.480150: step 26520/164800 (epoch 13/80),jp_loss = 0.008560, trig_loss = 0.007568, rela_loss = 0.000905, bind_loss = 0.000041 (3.357 sec/batch), lr: 0.000100
2021-07-13 00:00:50.155402: step 26540/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.000519, rela_loss = 0.000003, bind_loss = 0.000000 (0.971 sec/batch), lr: 0.000100
2021-07-13 00:01:21.849921: step 26560/164800 (epoch 13/80),jp_loss = 0.002563, trig_loss = 0.001068, rela_loss = 0.000012, bind_loss = 0.000000 (3.290 sec/batch), lr: 0.000100
2021-07-13 00:02:08.698327: step 26580/164800 (epoch 13/80),jp_loss = 0.000122, trig_loss = 0.000732, rela_loss = 0.000000, bind_loss = 0.000000 (1.995 sec/batch), lr: 0.000100
2021-07-13 00:02:38.438997: step 26600/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000870, rela_loss = 0.000005, bind_loss = 0.000000 (2.046 sec/batch), lr: 0.000100
2021-07-13 00:03:28.024603: step 26620/164800 (epoch 13/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.002097, bind_loss = 0.000000 (0.734 sec/batch), lr: 0.000100
2021-07-13 00:03:57.009068: step 26640/164800 (epoch 13/80),jp_loss = 0.001709, trig_loss = 1.258179, rela_loss = 0.000005, bind_loss = 0.000000 (4.157 sec/batch), lr: 0.000100
2021-07-13 00:04:30.840417: step 26660/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.972 sec/batch), lr: 0.000100
2021-07-13 00:05:02.801132: step 26680/164800 (epoch 13/80),jp_loss = 0.002441, trig_loss = 3.972717, rela_loss = 0.000000, bind_loss = 0.000088 (3.907 sec/batch), lr: 0.000100
2021-07-13 00:05:29.364823: step 26700/164800 (epoch 13/80),jp_loss = 0.000092, trig_loss = 0.000458, rela_loss = 0.000000, bind_loss = 0.000000 (0.934 sec/batch), lr: 0.000100
2021-07-13 00:06:02.009691: step 26720/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 5.049545, rela_loss = 0.000000, bind_loss = 0.000000 (1.567 sec/batch), lr: 0.000100
2021-07-13 00:06:30.858982: step 26740/164800 (epoch 13/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.188 sec/batch), lr: 0.000100
2021-07-13 00:07:03.008283: step 26760/164800 (epoch 13/80),jp_loss = 0.000107, trig_loss = 0.001282, rela_loss = 0.000768, bind_loss = 0.000117 (1.655 sec/batch), lr: 0.000100
2021-07-13 00:07:34.297360: step 26780/164800 (epoch 13/80),jp_loss = 0.000031, trig_loss = 0.000366, rela_loss = 0.000004, bind_loss = 0.000000 (1.421 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.54%  R:  99.86%  F1:  99.70%  #: 2174

Final Score:
Precision (micro): 99.541%
   Recall (micro): 99.862%
       F1 (micro): 99.701%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  99.66%  R:  98.99%  F1:  99.32%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  97.15%  R:  97.36%  F1:  97.26%  #: 455
Localization         P:  99.44%  R: 100.00%  F1:  99.72%  #: 178
Negative_regulation  P:  98.34%  R:  98.34%  F1:  98.34%  #: 421
Phosphorylation      P:  97.44%  R:  98.06%  F1:  97.75%  #: 155
Positive_regulation  P:  96.54%  R:  97.77%  F1:  97.15%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  99.50%  R:  97.57%  F1:  98.53%  #: 206
Transcription        P:  85.33%  R:  95.52%  F1:  90.14%  #: 67

Final Score:
Precision (micro): 97.469%
   Recall (micro): 97.829%
       F1 (micro): 97.649%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  96.98%  R:  98.57%  F1:  97.76%  #: 488
Gene_expression      P:  96.90%  R:  96.73%  F1:  96.81%  #: 581
Localization         P:  96.88%  R:  96.88%  F1:  96.88%  #: 192
Negative_regulation  P:  95.26%  R:  95.11%  F1:  95.19%  #: 655
Phosphorylation      P:  97.46%  R:  97.46%  F1:  97.46%  #: 197
Positive_regulation  P:  92.60%  R:  94.91%  F1:  93.74%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  96.44%  R:  94.76%  F1:  95.59%  #: 286
Transcription        P:  84.54%  R:  92.13%  F1:  88.17%  #: 89

Final Score:
Precision (micro): 95.049%
   Recall (micro): 95.960%
       F1 (micro): 95.503%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  96.11%  R:  96.11%  F1:  96.11%  #: 180

Final Score:
Precision (micro): 96.111%
   Recall (micro): 96.111%
       F1 (micro): 96.111%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  93.59%  R:  95.18%  F1:  94.38%  #: 353

Gene_expression      P:  97.23%  R:  96.73%  F1:  96.98%  #: 581

Localization         P:  96.88%  R:  96.88%  F1:  96.88%  #: 192

Negative_regulation  P:  91.14%  R:  77.26%  F1:  83.63%  #: 519

Phosphorylation      P:  90.81%  R:  87.96%  F1:  89.36%  #: 191

Positive_regulation  P:  92.05%  R:  80.16%  F1:  85.70%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  91.44%  R:  75.46%  F1:  82.69%  #: 269

Transcription        P:  84.54%  R:  92.13%  F1:  88.17%  #: 89

Final Score:
Precision (micro): 93.113%
   Recall (micro): 86.151%
       F1 (micro): 89.497%
epoch 13: train_loss = 0.080401, dev_loss = 0.000000, dev_rela_f1 = 0.8950
0.894967916244512 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_13.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.894967916244512 ---- 13

2021-07-13 00:19:58.516117: step 26800/164800 (epoch 14/80),jp_loss = 0.000153, trig_loss = 0.197662, rela_loss = 0.000015, bind_loss = 0.000000 (2.174 sec/batch), lr: 0.000100
2021-07-13 00:20:35.119346: step 26820/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 12.076111, rela_loss = 0.000684, bind_loss = 0.000000 (0.983 sec/batch), lr: 0.000100
2021-07-13 00:21:21.871071: step 26840/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.001404, rela_loss = 0.000000, bind_loss = 0.000000 (0.857 sec/batch), lr: 0.000100
2021-07-13 00:21:51.936262: step 26860/164800 (epoch 14/80),jp_loss = 0.000290, trig_loss = 0.000732, rela_loss = 0.000000, bind_loss = 0.000000 (0.862 sec/batch), lr: 0.000100
2021-07-13 00:22:34.847690: step 26880/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000946, rela_loss = 0.000000, bind_loss = 0.000000 (0.946 sec/batch), lr: 0.000100
2021-07-13 00:23:10.355087: step 26900/164800 (epoch 14/80),jp_loss = 0.000580, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.818 sec/batch), lr: 0.000100
2021-07-13 00:23:48.959648: step 26920/164800 (epoch 14/80),jp_loss = 0.000145, trig_loss = 0.000046, rela_loss = 0.000000, bind_loss = 0.000001 (0.702 sec/batch), lr: 0.000100
2021-07-13 00:24:16.091330: step 26940/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000242, bind_loss = 0.000000 (0.852 sec/batch), lr: 0.000100
2021-07-13 00:24:52.873896: step 26960/164800 (epoch 14/80),jp_loss = 8.075638, trig_loss = 0.186462, rela_loss = 0.000002, bind_loss = 0.000000 (1.454 sec/batch), lr: 0.000100
2021-07-13 00:25:21.131712: step 26980/164800 (epoch 14/80),jp_loss = 0.000702, trig_loss = 0.000854, rela_loss = 0.000000, bind_loss = 0.000000 (1.616 sec/batch), lr: 0.000100
2021-07-13 00:25:51.574617: step 27000/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.693085, rela_loss = 0.000014, bind_loss = 0.000000 (0.793 sec/batch), lr: 0.000100
2021-07-13 00:26:35.163886: step 27020/164800 (epoch 14/80),jp_loss = 0.000305, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.920 sec/batch), lr: 0.000100
2021-07-13 00:27:08.136364: step 27040/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000000, bind_loss = 0.000000 (1.548 sec/batch), lr: 0.000100
2021-07-13 00:27:47.604246: step 27060/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000076, rela_loss = 0.000000, bind_loss = 0.000000 (0.554 sec/batch), lr: 0.000100
2021-07-13 00:28:26.294274: step 27080/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (0.780 sec/batch), lr: 0.000100
2021-07-13 00:29:01.643803: step 27100/164800 (epoch 14/80),jp_loss = 0.000076, trig_loss = 2.013489, rela_loss = 0.000002, bind_loss = 0.000000 (1.198 sec/batch), lr: 0.000100
2021-07-13 00:29:39.714747: step 27120/164800 (epoch 14/80),jp_loss = 0.000046, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.769 sec/batch), lr: 0.000100
2021-07-13 00:30:18.869872: step 27140/164800 (epoch 14/80),jp_loss = 0.000137, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (1.078 sec/batch), lr: 0.000100
2021-07-13 00:30:44.304541: step 27160/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 2.382172, rela_loss = 0.000006, bind_loss = 0.000101 (1.935 sec/batch), lr: 0.000100
2021-07-13 00:31:06.930622: step 27180/164800 (epoch 14/80),jp_loss = 0.000458, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (0.731 sec/batch), lr: 0.000100
2021-07-13 00:31:45.612089: step 27200/164800 (epoch 14/80),jp_loss = 0.002502, trig_loss = 0.002106, rela_loss = 0.001085, bind_loss = 0.000000 (2.398 sec/batch), lr: 0.000100
2021-07-13 00:32:12.677995: step 27220/164800 (epoch 14/80),jp_loss = 4.454742, trig_loss = 0.000061, rela_loss = 0.000004, bind_loss = 0.000000 (0.947 sec/batch), lr: 0.000100
2021-07-13 00:32:36.478357: step 27240/164800 (epoch 14/80),jp_loss = 0.002525, trig_loss = 0.001114, rela_loss = 0.000032, bind_loss = 0.000188 (0.997 sec/batch), lr: 0.000100
2021-07-13 00:33:24.732529: step 27260/164800 (epoch 14/80),jp_loss = 0.000305, trig_loss = 0.007446, rela_loss = 0.000146, bind_loss = 0.000000 (6.483 sec/batch), lr: 0.000100
2021-07-13 00:33:46.763359: step 27280/164800 (epoch 14/80),jp_loss = 0.000015, trig_loss = 0.000092, rela_loss = 0.000133, bind_loss = 0.000000 (0.623 sec/batch), lr: 0.000100
2021-07-13 00:34:13.098773: step 27300/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.000092, rela_loss = 0.000002, bind_loss = 0.000000 (0.736 sec/batch), lr: 0.000100
2021-07-13 00:34:49.473515: step 27320/164800 (epoch 14/80),jp_loss = 0.745697, trig_loss = 0.000122, rela_loss = 0.000062, bind_loss = 0.000000 (0.795 sec/batch), lr: 0.000100
2021-07-13 00:35:26.575702: step 27340/164800 (epoch 14/80),jp_loss = 0.000275, trig_loss = 0.006287, rela_loss = 0.000172, bind_loss = 0.000000 (3.796 sec/batch), lr: 0.000100
2021-07-13 00:36:07.869195: step 27360/164800 (epoch 14/80),jp_loss = 0.000153, trig_loss = 0.031128, rela_loss = 0.000010, bind_loss = 0.000000 (1.649 sec/batch), lr: 0.000100
2021-07-13 00:36:34.916246: step 27380/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (1.910 sec/batch), lr: 0.000100
2021-07-13 00:37:04.610487: step 27400/164800 (epoch 14/80),jp_loss = 0.002136, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000300 (2.168 sec/batch), lr: 0.000100
2021-07-13 00:37:41.633472: step 27420/164800 (epoch 14/80),jp_loss = 0.000244, trig_loss = 0.000336, rela_loss = 0.000076, bind_loss = 0.000000 (1.701 sec/batch), lr: 0.000100
2021-07-13 00:38:09.774076: step 27440/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000118, bind_loss = 0.000000 (0.743 sec/batch), lr: 0.000100
2021-07-13 00:38:38.189576: step 27460/164800 (epoch 14/80),jp_loss = 0.001404, trig_loss = 0.002289, rela_loss = 0.000000, bind_loss = 0.000000 (1.290 sec/batch), lr: 0.000100
2021-07-13 00:39:08.101534: step 27480/164800 (epoch 14/80),jp_loss = 0.000015, trig_loss = 0.001083, rela_loss = 0.000000, bind_loss = 0.000000 (1.597 sec/batch), lr: 0.000100
2021-07-13 00:39:39.073835: step 27500/164800 (epoch 14/80),jp_loss = 0.000046, trig_loss = 0.000259, rela_loss = 0.000030, bind_loss = 0.000000 (0.801 sec/batch), lr: 0.000100
2021-07-13 00:40:10.191811: step 27520/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.000122, rela_loss = 0.000002, bind_loss = 0.000000 (2.023 sec/batch), lr: 0.000100
2021-07-13 00:40:49.297829: step 27540/164800 (epoch 14/80),jp_loss = 0.000336, trig_loss = 0.000122, rela_loss = 0.000056, bind_loss = 0.000000 (0.951 sec/batch), lr: 0.000100
2021-07-13 00:41:27.755748: step 27560/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.528 sec/batch), lr: 0.000100
2021-07-13 00:42:16.329593: step 27580/164800 (epoch 14/80),jp_loss = 0.000015, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (1.012 sec/batch), lr: 0.000100
2021-07-13 00:42:47.550773: step 27600/164800 (epoch 14/80),jp_loss = 0.000153, trig_loss = 0.002716, rela_loss = 0.000038, bind_loss = 0.000000 (1.687 sec/batch), lr: 0.000100
2021-07-13 00:43:26.032486: step 27620/164800 (epoch 14/80),jp_loss = 2.136932, trig_loss = 0.000427, rela_loss = 0.000005, bind_loss = 0.018995 (5.155 sec/batch), lr: 0.000100
2021-07-13 00:43:54.632188: step 27640/164800 (epoch 14/80),jp_loss = 0.000275, trig_loss = 0.000061, rela_loss = 0.000008, bind_loss = 0.000000 (1.071 sec/batch), lr: 0.000100
2021-07-13 00:44:27.084777: step 27660/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.002441, rela_loss = 0.000015, bind_loss = 0.000000 (3.155 sec/batch), lr: 0.000100
2021-07-13 00:44:54.529186: step 27680/164800 (epoch 14/80),jp_loss = 0.000237, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.526 sec/batch), lr: 0.000100
2021-07-13 00:45:29.069023: step 27700/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (0.841 sec/batch), lr: 0.000100
2021-07-13 00:46:07.931120: step 27720/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 7.338501, rela_loss = 0.000002, bind_loss = 0.000000 (0.877 sec/batch), lr: 0.000100
2021-07-13 00:46:41.353063: step 27740/164800 (epoch 14/80),jp_loss = 0.000366, trig_loss = 0.000305, rela_loss = 0.000436, bind_loss = 0.000000 (2.495 sec/batch), lr: 0.000100
2021-07-13 00:47:14.283763: step 27760/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 3.538544, rela_loss = 0.000090, bind_loss = 0.000000 (0.661 sec/batch), lr: 0.000100
2021-07-13 00:47:54.388989: step 27780/164800 (epoch 14/80),jp_loss = 0.003723, trig_loss = 0.000397, rela_loss = 0.000000, bind_loss = 0.000000 (1.118 sec/batch), lr: 0.000100
2021-07-13 00:48:29.293954: step 27800/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000793, rela_loss = 0.000030, bind_loss = 0.000000 (2.105 sec/batch), lr: 0.000100
2021-07-13 00:49:01.389722: step 27820/164800 (epoch 14/80),jp_loss = 0.031189, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.326 sec/batch), lr: 0.000100
2021-07-13 00:49:28.259987: step 27840/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.855 sec/batch), lr: 0.000100
2021-07-13 00:50:01.246459: step 27860/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000488, rela_loss = 0.000124, bind_loss = 0.000000 (1.417 sec/batch), lr: 0.000100
2021-07-13 00:50:25.907995: step 27880/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000058, bind_loss = 0.000077 (1.709 sec/batch), lr: 0.000100
2021-07-13 00:51:05.574348: step 27900/164800 (epoch 14/80),jp_loss = 0.000099, trig_loss = 0.000046, rela_loss = 0.000100, bind_loss = 0.000000 (1.070 sec/batch), lr: 0.000100
2021-07-13 00:51:41.780196: step 27920/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000153, rela_loss = 0.000010, bind_loss = 0.000000 (0.563 sec/batch), lr: 0.000100
2021-07-13 00:52:13.430565: step 27940/164800 (epoch 14/80),jp_loss = 0.000168, trig_loss = 0.000015, rela_loss = 0.000693, bind_loss = 0.000573 (0.692 sec/batch), lr: 0.000100
2021-07-13 00:52:40.865220: step 27960/164800 (epoch 14/80),jp_loss = 0.000244, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000054 (1.678 sec/batch), lr: 0.000100
2021-07-13 00:53:08.173364: step 27980/164800 (epoch 14/80),jp_loss = 0.000076, trig_loss = 0.000015, rela_loss = 0.000004, bind_loss = 0.000000 (0.589 sec/batch), lr: 0.000100
2021-07-13 00:53:37.963394: step 28000/164800 (epoch 14/80),jp_loss = 0.000244, trig_loss = 0.000122, rela_loss = 0.015805, bind_loss = 0.002242 (3.355 sec/batch), lr: 0.000100
2021-07-13 00:54:16.677201: step 28020/164800 (epoch 14/80),jp_loss = 0.000320, trig_loss = 0.000839, rela_loss = 0.000000, bind_loss = 0.000000 (3.111 sec/batch), lr: 0.000100
2021-07-13 00:54:48.572803: step 28040/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.000732, rela_loss = 0.000009, bind_loss = 0.000000 (1.368 sec/batch), lr: 0.000100
2021-07-13 00:55:26.918960: step 28060/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.000458, rela_loss = 0.000002, bind_loss = 0.000095 (1.835 sec/batch), lr: 0.000100
2021-07-13 00:55:57.027668: step 28080/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 0.450195, rela_loss = 0.000001, bind_loss = 0.000000 (1.275 sec/batch), lr: 0.000100
2021-07-13 00:56:39.566757: step 28100/164800 (epoch 14/80),jp_loss = 0.000137, trig_loss = 7.849487, rela_loss = 0.000635, bind_loss = 0.000000 (2.915 sec/batch), lr: 0.000100
2021-07-13 00:57:06.659704: step 28120/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000427, rela_loss = 0.000000, bind_loss = 0.000000 (1.352 sec/batch), lr: 0.000100
2021-07-13 00:57:39.108391: step 28140/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.001221, rela_loss = 0.000013, bind_loss = 0.000000 (0.843 sec/batch), lr: 0.000100
2021-07-13 00:58:21.248149: step 28160/164800 (epoch 14/80),jp_loss = 0.000580, trig_loss = 2.642975, rela_loss = 0.361636, bind_loss = 0.000133 (1.790 sec/batch), lr: 0.000100
2021-07-13 00:59:02.007709: step 28180/164800 (epoch 14/80),jp_loss = 0.000107, trig_loss = 0.002075, rela_loss = 0.000017, bind_loss = 0.000000 (1.490 sec/batch), lr: 0.000100
2021-07-13 00:59:32.197153: step 28200/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.009338, rela_loss = 0.000413, bind_loss = 0.000000 (1.307 sec/batch), lr: 0.000100
2021-07-13 00:59:58.991208: step 28220/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.524 sec/batch), lr: 0.000100
2021-07-13 01:00:25.271729: step 28240/164800 (epoch 14/80),jp_loss = 0.001038, trig_loss = 0.000122, rela_loss = 0.000080, bind_loss = 0.000136 (1.764 sec/batch), lr: 0.000100
2021-07-13 01:00:57.016294: step 28260/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000038, bind_loss = 0.000000 (2.094 sec/batch), lr: 0.000100
2021-07-13 01:01:27.699820: step 28280/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 0.000092, rela_loss = 0.000006, bind_loss = 0.000000 (0.954 sec/batch), lr: 0.000100
2021-07-13 01:02:05.257792: step 28300/164800 (epoch 14/80),jp_loss = 0.000153, trig_loss = 0.000092, rela_loss = 0.000231, bind_loss = 0.000000 (1.138 sec/batch), lr: 0.000100
2021-07-13 01:02:28.494757: step 28320/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.004730, rela_loss = 0.005379, bind_loss = 0.000000 (1.829 sec/batch), lr: 0.000100
2021-07-13 01:03:16.472872: step 28340/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000427, rela_loss = 0.001186, bind_loss = 0.000000 (3.272 sec/batch), lr: 0.000100
2021-07-13 01:03:44.061090: step 28360/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000549, rela_loss = 0.009450, bind_loss = 0.000000 (1.550 sec/batch), lr: 0.000100
2021-07-13 01:04:16.641142: step 28380/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 0.000153, rela_loss = 0.000004, bind_loss = 0.000000 (1.996 sec/batch), lr: 0.000100
2021-07-13 01:04:44.448575: step 28400/164800 (epoch 14/80),jp_loss = 0.000046, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.573 sec/batch), lr: 0.000100
2021-07-13 01:05:24.509404: step 28420/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.074341, rela_loss = 6.138801, bind_loss = 0.000000 (2.376 sec/batch), lr: 0.000100
2021-07-13 01:05:59.143476: step 28440/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000006, bind_loss = 0.000000 (1.411 sec/batch), lr: 0.000100
2021-07-13 01:06:21.072378: step 28460/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (1.002 sec/batch), lr: 0.000100
2021-07-13 01:06:48.895385: step 28480/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 0.001038, rela_loss = 0.000000, bind_loss = 0.000000 (1.808 sec/batch), lr: 0.000100
2021-07-13 01:07:14.785396: step 28500/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (0.626 sec/batch), lr: 0.000100
2021-07-13 01:07:45.074953: step 28520/164800 (epoch 14/80),jp_loss = 0.000183, trig_loss = 0.000687, rela_loss = 0.000003, bind_loss = 0.000000 (2.850 sec/batch), lr: 0.000100
2021-07-13 01:08:14.660645: step 28540/164800 (epoch 14/80),jp_loss = 0.000427, trig_loss = 0.000244, rela_loss = 0.000023, bind_loss = 0.000000 (2.045 sec/batch), lr: 0.000100
2021-07-13 01:08:46.325019: step 28560/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 0.000061, rela_loss = 0.000175, bind_loss = 0.000000 (2.082 sec/batch), lr: 0.000100
2021-07-13 01:09:30.807032: step 28580/164800 (epoch 14/80),jp_loss = 0.000305, trig_loss = 0.000214, rela_loss = 0.000011, bind_loss = 0.000013 (3.531 sec/batch), lr: 0.000100
2021-07-13 01:10:00.686074: step 28600/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000002, bind_loss = 0.000000 (0.814 sec/batch), lr: 0.000100
2021-07-13 01:10:32.515326: step 28620/164800 (epoch 14/80),jp_loss = 0.000824, trig_loss = 0.000183, rela_loss = 0.000044, bind_loss = 0.000000 (3.460 sec/batch), lr: 0.000100
2021-07-13 01:11:18.638442: step 28640/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000854, rela_loss = 0.000003, bind_loss = 0.000000 (1.906 sec/batch), lr: 0.000100
2021-07-13 01:11:48.573065: step 28660/164800 (epoch 14/80),jp_loss = 0.000015, trig_loss = 0.003677, rela_loss = 0.000813, bind_loss = 0.000000 (2.157 sec/batch), lr: 0.000100
2021-07-13 01:12:37.378471: step 28680/164800 (epoch 14/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000121, bind_loss = 0.000000 (0.865 sec/batch), lr: 0.000100
2021-07-13 01:13:06.480314: step 28700/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.051575, rela_loss = 0.000008, bind_loss = 0.000000 (4.491 sec/batch), lr: 0.000100
2021-07-13 01:13:40.771235: step 28720/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (1.345 sec/batch), lr: 0.000100
2021-07-13 01:14:11.121417: step 28740/164800 (epoch 14/80),jp_loss = 0.000122, trig_loss = 17.155518, rela_loss = 0.000009, bind_loss = 0.000036 (4.015 sec/batch), lr: 0.000100
2021-07-13 01:14:37.919880: step 28760/164800 (epoch 14/80),jp_loss = 0.000092, trig_loss = 0.000549, rela_loss = 0.000000, bind_loss = 0.000000 (0.912 sec/batch), lr: 0.000100
2021-07-13 01:15:10.514914: step 28780/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.002518, rela_loss = 0.000001, bind_loss = 0.000000 (1.767 sec/batch), lr: 0.000100
2021-07-13 01:15:40.468072: step 28800/164800 (epoch 14/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.244 sec/batch), lr: 0.000100
2021-07-13 01:16:13.463701: step 28820/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.000397, rela_loss = 0.000239, bind_loss = 0.000214 (1.670 sec/batch), lr: 0.000100
2021-07-13 01:16:46.017665: step 28840/164800 (epoch 14/80),jp_loss = 0.000031, trig_loss = 0.009399, rela_loss = 0.000021, bind_loss = 0.000000 (1.621 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.68%  R:  99.54%  F1:  99.61%  #: 2174

Final Score:
Precision (micro): 99.678%
   Recall (micro): 99.540%
       F1 (micro): 99.609%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P: 100.00%  R:  98.99%  F1:  99.49%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  97.40%  R:  98.90%  F1:  98.15%  #: 455
Localization         P: 100.00%  R: 100.00%  F1: 100.00%  #: 178
Negative_regulation  P:  99.76%  R:  99.29%  F1:  99.52%  #: 421
Phosphorylation      P:  97.44%  R:  98.06%  F1:  97.75%  #: 155
Positive_regulation  P:  98.56%  R:  98.41%  F1:  98.48%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  97.56%  R:  97.09%  F1:  97.32%  #: 206
Transcription        P:  95.52%  R:  95.52%  F1:  95.52%  #: 67

Final Score:
Precision (micro): 98.523%
   Recall (micro): 98.402%
       F1 (micro): 98.463%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  97.16%  R:  98.16%  F1:  97.66%  #: 488
Gene_expression      P:  97.12%  R:  98.28%  F1:  97.70%  #: 583
Localization         P:  97.92%  R:  97.92%  F1:  97.92%  #: 192
Negative_regulation  P:  97.26%  R:  97.71%  F1:  97.49%  #: 655
Phosphorylation      P:  96.95%  R:  96.95%  F1:  96.95%  #: 197
Positive_regulation  P:  95.81%  R:  96.53%  F1:  96.17%  #: 923
Protein_catabolism   P:  90.62%  R:  96.67%  F1:  93.55%  #: 30
Regulation           P:  95.12%  R:  95.45%  F1:  95.29%  #: 286
Transcription        P:  93.26%  R:  94.32%  F1:  93.79%  #: 88

Final Score:
Precision (micro): 96.511%
   Recall (micro): 97.240%
       F1 (micro): 96.874%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  91.28%  R:  98.34%  F1:  94.68%  #: 181

Final Score:
Precision (micro): 91.282%
   Recall (micro): 98.343%
       F1 (micro): 94.681%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  93.65%  R:  96.03%  F1:  94.83%  #: 353

Gene_expression      P:  97.61%  R:  98.28%  F1:  97.95%  #: 583

Localization         P:  97.92%  R:  97.92%  F1:  97.92%  #: 192

Negative_regulation  P:  95.42%  R:  80.35%  F1:  87.24%  #: 519

Phosphorylation      P:  90.27%  R:  87.43%  F1:  88.83%  #: 191

Positive_regulation  P:  94.79%  R:  81.10%  F1:  87.41%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  96.19%  R:  75.09%  F1:  84.34%  #: 269

Transcription        P:  93.26%  R:  94.32%  F1:  93.79%  #: 88

Final Score:
Precision (micro): 95.287%
   Recall (micro): 87.390%
       F1 (micro): 91.168%
epoch 14: train_loss = 0.119653, dev_loss = 0.000000, dev_rela_f1 = 0.9117
0.9116799457535176 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_14.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.9116799457535176 ---- 14

2021-07-13 01:29:29.522465: step 28860/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000458, rela_loss = 0.000000, bind_loss = 0.000000 (2.189 sec/batch), lr: 0.000100
2021-07-13 01:30:05.415381: step 28880/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 10.468658, rela_loss = 0.000508, bind_loss = 0.000000 (1.042 sec/batch), lr: 0.000100
2021-07-13 01:30:51.103573: step 28900/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.794 sec/batch), lr: 0.000100
2021-07-13 01:31:20.559609: step 28920/164800 (epoch 15/80),jp_loss = 0.000076, trig_loss = 0.005280, rela_loss = 0.000002, bind_loss = 0.000000 (0.728 sec/batch), lr: 0.000100
2021-07-13 01:32:01.583012: step 28940/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.002106, rela_loss = 0.000001, bind_loss = 0.000000 (0.802 sec/batch), lr: 0.000100
2021-07-13 01:32:34.722444: step 28960/164800 (epoch 15/80),jp_loss = 0.000214, trig_loss = 0.001831, rela_loss = 0.000019, bind_loss = 0.000000 (1.748 sec/batch), lr: 0.000100
2021-07-13 01:33:14.059330: step 28980/164800 (epoch 15/80),jp_loss = 0.000069, trig_loss = 0.000031, rela_loss = 0.000008, bind_loss = 0.000037 (0.720 sec/batch), lr: 0.000100
2021-07-13 01:33:41.544893: step 29000/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000155, bind_loss = 0.000000 (0.851 sec/batch), lr: 0.000100
2021-07-13 01:34:19.372456: step 29020/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.059021, rela_loss = 0.000031, bind_loss = 0.000000 (1.623 sec/batch), lr: 0.000100
2021-07-13 01:34:47.308706: step 29040/164800 (epoch 15/80),jp_loss = 0.020844, trig_loss = 0.004288, rela_loss = 0.000051, bind_loss = 0.000000 (1.769 sec/batch), lr: 0.000100
2021-07-13 01:35:18.905431: step 29060/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000519, rela_loss = 0.000003, bind_loss = 0.000000 (0.743 sec/batch), lr: 0.000100
2021-07-13 01:36:01.775802: step 29080/164800 (epoch 15/80),jp_loss = 0.000046, trig_loss = 3.342957, rela_loss = 0.000001, bind_loss = 0.000000 (0.893 sec/batch), lr: 0.000100
2021-07-13 01:36:32.779195: step 29100/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000003, bind_loss = 0.000000 (1.386 sec/batch), lr: 0.000100
2021-07-13 01:37:11.188487: step 29120/164800 (epoch 15/80),jp_loss = 0.000008, trig_loss = 0.000214, rela_loss = 0.000002, bind_loss = 0.000000 (0.480 sec/batch), lr: 0.000100
2021-07-13 01:37:48.810226: step 29140/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000003, bind_loss = 0.000000 (0.703 sec/batch), lr: 0.000100
2021-07-13 01:38:22.024849: step 29160/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.016754, rela_loss = 0.372335, bind_loss = 0.000000 (1.101 sec/batch), lr: 0.000100
2021-07-13 01:38:58.866241: step 29180/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000488, rela_loss = 0.000001, bind_loss = 0.000000 (0.757 sec/batch), lr: 0.000100
2021-07-13 01:39:36.329848: step 29200/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.005188, rela_loss = 0.000003, bind_loss = 0.000000 (0.967 sec/batch), lr: 0.000100
2021-07-13 01:40:01.456942: step 29220/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.001526, rela_loss = 0.000214, bind_loss = 0.000033 (2.051 sec/batch), lr: 0.000100
2021-07-13 01:40:25.926347: step 29240/164800 (epoch 15/80),jp_loss = 0.000214, trig_loss = 0.000092, rela_loss = 0.000075, bind_loss = 0.000000 (0.846 sec/batch), lr: 0.000100
2021-07-13 01:41:09.528888: step 29260/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.222656, rela_loss = 0.009268, bind_loss = 0.000000 (2.675 sec/batch), lr: 0.000100
2021-07-13 01:41:40.043088: step 29280/164800 (epoch 15/80),jp_loss = 0.000122, trig_loss = 0.041992, rela_loss = 0.000001, bind_loss = 0.000000 (1.011 sec/batch), lr: 0.000100
2021-07-13 01:42:07.397413: step 29300/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000290, rela_loss = 0.000008, bind_loss = 0.000000 (1.373 sec/batch), lr: 0.000100
2021-07-13 01:42:59.826154: step 29320/164800 (epoch 15/80),jp_loss = 0.000244, trig_loss = 0.003235, rela_loss = 0.000038, bind_loss = 0.000000 (6.364 sec/batch), lr: 0.000100
2021-07-13 01:43:27.133592: step 29340/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000064, bind_loss = 0.000000 (0.749 sec/batch), lr: 0.000100
2021-07-13 01:43:58.436313: step 29360/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000280, bind_loss = 0.000000 (0.862 sec/batch), lr: 0.000100
2021-07-13 01:44:39.516245: step 29380/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000002, bind_loss = 0.000000 (0.900 sec/batch), lr: 0.000100
2021-07-13 01:45:19.377656: step 29400/164800 (epoch 15/80),jp_loss = 0.000153, trig_loss = 10.906219, rela_loss = 0.000055, bind_loss = 0.000000 (3.731 sec/batch), lr: 0.000100
2021-07-13 01:46:01.529563: step 29420/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.002930, rela_loss = 0.000155, bind_loss = 0.000000 (1.918 sec/batch), lr: 0.000100
2021-07-13 01:46:29.804850: step 29440/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000275, rela_loss = 0.222403, bind_loss = 0.000000 (1.543 sec/batch), lr: 0.000100
2021-07-13 01:46:59.833000: step 29460/164800 (epoch 15/80),jp_loss = 0.002014, trig_loss = 0.000122, rela_loss = 0.000001, bind_loss = 0.000030 (2.199 sec/batch), lr: 0.000100
2021-07-13 01:47:37.520089: step 29480/164800 (epoch 15/80),jp_loss = 0.000137, trig_loss = 0.024597, rela_loss = 0.000005, bind_loss = 0.000000 (1.531 sec/batch), lr: 0.000100
2021-07-13 01:48:05.265299: step 29500/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000488, rela_loss = 0.000023, bind_loss = 0.000000 (0.801 sec/batch), lr: 0.000100
2021-07-13 01:48:34.251914: step 29520/164800 (epoch 15/80),jp_loss = 0.000244, trig_loss = 0.000092, rela_loss = 0.001415, bind_loss = 0.000000 (1.702 sec/batch), lr: 0.000100
2021-07-13 01:49:03.433644: step 29540/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.001816, rela_loss = 0.000003, bind_loss = 0.000000 (1.292 sec/batch), lr: 0.000100
2021-07-13 01:49:35.994859: step 29560/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 1.086624, rela_loss = 0.000023, bind_loss = 0.000000 (0.798 sec/batch), lr: 0.000100
2021-07-13 01:50:06.778014: step 29580/164800 (epoch 15/80),jp_loss = 0.000153, trig_loss = 0.001068, rela_loss = 0.000001, bind_loss = 0.000000 (1.532 sec/batch), lr: 0.000100
2021-07-13 01:50:45.905964: step 29600/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000000 (1.205 sec/batch), lr: 0.000100
2021-07-13 01:51:23.621213: step 29620/164800 (epoch 15/80),jp_loss = 0.000008, trig_loss = 0.000023, rela_loss = 0.000000, bind_loss = 0.000000 (0.499 sec/batch), lr: 0.000100
2021-07-13 01:52:10.480068: step 29640/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 0.000458, rela_loss = 0.000000, bind_loss = 0.000000 (1.069 sec/batch), lr: 0.000100
2021-07-13 01:52:42.462517: step 29660/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.001892, rela_loss = 0.000002, bind_loss = 0.000000 (1.601 sec/batch), lr: 0.000100
2021-07-13 01:53:21.137093: step 29680/164800 (epoch 15/80),jp_loss = 0.000336, trig_loss = 0.000214, rela_loss = 0.000124, bind_loss = 0.019438 (5.240 sec/batch), lr: 0.000100
2021-07-13 01:53:50.189818: step 29700/164800 (epoch 15/80),jp_loss = 0.000427, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.196 sec/batch), lr: 0.000100
2021-07-13 01:54:22.315454: step 29720/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000549, rela_loss = 0.000000, bind_loss = 0.000000 (3.188 sec/batch), lr: 0.000100
2021-07-13 01:54:49.437639: step 29740/164800 (epoch 15/80),jp_loss = 0.000099, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.564 sec/batch), lr: 0.000100
2021-07-13 01:55:25.317667: step 29760/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (0.834 sec/batch), lr: 0.000100
2021-07-13 01:56:04.825029: step 29780/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000014, bind_loss = 0.000000 (0.907 sec/batch), lr: 0.000100
2021-07-13 01:56:38.029229: step 29800/164800 (epoch 15/80),jp_loss = 1.201920, trig_loss = 0.000336, rela_loss = 0.058059, bind_loss = 0.000000 (2.289 sec/batch), lr: 0.000100
2021-07-13 01:57:12.101081: step 29820/164800 (epoch 15/80),jp_loss = 0.000046, trig_loss = 0.010284, rela_loss = 0.000000, bind_loss = 0.000000 (0.622 sec/batch), lr: 0.000100
2021-07-13 01:57:52.839744: step 29840/164800 (epoch 15/80),jp_loss = 0.000336, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.114 sec/batch), lr: 0.000100
2021-07-13 01:58:26.946497: step 29860/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 3.984680, rela_loss = 0.000001, bind_loss = 0.000000 (2.244 sec/batch), lr: 0.000100
2021-07-13 01:58:59.254957: step 29880/164800 (epoch 15/80),jp_loss = 0.001343, trig_loss = 0.001221, rela_loss = 0.000000, bind_loss = 0.000000 (1.449 sec/batch), lr: 0.000100
2021-07-13 01:59:25.764209: step 29900/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000244, rela_loss = 0.000001, bind_loss = 0.000000 (0.895 sec/batch), lr: 0.000100
2021-07-13 01:59:58.281553: step 29920/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000610, rela_loss = 0.000026, bind_loss = 0.000000 (1.356 sec/batch), lr: 0.000100
2021-07-13 02:00:22.303880: step 29940/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000043 (1.588 sec/batch), lr: 0.000100
2021-07-13 02:01:01.887454: step 29960/164800 (epoch 15/80),jp_loss = 0.000038, trig_loss = 0.000244, rela_loss = 0.000002, bind_loss = 0.000000 (1.132 sec/batch), lr: 0.000100
2021-07-13 02:01:38.060599: step 29980/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.677 sec/batch), lr: 0.000100
2021-07-13 02:02:09.839221: step 30000/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000820, bind_loss = 0.000005 (0.742 sec/batch), lr: 0.000100
2021-07-13 02:02:38.209554: step 30020/164800 (epoch 15/80),jp_loss = 0.000458, trig_loss = 2.779114, rela_loss = 0.000001, bind_loss = 0.000002 (1.569 sec/batch), lr: 0.000100
2021-07-13 02:03:05.281135: step 30040/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 0.000031, rela_loss = 0.441600, bind_loss = 0.000000 (0.512 sec/batch), lr: 0.000100
2021-07-13 02:03:35.013584: step 30060/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.001916 (3.029 sec/batch), lr: 0.000100
2021-07-13 02:04:14.247288: step 30080/164800 (epoch 15/80),jp_loss = 0.000107, trig_loss = 9.979233, rela_loss = 0.000000, bind_loss = 0.000000 (3.206 sec/batch), lr: 0.000100
2021-07-13 02:04:45.723485: step 30100/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000305, rela_loss = 0.000007, bind_loss = 0.000000 (1.313 sec/batch), lr: 0.000100
2021-07-13 02:05:21.758430: step 30120/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000152, bind_loss = 0.000020 (2.067 sec/batch), lr: 0.000100
2021-07-13 02:05:51.044939: step 30140/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000519, rela_loss = 0.000006, bind_loss = 0.000000 (1.248 sec/batch), lr: 0.000100
2021-07-13 02:06:33.106413: step 30160/164800 (epoch 15/80),jp_loss = 0.000320, trig_loss = 8.075958, rela_loss = 0.000499, bind_loss = 0.000000 (2.818 sec/batch), lr: 0.000100
2021-07-13 02:07:00.150894: step 30180/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.007721, rela_loss = 0.000005, bind_loss = 0.000000 (1.324 sec/batch), lr: 0.000100
2021-07-13 02:07:32.675701: step 30200/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.038116, rela_loss = 0.000014, bind_loss = 0.000000 (0.844 sec/batch), lr: 0.000100
2021-07-13 02:08:14.067796: step 30220/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.160126, rela_loss = 0.000004, bind_loss = 0.000042 (1.806 sec/batch), lr: 0.000100
2021-07-13 02:08:53.569963: step 30240/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.157013, rela_loss = 0.000067, bind_loss = 0.000000 (1.401 sec/batch), lr: 0.000100
2021-07-13 02:09:22.520892: step 30260/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.002292, bind_loss = 0.000000 (1.034 sec/batch), lr: 0.000100
2021-07-13 02:09:48.696694: step 30280/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.391 sec/batch), lr: 0.000100
2021-07-13 02:10:13.506176: step 30300/164800 (epoch 15/80),jp_loss = 0.000046, trig_loss = 0.000214, rela_loss = 0.000023, bind_loss = 0.000044 (1.747 sec/batch), lr: 0.000100
2021-07-13 02:10:45.686797: step 30320/164800 (epoch 15/80),jp_loss = 0.002319, trig_loss = 0.000061, rela_loss = 0.000164, bind_loss = 0.000000 (2.470 sec/batch), lr: 0.000100
2021-07-13 02:11:16.072972: step 30340/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (0.760 sec/batch), lr: 0.000100
2021-07-13 02:11:53.294657: step 30360/164800 (epoch 15/80),jp_loss = 0.000137, trig_loss = 0.000381, rela_loss = 0.000000, bind_loss = 0.000000 (0.967 sec/batch), lr: 0.000100
2021-07-13 02:12:16.097829: step 30380/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.001129, rela_loss = 0.000013, bind_loss = 0.000000 (2.344 sec/batch), lr: 0.000100
2021-07-13 02:13:04.370610: step 30400/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000549, rela_loss = 0.000040, bind_loss = 0.000000 (3.087 sec/batch), lr: 0.000100
2021-07-13 02:13:31.774979: step 30420/164800 (epoch 15/80),jp_loss = 0.000107, trig_loss = 0.000214, rela_loss = 0.000165, bind_loss = 0.000000 (1.286 sec/batch), lr: 0.000100
2021-07-13 02:14:04.670532: step 30440/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.907 sec/batch), lr: 0.000100
2021-07-13 02:14:30.458279: step 30460/164800 (epoch 15/80),jp_loss = 0.000076, trig_loss = 0.000145, rela_loss = 0.000024, bind_loss = 0.000000 (0.551 sec/batch), lr: 0.000100
2021-07-13 02:15:10.277520: step 30480/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.020111, rela_loss = 0.000000, bind_loss = 0.000000 (2.096 sec/batch), lr: 0.000100
2021-07-13 02:15:44.412978: step 30500/164800 (epoch 15/80),jp_loss = 0.000122, trig_loss = 0.000214, rela_loss = 0.002692, bind_loss = 0.000000 (1.471 sec/batch), lr: 0.000100
2021-07-13 02:16:06.651246: step 30520/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 0.000183, rela_loss = 0.000078, bind_loss = 0.000000 (0.970 sec/batch), lr: 0.000100
2021-07-13 02:16:34.498168: step 30540/164800 (epoch 15/80),jp_loss = 0.000244, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (1.972 sec/batch), lr: 0.000100
2021-07-13 02:17:01.002680: step 30560/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (0.655 sec/batch), lr: 0.000100
2021-07-13 02:17:32.039718: step 30580/164800 (epoch 15/80),jp_loss = 0.000290, trig_loss = 0.014465, rela_loss = 0.000000, bind_loss = 0.000000 (2.563 sec/batch), lr: 0.000100
2021-07-13 02:18:01.475135: step 30600/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.001617, rela_loss = 0.000008, bind_loss = 0.000000 (1.677 sec/batch), lr: 0.000100
2021-07-13 02:18:33.844834: step 30620/164800 (epoch 15/80),jp_loss = 0.001282, trig_loss = 0.000916, rela_loss = 0.000079, bind_loss = 0.000000 (1.828 sec/batch), lr: 0.000100
2021-07-13 02:19:17.737500: step 30640/164800 (epoch 15/80),jp_loss = 0.000061, trig_loss = 0.000198, rela_loss = 0.000002, bind_loss = 0.000022 (3.405 sec/batch), lr: 0.000100
2021-07-13 02:19:47.297800: step 30660/164800 (epoch 15/80),jp_loss = 0.000122, trig_loss = 5.151489, rela_loss = 0.000001, bind_loss = 0.000000 (0.949 sec/batch), lr: 0.000100
2021-07-13 02:20:18.969265: step 30680/164800 (epoch 15/80),jp_loss = 0.000443, trig_loss = 0.000305, rela_loss = 2.036385, bind_loss = 0.000000 (3.511 sec/batch), lr: 0.000100
2021-07-13 02:21:05.618848: step 30700/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000549, rela_loss = 0.000000, bind_loss = 0.000000 (2.021 sec/batch), lr: 0.000100
2021-07-13 02:21:35.116313: step 30720/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.001251, rela_loss = 0.000001, bind_loss = 0.000000 (2.151 sec/batch), lr: 0.000100
2021-07-13 02:22:23.924129: step 30740/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000153, rela_loss = 0.000008, bind_loss = 0.000000 (0.739 sec/batch), lr: 0.000100
2021-07-13 02:22:53.060578: step 30760/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.630981, rela_loss = 0.000004, bind_loss = 0.000000 (4.326 sec/batch), lr: 0.000100
2021-07-13 02:23:25.682966: step 30780/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.904 sec/batch), lr: 0.000100
2021-07-13 02:23:57.860322: step 30800/164800 (epoch 15/80),jp_loss = 0.000031, trig_loss = 4.960632, rela_loss = 1.220526, bind_loss = 0.000007 (4.008 sec/batch), lr: 0.000100
2021-07-13 02:24:24.311109: step 30820/164800 (epoch 15/80),jp_loss = 0.000092, trig_loss = 0.000092, rela_loss = 0.000033, bind_loss = 0.000000 (0.910 sec/batch), lr: 0.000100
2021-07-13 02:24:57.764802: step 30840/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000671, rela_loss = 0.000000, bind_loss = 0.000000 (1.637 sec/batch), lr: 0.000100
2021-07-13 02:25:28.138821: step 30860/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000002, bind_loss = 0.000000 (1.248 sec/batch), lr: 0.000100
2021-07-13 02:26:00.624553: step 30880/164800 (epoch 15/80),jp_loss = 0.000015, trig_loss = 0.000107, rela_loss = 0.000026, bind_loss = 0.000026 (1.556 sec/batch), lr: 0.000100
2021-07-13 02:26:32.063372: step 30900/164800 (epoch 15/80),jp_loss = 0.000000, trig_loss = 4.530731, rela_loss = 0.000011, bind_loss = 0.000000 (1.534 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.86%  R:  99.72%  F1:  99.79%  #: 2174

Final Score:
Precision (micro): 99.862%
   Recall (micro): 99.724%
       F1 (micro): 99.793%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  99.66%  R:  99.33%  F1:  99.49%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  97.81%  R:  98.02%  F1:  97.91%  #: 455
Localization         P:  98.34%  R: 100.00%  F1:  99.16%  #: 178
Negative_regulation  P:  99.28%  R:  98.34%  F1:  98.81%  #: 421
Phosphorylation      P:  94.44%  R:  98.71%  F1:  96.53%  #: 155
Positive_regulation  P:  99.68%  R:  98.41%  F1:  99.04%  #: 627
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  96.55%  R:  95.15%  F1:  95.84%  #: 206
Transcription        P:  91.55%  R:  97.01%  F1:  94.20%  #: 67

Final Score:
Precision (micro): 98.275%
   Recall (micro): 98.034%
       F1 (micro): 98.154%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  97.14%  R:  97.54%  F1:  97.34%  #: 488
Gene_expression      P:  97.07%  R:  97.24%  F1:  97.15%  #: 579
Localization         P:  96.39%  R:  97.40%  F1:  96.89%  #: 192
Negative_regulation  P:  95.41%  R:  95.11%  F1:  95.26%  #: 655
Phosphorylation      P:  95.10%  R:  98.48%  F1:  96.76%  #: 197
Positive_regulation  P:  95.97%  R:  95.45%  F1:  95.71%  #: 923
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  91.03%  R:  92.31%  F1:  91.67%  #: 286
Transcription        P:  89.66%  R:  87.64%  F1:  88.64%  #: 89

Final Score:
Precision (micro): 95.618%
   Recall (micro): 95.813%
       F1 (micro): 95.715%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  92.51%  R:  96.11%  F1:  94.28%  #: 180

Final Score:
Precision (micro): 92.513%
   Recall (micro): 96.111%
       F1 (micro): 94.278%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  93.31%  R:  94.90%  F1:  94.10%  #: 353

Gene_expression      P:  97.91%  R:  97.24%  F1:  97.57%  #: 579

Localization         P:  97.40%  R:  97.40%  F1:  97.40%  #: 192

Negative_regulation  P:  93.33%  R:  75.53%  F1:  83.49%  #: 519

Phosphorylation      P:  88.54%  R:  89.01%  F1:  88.77%  #: 191

Positive_regulation  P:  95.62%  R:  79.46%  F1:  86.79%  #: 852

Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30

Regulation           P:  95.61%  R:  72.86%  F1:  82.70%  #: 269

Transcription        P:  90.70%  R:  87.64%  F1:  89.14%  #: 89

Final Score:
Precision (micro): 94.940%
   Recall (micro): 85.459%
       F1 (micro): 89.950%
epoch 15: train_loss = 0.086067, dev_loss = 0.000000, dev_rela_f1 = 0.8995
0.9116799457535176 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_15.pt

2021-07-13 02:38:37.312621: step 30920/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000977, rela_loss = 0.000000, bind_loss = 0.000000 (2.048 sec/batch), lr: 0.000100
2021-07-13 02:39:13.030023: step 30940/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 5.132874, rela_loss = 0.005460, bind_loss = 0.000000 (0.962 sec/batch), lr: 0.000100
2021-07-13 02:39:58.712144: step 30960/164800 (epoch 16/80),jp_loss = 0.012146, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.922 sec/batch), lr: 0.000100
2021-07-13 02:40:27.600779: step 30980/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000946, rela_loss = 0.000000, bind_loss = 0.000000 (0.735 sec/batch), lr: 0.000100
2021-07-13 02:41:09.431938: step 31000/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000336, rela_loss = 0.000003, bind_loss = 0.000000 (0.844 sec/batch), lr: 0.000100
2021-07-13 02:41:43.829051: step 31020/164800 (epoch 16/80),jp_loss = 0.000183, trig_loss = 0.000122, rela_loss = 0.000006, bind_loss = 0.000000 (1.546 sec/batch), lr: 0.000100
2021-07-13 02:42:22.190757: step 31040/164800 (epoch 16/80),jp_loss = 0.000122, trig_loss = 0.000053, rela_loss = 0.000007, bind_loss = 0.000017 (0.716 sec/batch), lr: 0.000100
2021-07-13 02:42:49.632058: step 31060/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000092, rela_loss = 0.000005, bind_loss = 0.000000 (0.802 sec/batch), lr: 0.000100
2021-07-13 02:43:26.760060: step 31080/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000671, rela_loss = 0.000282, bind_loss = 0.000000 (1.504 sec/batch), lr: 0.000100
2021-07-13 02:43:54.696716: step 31100/164800 (epoch 16/80),jp_loss = 0.000153, trig_loss = 0.001663, rela_loss = 0.000002, bind_loss = 0.000000 (1.832 sec/batch), lr: 0.000100
2021-07-13 02:44:26.664986: step 31120/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.002197, rela_loss = 0.000003, bind_loss = 0.000000 (0.724 sec/batch), lr: 0.000100
2021-07-13 02:45:07.602309: step 31140/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.009430, rela_loss = 0.000000, bind_loss = 0.000000 (0.941 sec/batch), lr: 0.000100
2021-07-13 02:45:38.118340: step 31160/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000001, bind_loss = 0.000000 (1.565 sec/batch), lr: 0.000100
2021-07-13 02:46:16.773594: step 31180/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.000107, rela_loss = 0.000000, bind_loss = 0.000000 (0.552 sec/batch), lr: 0.000100
2021-07-13 02:46:53.126218: step 31200/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000001, bind_loss = 0.000000 (0.659 sec/batch), lr: 0.000100
2021-07-13 02:47:25.087327: step 31220/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.005493, rela_loss = 0.006948, bind_loss = 0.000000 (1.202 sec/batch), lr: 0.000100
2021-07-13 02:48:00.422255: step 31240/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.741 sec/batch), lr: 0.000100
2021-07-13 02:48:36.076576: step 31260/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.002136, rela_loss = 0.000003, bind_loss = 0.000000 (0.845 sec/batch), lr: 0.000100
2021-07-13 02:48:59.993331: step 31280/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.068542, rela_loss = 0.000047, bind_loss = 0.000019 (1.961 sec/batch), lr: 0.000100
2021-07-13 02:49:24.933959: step 31300/164800 (epoch 16/80),jp_loss = 0.003235, trig_loss = 0.000305, rela_loss = 0.000001, bind_loss = 0.000000 (1.078 sec/batch), lr: 0.000100
2021-07-13 02:50:09.133613: step 31320/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000946, rela_loss = 0.000108, bind_loss = 0.000000 (2.495 sec/batch), lr: 0.000100
2021-07-13 02:50:38.987458: step 31340/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000732, rela_loss = 0.000000, bind_loss = 0.000000 (1.055 sec/batch), lr: 0.000100
2021-07-13 02:51:05.718846: step 31360/164800 (epoch 16/80),jp_loss = 0.000130, trig_loss = 0.000198, rela_loss = 0.677240, bind_loss = 0.000004 (1.342 sec/batch), lr: 0.000100
2021-07-13 02:51:58.877624: step 31380/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000793, rela_loss = 0.002178, bind_loss = 0.000000 (6.662 sec/batch), lr: 0.000100
2021-07-13 02:52:24.474124: step 31400/164800 (epoch 16/80),jp_loss = 0.000046, trig_loss = 0.000122, rela_loss = 0.000001, bind_loss = 0.000000 (0.648 sec/batch), lr: 0.000100
2021-07-13 02:52:55.034074: step 31420/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (0.922 sec/batch), lr: 0.000100
2021-07-13 02:53:36.564128: step 31440/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000012, bind_loss = 0.000000 (0.976 sec/batch), lr: 0.000100
2021-07-13 02:54:17.011642: step 31460/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.001740, rela_loss = 0.000175, bind_loss = 0.000000 (3.715 sec/batch), lr: 0.000100
2021-07-13 02:54:59.013923: step 31480/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.158936, rela_loss = 0.000000, bind_loss = 0.000000 (1.957 sec/batch), lr: 0.000100
2021-07-13 02:55:27.336391: step 31500/164800 (epoch 16/80),jp_loss = 0.000015, trig_loss = 0.000183, rela_loss = 0.000004, bind_loss = 0.000000 (1.709 sec/batch), lr: 0.000100
2021-07-13 02:55:57.261936: step 31520/164800 (epoch 16/80),jp_loss = 0.005402, trig_loss = 0.000336, rela_loss = 0.006284, bind_loss = 0.000010 (2.897 sec/batch), lr: 0.000100
2021-07-13 02:56:35.049650: step 31540/164800 (epoch 16/80),jp_loss = 0.000046, trig_loss = 0.001678, rela_loss = 0.000001, bind_loss = 0.000000 (1.525 sec/batch), lr: 0.000100
2021-07-13 02:57:02.424881: step 31560/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000153, rela_loss = 0.000229, bind_loss = 0.000000 (0.741 sec/batch), lr: 0.000100
2021-07-13 02:57:30.077072: step 31580/164800 (epoch 16/80),jp_loss = 0.000153, trig_loss = 0.000244, rela_loss = 0.000001, bind_loss = 0.000000 (1.147 sec/batch), lr: 0.000100
2021-07-13 02:57:59.271441: step 31600/164800 (epoch 16/80),jp_loss = 0.000015, trig_loss = 0.000809, rela_loss = 0.000003, bind_loss = 0.000000 (1.286 sec/batch), lr: 0.000100
2021-07-13 02:58:30.977194: step 31620/164800 (epoch 16/80),jp_loss = 0.000015, trig_loss = 0.000381, rela_loss = 0.000007, bind_loss = 0.000000 (0.936 sec/batch), lr: 0.000100
2021-07-13 02:59:00.963720: step 31640/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.534 sec/batch), lr: 0.000100
2021-07-13 02:59:38.129274: step 31660/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000021, bind_loss = 0.000000 (0.850 sec/batch), lr: 0.000100
2021-07-13 03:00:17.965537: step 31680/164800 (epoch 16/80),jp_loss = 0.000023, trig_loss = 0.000038, rela_loss = 0.000000, bind_loss = 0.000000 (0.445 sec/batch), lr: 0.000100
2021-07-13 03:01:05.880662: step 31700/164800 (epoch 16/80),jp_loss = 0.000046, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (1.067 sec/batch), lr: 0.000100
2021-07-13 03:01:38.748488: step 31720/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (1.707 sec/batch), lr: 0.000100
2021-07-13 03:02:16.834733: step 31740/164800 (epoch 16/80),jp_loss = 0.000153, trig_loss = 0.000702, rela_loss = 0.000010, bind_loss = 0.003377 (4.838 sec/batch), lr: 0.000100
2021-07-13 03:02:46.943096: step 31760/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000056, bind_loss = 0.000000 (1.103 sec/batch), lr: 0.000100
2021-07-13 03:03:18.888733: step 31780/164800 (epoch 16/80),jp_loss = 0.000122, trig_loss = 0.000610, rela_loss = 0.000000, bind_loss = 0.000000 (3.505 sec/batch), lr: 0.000100
2021-07-13 03:03:46.945969: step 31800/164800 (epoch 16/80),jp_loss = 0.000305, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.594 sec/batch), lr: 0.000100
2021-07-13 03:04:23.094638: step 31820/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000013, bind_loss = 0.000000 (0.802 sec/batch), lr: 0.000100
2021-07-13 03:05:01.747469: step 31840/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000519, rela_loss = 0.000014, bind_loss = 0.000000 (0.835 sec/batch), lr: 0.000100
2021-07-13 03:05:35.381633: step 31860/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000290, bind_loss = 0.000000 (2.546 sec/batch), lr: 0.000100
2021-07-13 03:06:08.449243: step 31880/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000397, rela_loss = 0.000000, bind_loss = 0.000000 (0.620 sec/batch), lr: 0.000100
2021-07-13 03:06:49.686545: step 31900/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000732, rela_loss = 0.000025, bind_loss = 0.000000 (1.201 sec/batch), lr: 0.000100
2021-07-13 03:07:25.259464: step 31920/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.001343, rela_loss = 0.000006, bind_loss = 0.000000 (2.575 sec/batch), lr: 0.000100
2021-07-13 03:07:57.602268: step 31940/164800 (epoch 16/80),jp_loss = 0.000854, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.445 sec/batch), lr: 0.000100
2021-07-13 03:08:24.192069: step 31960/164800 (epoch 16/80),jp_loss = 0.000107, trig_loss = 0.000031, rela_loss = 0.000016, bind_loss = 0.000000 (1.302 sec/batch), lr: 0.000100
2021-07-13 03:08:58.283524: step 31980/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000010, bind_loss = 0.000000 (1.395 sec/batch), lr: 0.000100
2021-07-13 03:09:22.299440: step 32000/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000019, bind_loss = 0.005585 (1.552 sec/batch), lr: 0.000100
2021-07-13 03:10:02.425557: step 32020/164800 (epoch 16/80),jp_loss = 0.000038, trig_loss = 0.000061, rela_loss = 0.000221, bind_loss = 0.000000 (1.142 sec/batch), lr: 0.000100
2021-07-13 03:10:39.286343: step 32040/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000168, rela_loss = 0.000000, bind_loss = 0.000000 (0.631 sec/batch), lr: 0.000100
2021-07-13 03:11:12.411682: step 32060/164800 (epoch 16/80),jp_loss = 0.000244, trig_loss = 0.000076, rela_loss = 0.000007, bind_loss = 0.000068 (0.826 sec/batch), lr: 0.000100
2021-07-13 03:11:42.664075: step 32080/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000047, bind_loss = 0.000495 (1.539 sec/batch), lr: 0.000100
2021-07-13 03:12:10.787139: step 32100/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000046, rela_loss = 0.000006, bind_loss = 0.000000 (0.526 sec/batch), lr: 0.000100
2021-07-13 03:12:42.629160: step 32120/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 1.853394, rela_loss = 0.000000, bind_loss = 1.165747 (2.962 sec/batch), lr: 0.000100
2021-07-13 03:13:23.534982: step 32140/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (3.263 sec/batch), lr: 0.000100
2021-07-13 03:13:55.492295: step 32160/164800 (epoch 16/80),jp_loss = 0.000046, trig_loss = 0.000641, rela_loss = 0.000378, bind_loss = 0.000000 (1.359 sec/batch), lr: 0.000100
2021-07-13 03:14:33.271417: step 32180/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000003, bind_loss = 0.000257 (1.970 sec/batch), lr: 0.000100
2021-07-13 03:15:01.238429: step 32200/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.216980, rela_loss = 0.000000, bind_loss = 0.000000 (1.129 sec/batch), lr: 0.000100
2021-07-13 03:15:44.956127: step 32220/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 1.789230, rela_loss = 3.667930, bind_loss = 0.000000 (2.958 sec/batch), lr: 0.000100
2021-07-13 03:16:11.563629: step 32240/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000002, bind_loss = 0.000000 (1.380 sec/batch), lr: 0.000100
2021-07-13 03:16:45.713753: step 32260/164800 (epoch 16/80),jp_loss = 1.040680, trig_loss = 0.000366, rela_loss = 0.000034, bind_loss = 0.000000 (0.951 sec/batch), lr: 0.000100
2021-07-13 03:17:27.087622: step 32280/164800 (epoch 16/80),jp_loss = 12.781189, trig_loss = 0.000458, rela_loss = 0.000001, bind_loss = 0.000227 (2.133 sec/batch), lr: 0.000100
2021-07-13 03:18:06.392819: step 32300/164800 (epoch 16/80),jp_loss = 0.000015, trig_loss = 0.000504, rela_loss = 0.053551, bind_loss = 0.000000 (1.261 sec/batch), lr: 0.000100
2021-07-13 03:18:34.990005: step 32320/164800 (epoch 16/80),jp_loss = 0.000015, trig_loss = 0.000092, rela_loss = 0.041073, bind_loss = 0.000000 (1.146 sec/batch), lr: 0.000100
2021-07-13 03:19:01.463279: step 32340/164800 (epoch 16/80),jp_loss = 0.001099, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (1.430 sec/batch), lr: 0.000100
2021-07-13 03:19:27.591954: step 32360/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000366, rela_loss = 0.000004, bind_loss = 0.000560 (1.855 sec/batch), lr: 0.000100
2021-07-13 03:19:58.529374: step 32380/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000160, bind_loss = 0.000000 (1.923 sec/batch), lr: 0.000100
2021-07-13 03:20:28.286718: step 32400/164800 (epoch 16/80),jp_loss = 0.000076, trig_loss = 0.000336, rela_loss = 0.000003, bind_loss = 0.000000 (0.715 sec/batch), lr: 0.000100
2021-07-13 03:21:06.525170: step 32420/164800 (epoch 16/80),jp_loss = 0.000072, trig_loss = 0.000107, rela_loss = 0.000014, bind_loss = 0.000000 (0.947 sec/batch), lr: 0.000100
2021-07-13 03:21:28.794653: step 32440/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000702, rela_loss = 0.000036, bind_loss = 0.000000 (1.771 sec/batch), lr: 0.000100
2021-07-13 03:22:15.447139: step 32460/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000610, rela_loss = 2.150722, bind_loss = 0.000000 (3.073 sec/batch), lr: 0.000100
2021-07-13 03:22:42.662246: step 32480/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000793, rela_loss = 0.000006, bind_loss = 0.000000 (1.493 sec/batch), lr: 0.000100
2021-07-13 03:23:14.371959: step 32500/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000458, rela_loss = 0.000001, bind_loss = 0.000000 (1.890 sec/batch), lr: 0.000100
2021-07-13 03:23:41.170871: step 32520/164800 (epoch 16/80),jp_loss = 0.000160, trig_loss = 0.000145, rela_loss = 0.000087, bind_loss = 0.000000 (0.537 sec/batch), lr: 0.000100
2021-07-13 03:24:20.104082: step 32540/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000458, rela_loss = 0.000004, bind_loss = 0.000000 (2.119 sec/batch), lr: 0.000100
2021-07-13 03:24:53.672393: step 32560/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (1.493 sec/batch), lr: 0.000100
2021-07-13 03:25:15.590207: step 32580/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000473, rela_loss = 0.000001, bind_loss = 0.000000 (0.979 sec/batch), lr: 0.000100
2021-07-13 03:25:43.622731: step 32600/164800 (epoch 16/80),jp_loss = 0.109863, trig_loss = 0.002991, rela_loss = 0.000000, bind_loss = 0.000000 (2.126 sec/batch), lr: 0.000100
2021-07-13 03:26:09.109719: step 32620/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000005, bind_loss = 0.000000 (0.698 sec/batch), lr: 0.000100
2021-07-13 03:26:38.763674: step 32640/164800 (epoch 16/80),jp_loss = 0.000717, trig_loss = 0.000671, rela_loss = 0.000002, bind_loss = 0.000000 (2.765 sec/batch), lr: 0.000100
2021-07-13 03:27:07.059639: step 32660/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000366, rela_loss = 0.000095, bind_loss = 0.000000 (1.825 sec/batch), lr: 0.000100
2021-07-13 03:27:38.264668: step 32680/164800 (epoch 16/80),jp_loss = 0.001282, trig_loss = 0.000244, rela_loss = 0.000008, bind_loss = 0.000000 (1.934 sec/batch), lr: 0.000100
2021-07-13 03:28:21.778278: step 32700/164800 (epoch 16/80),jp_loss = 0.000427, trig_loss = 0.000305, rela_loss = 0.000007, bind_loss = 0.000071 (3.646 sec/batch), lr: 0.000100
2021-07-13 03:28:51.093258: step 32720/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000003, bind_loss = 0.000000 (0.948 sec/batch), lr: 0.000100
2021-07-13 03:29:21.781605: step 32740/164800 (epoch 16/80),jp_loss = 0.000504, trig_loss = 0.000702, rela_loss = 0.020412, bind_loss = 0.000000 (3.377 sec/batch), lr: 0.000100
2021-07-13 03:30:09.149684: step 32760/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000005, bind_loss = 0.000000 (2.096 sec/batch), lr: 0.000100
2021-07-13 03:30:38.237755: step 32780/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.000595, rela_loss = 0.000021, bind_loss = 0.000000 (2.139 sec/batch), lr: 0.000100
2021-07-13 03:31:26.622975: step 32800/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000214, rela_loss = 0.000020, bind_loss = 0.000000 (0.845 sec/batch), lr: 0.000100
2021-07-13 03:31:54.361535: step 32820/164800 (epoch 16/80),jp_loss = 0.001282, trig_loss = 3.911560, rela_loss = 0.000007, bind_loss = 0.000000 (4.117 sec/batch), lr: 0.000100
2021-07-13 03:32:27.857769: step 32840/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000002, bind_loss = 0.000000 (0.935 sec/batch), lr: 0.000100
2021-07-13 03:33:00.106340: step 32860/164800 (epoch 16/80),jp_loss = 0.000092, trig_loss = 0.401123, rela_loss = 0.000000, bind_loss = 0.000101 (3.953 sec/batch), lr: 0.000100
2021-07-13 03:33:28.071711: step 32880/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (0.992 sec/batch), lr: 0.000100
2021-07-13 03:34:01.064719: step 32900/164800 (epoch 16/80),jp_loss = 0.000031, trig_loss = 0.002518, rela_loss = 0.000000, bind_loss = 0.000000 (1.704 sec/batch), lr: 0.000100
2021-07-13 03:34:30.642135: step 32920/164800 (epoch 16/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (1.363 sec/batch), lr: 0.000100
2021-07-13 03:35:03.942540: step 32940/164800 (epoch 16/80),jp_loss = 0.000290, trig_loss = 0.000107, rela_loss = 0.000065, bind_loss = 0.000246 (1.651 sec/batch), lr: 0.000100
2021-07-13 03:35:35.294184: step 32960/164800 (epoch 16/80),jp_loss = 0.000000, trig_loss = 0.000397, rela_loss = 0.000156, bind_loss = 0.000000 (1.505 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.77%  R:  99.72%  F1:  99.75%  #: 2174

Final Score:
Precision (micro): 99.770%
   Recall (micro): 99.724%
       F1 (micro): 99.747%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P: 100.00%  R: 100.00%  F1: 100.00%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  98.04%  R:  98.90%  F1:  98.47%  #: 455
Localization         P:  99.44%  R: 100.00%  F1:  99.72%  #: 178
Negative_regulation  P: 100.00%  R:  98.57%  F1:  99.28%  #: 421
Phosphorylation      P:  97.44%  R:  98.06%  F1:  97.75%  #: 155
Positive_regulation  P:  99.03%  R:  98.09%  F1:  98.56%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  99.50%  R:  97.09%  F1:  98.28%  #: 206
Transcription        P: 100.00%  R:  98.51%  F1:  99.25%  #: 67

Final Score:
Precision (micro): 99.052%
   Recall (micro): 98.402%
       F1 (micro): 98.726%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  97.91%  R:  96.11%  F1:  97.00%  #: 488
Gene_expression      P:  97.95%  R:  98.46%  F1:  98.20%  #: 583
Localization         P:  97.41%  R:  97.92%  F1:  97.66%  #: 192
Negative_regulation  P:  98.00%  R:  97.10%  F1:  97.55%  #: 655
Phosphorylation      P:  96.98%  R:  97.97%  F1:  97.47%  #: 197
Positive_regulation  P:  96.51%  R:  95.99%  F1:  96.25%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  97.14%  R:  95.10%  F1:  96.11%  #: 286
Transcription        P:  97.73%  R:  97.73%  F1:  97.73%  #: 88

Final Score:
Precision (micro): 97.371%
   Recall (micro): 96.833%
       F1 (micro): 97.101%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  94.92%  R:  93.85%  F1:  94.38%  #: 179

Final Score:
Precision (micro): 94.915%
   Recall (micro): 93.855%
       F1 (micro): 94.382%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  94.30%  R:  93.77%  F1:  94.03%  #: 353

Gene_expression      P:  98.46%  R:  98.46%  F1:  98.46%  #: 583

Localization         P:  97.41%  R:  97.92%  F1:  97.66%  #: 192

Negative_regulation  P:  96.68%  R:  78.61%  F1:  86.72%  #: 519

Phosphorylation      P:  90.37%  R:  88.48%  F1:  89.42%  #: 191

Positive_regulation  P:  96.75%  R:  76.88%  F1:  85.68%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  95.83%  R:  76.95%  F1:  85.36%  #: 269

Transcription        P:  97.73%  R:  97.73%  F1:  97.73%  #: 88

Final Score:
Precision (micro): 96.325%
   Recall (micro): 86.025%
       F1 (micro): 90.884%
epoch 16: train_loss = 0.058436, dev_loss = 0.000000, dev_rela_f1 = 0.9088
0.9116799457535176 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_16.pt

2021-07-13 03:47:37.997829: step 32980/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.001404, rela_loss = 5.153803, bind_loss = 0.000000 (2.374 sec/batch), lr: 0.000100
2021-07-13 03:48:15.623395: step 33000/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 5.842407, rela_loss = 0.000027, bind_loss = 0.000000 (1.091 sec/batch), lr: 0.000100
2021-07-13 03:49:02.647380: step 33020/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (0.812 sec/batch), lr: 0.000100
2021-07-13 03:49:32.836993: step 33040/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.671 sec/batch), lr: 0.000100
2021-07-13 03:50:16.791875: step 33060/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000641, rela_loss = 0.000003, bind_loss = 0.000000 (0.972 sec/batch), lr: 0.000100
2021-07-13 03:50:51.540524: step 33080/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000026, bind_loss = 0.000000 (1.625 sec/batch), lr: 0.000100
2021-07-13 03:51:30.294747: step 33100/164800 (epoch 17/80),jp_loss = 0.000038, trig_loss = 0.000069, rela_loss = 0.000000, bind_loss = 0.000002 (0.625 sec/batch), lr: 0.000100
2021-07-13 03:51:59.116434: step 33120/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000046, rela_loss = 0.000000, bind_loss = 0.000000 (0.883 sec/batch), lr: 0.000100
2021-07-13 03:52:38.028212: step 33140/164800 (epoch 17/80),jp_loss = 7.065887, trig_loss = 0.000244, rela_loss = 0.000294, bind_loss = 0.000000 (1.871 sec/batch), lr: 0.000100
2021-07-13 03:53:06.127385: step 33160/164800 (epoch 17/80),jp_loss = 0.000046, trig_loss = 0.000580, rela_loss = 0.000057, bind_loss = 0.000000 (1.642 sec/batch), lr: 0.000100
2021-07-13 03:53:37.822858: step 33180/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000198, rela_loss = 0.000001, bind_loss = 0.000000 (0.847 sec/batch), lr: 0.000100
2021-07-13 03:54:18.883209: step 33200/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.000275, rela_loss = 0.000000, bind_loss = 0.000000 (0.898 sec/batch), lr: 0.000100
2021-07-13 03:54:49.501803: step 33220/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000398, bind_loss = 0.000000 (1.394 sec/batch), lr: 0.000100
2021-07-13 03:55:27.043384: step 33240/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000061, rela_loss = 0.000012, bind_loss = 0.000000 (0.521 sec/batch), lr: 0.000100
2021-07-13 03:56:03.507969: step 33260/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.619 sec/batch), lr: 0.000100
2021-07-13 03:56:35.936199: step 33280/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000977, rela_loss = 0.002394, bind_loss = 0.000000 (1.259 sec/batch), lr: 0.000100
2021-07-13 03:57:11.634412: step 33300/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.705 sec/batch), lr: 0.000100
2021-07-13 03:57:47.899709: step 33320/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.917 sec/batch), lr: 0.000100
2021-07-13 03:58:12.114340: step 33340/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.003235, rela_loss = 0.000007, bind_loss = 0.000005 (1.951 sec/batch), lr: 0.000100
2021-07-13 03:58:37.420476: step 33360/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000427, rela_loss = 0.000014, bind_loss = 0.000000 (0.924 sec/batch), lr: 0.000100
2021-07-13 03:59:19.960019: step 33380/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000336, rela_loss = 0.186588, bind_loss = 0.000000 (2.316 sec/batch), lr: 0.000100
2021-07-13 03:59:49.517354: step 33400/164800 (epoch 17/80),jp_loss = 0.000244, trig_loss = 0.000122, rela_loss = 0.000006, bind_loss = 0.000000 (1.014 sec/batch), lr: 0.000100
2021-07-13 04:00:16.930827: step 33420/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000641, rela_loss = 0.001670, bind_loss = 0.000004 (1.152 sec/batch), lr: 0.000100
2021-07-13 04:01:09.064876: step 33440/164800 (epoch 17/80),jp_loss = 4.544861, trig_loss = 0.001770, rela_loss = 0.000021, bind_loss = 0.000000 (6.455 sec/batch), lr: 0.000100
2021-07-13 04:01:34.804002: step 33460/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.748 sec/batch), lr: 0.000100
2021-07-13 04:02:05.570536: step 33480/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.977 sec/batch), lr: 0.000100
2021-07-13 04:02:46.334130: step 33500/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (0.905 sec/batch), lr: 0.000100
2021-07-13 04:03:26.520318: step 33520/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.002136, rela_loss = 0.000458, bind_loss = 0.000000 (3.831 sec/batch), lr: 0.000100
2021-07-13 04:04:08.723413: step 33540/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.001801, rela_loss = 0.000018, bind_loss = 0.000000 (1.762 sec/batch), lr: 0.000100
2021-07-13 04:04:36.685422: step 33560/164800 (epoch 17/80),jp_loss = 0.000046, trig_loss = 0.000122, rela_loss = 0.000009, bind_loss = 0.000000 (1.740 sec/batch), lr: 0.000100
2021-07-13 04:05:06.090721: step 33580/164800 (epoch 17/80),jp_loss = 0.013153, trig_loss = 0.000427, rela_loss = 0.000001, bind_loss = 0.000066 (2.290 sec/batch), lr: 0.000100
2021-07-13 04:05:42.382136: step 33600/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000458, rela_loss = 0.000005, bind_loss = 0.000000 (1.714 sec/batch), lr: 0.000100
2021-07-13 04:06:10.566127: step 33620/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.001328, bind_loss = 0.000000 (0.722 sec/batch), lr: 0.000100
2021-07-13 04:06:38.710960: step 33640/164800 (epoch 17/80),jp_loss = 0.000259, trig_loss = 0.000153, rela_loss = 0.045505, bind_loss = 0.000000 (1.108 sec/batch), lr: 0.000100
2021-07-13 04:07:08.231581: step 33660/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000443, rela_loss = 0.000005, bind_loss = 0.000000 (1.663 sec/batch), lr: 0.000100
2021-07-13 04:07:41.711389: step 33680/164800 (epoch 17/80),jp_loss = 0.000107, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (1.141 sec/batch), lr: 0.000100
2021-07-13 04:08:12.721150: step 33700/164800 (epoch 17/80),jp_loss = 0.000183, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (1.499 sec/batch), lr: 0.000100
2021-07-13 04:08:51.531531: step 33720/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (0.911 sec/batch), lr: 0.000100
2021-07-13 04:09:29.519233: step 33740/164800 (epoch 17/80),jp_loss = 0.000008, trig_loss = 0.000114, rela_loss = 0.000025, bind_loss = 0.000000 (0.427 sec/batch), lr: 0.000100
2021-07-13 04:10:16.266114: step 33760/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (1.045 sec/batch), lr: 0.000100
2021-07-13 04:10:48.062654: step 33780/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 2.556549, rela_loss = 0.000000, bind_loss = 0.000000 (1.477 sec/batch), lr: 0.000100
2021-07-13 04:11:25.844085: step 33800/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.002754 (4.733 sec/batch), lr: 0.000100
2021-07-13 04:11:55.549334: step 33820/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (1.258 sec/batch), lr: 0.000100
2021-07-13 04:12:28.352969: step 33840/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000427, rela_loss = 0.000001, bind_loss = 0.000000 (3.292 sec/batch), lr: 0.000100
2021-07-13 04:12:56.141397: step 33860/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000076, rela_loss = 0.000000, bind_loss = 0.000000 (0.530 sec/batch), lr: 0.000100
2021-07-13 04:13:30.264079: step 33880/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000323, bind_loss = 0.000000 (0.910 sec/batch), lr: 0.000100
2021-07-13 04:14:08.754376: step 33900/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000549, rela_loss = 0.000028, bind_loss = 0.000000 (0.772 sec/batch), lr: 0.000100
2021-07-13 04:14:41.352733: step 33920/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000057, bind_loss = 0.000000 (2.241 sec/batch), lr: 0.000100
2021-07-13 04:15:15.370778: step 33940/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (0.701 sec/batch), lr: 0.000100
2021-07-13 04:15:56.596303: step 33960/164800 (epoch 17/80),jp_loss = 0.000092, trig_loss = 0.000122, rela_loss = 0.000003, bind_loss = 0.000000 (1.070 sec/batch), lr: 0.000100
2021-07-13 04:16:32.173914: step 33980/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000580, rela_loss = 0.000170, bind_loss = 0.000000 (2.438 sec/batch), lr: 0.000100
2021-07-13 04:17:04.057704: step 34000/164800 (epoch 17/80),jp_loss = 0.000397, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.334 sec/batch), lr: 0.000100
2021-07-13 04:17:31.189705: step 34020/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000009, bind_loss = 0.000000 (0.822 sec/batch), lr: 0.000100
2021-07-13 04:18:04.658147: step 34040/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000488, rela_loss = 0.000068, bind_loss = 0.000000 (1.391 sec/batch), lr: 0.000100
2021-07-13 04:18:28.923169: step 34060/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000040, bind_loss = 0.000029 (1.856 sec/batch), lr: 0.000100
2021-07-13 04:19:08.540710: step 34080/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000092, rela_loss = 0.000677, bind_loss = 0.000000 (1.133 sec/batch), lr: 0.000100
2021-07-13 04:19:44.725046: step 34100/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000005, bind_loss = 0.000000 (0.716 sec/batch), lr: 0.000100
2021-07-13 04:20:17.075049: step 34120/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000046, rela_loss = 0.000089, bind_loss = 0.000106 (0.819 sec/batch), lr: 0.000100
2021-07-13 04:20:46.373588: step 34140/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000017, bind_loss = 0.000297 (1.703 sec/batch), lr: 0.000100
2021-07-13 04:21:14.257917: step 34160/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000015, rela_loss = 0.000006, bind_loss = 0.000000 (0.499 sec/batch), lr: 0.000100
2021-07-13 04:21:44.792505: step 34180/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.256209 (3.133 sec/batch), lr: 0.000100
2021-07-13 04:22:24.480098: step 34200/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000778, rela_loss = 0.000000, bind_loss = 0.000000 (3.226 sec/batch), lr: 0.000100
2021-07-13 04:22:55.801980: step 34220/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.001404, rela_loss = 0.000006, bind_loss = 0.000000 (1.525 sec/batch), lr: 0.000100
2021-07-13 04:23:33.533203: step 34240/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000044 (1.858 sec/batch), lr: 0.000100
2021-07-13 04:24:02.401019: step 34260/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000004, bind_loss = 0.000000 (1.384 sec/batch), lr: 0.000100
2021-07-13 04:24:45.662247: step 34280/164800 (epoch 17/80),jp_loss = 0.000076, trig_loss = 5.503784, rela_loss = 0.000062, bind_loss = 0.000000 (3.143 sec/batch), lr: 0.000100
2021-07-13 04:25:12.348230: step 34300/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000305, rela_loss = 0.000037, bind_loss = 0.000000 (1.199 sec/batch), lr: 0.000100
2021-07-13 04:25:45.667770: step 34320/164800 (epoch 17/80),jp_loss = 0.000153, trig_loss = 0.120941, rela_loss = 0.000000, bind_loss = 0.000000 (1.045 sec/batch), lr: 0.000100
2021-07-13 04:26:27.449766: step 34340/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.003113, rela_loss = 0.000001, bind_loss = 0.000383 (1.819 sec/batch), lr: 0.000100
2021-07-13 04:27:08.383571: step 34360/164800 (epoch 17/80),jp_loss = 0.000336, trig_loss = 0.000336, rela_loss = 0.000187, bind_loss = 0.000000 (1.363 sec/batch), lr: 0.000100
2021-07-13 04:27:38.336679: step 34380/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000366, rela_loss = 0.000824, bind_loss = 0.000000 (1.085 sec/batch), lr: 0.000100
2021-07-13 04:28:04.234844: step 34400/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.676 sec/batch), lr: 0.000100
2021-07-13 04:28:30.403132: step 34420/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.000122, rela_loss = 0.000063, bind_loss = 0.000008 (1.948 sec/batch), lr: 0.000100
2021-07-13 04:29:01.293525: step 34440/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (1.947 sec/batch), lr: 0.000100
2021-07-13 04:29:31.895883: step 34460/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000488, rela_loss = 0.000004, bind_loss = 0.000000 (0.873 sec/batch), lr: 0.000100
2021-07-13 04:30:09.969394: step 34480/164800 (epoch 17/80),jp_loss = 0.000057, trig_loss = 0.000160, rela_loss = 0.000001, bind_loss = 0.000000 (1.049 sec/batch), lr: 0.000100
2021-07-13 04:30:33.490370: step 34500/164800 (epoch 17/80),jp_loss = 0.000092, trig_loss = 1.974487, rela_loss = 0.000009, bind_loss = 0.000000 (1.898 sec/batch), lr: 0.000100
2021-07-13 04:31:21.528213: step 34520/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000366, rela_loss = 0.000448, bind_loss = 0.000000 (3.461 sec/batch), lr: 0.000100
2021-07-13 04:31:50.178342: step 34540/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000336, rela_loss = 0.000011, bind_loss = 0.000000 (1.305 sec/batch), lr: 0.000100
2021-07-13 04:32:21.716429: step 34560/164800 (epoch 17/80),jp_loss = 0.000214, trig_loss = 0.000092, rela_loss = 0.000002, bind_loss = 0.000000 (1.775 sec/batch), lr: 0.000100
2021-07-13 04:32:48.661516: step 34580/164800 (epoch 17/80),jp_loss = 0.000023, trig_loss = 0.000046, rela_loss = 0.000083, bind_loss = 0.000000 (0.500 sec/batch), lr: 0.000100
2021-07-13 04:33:27.392461: step 34600/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000275, rela_loss = 0.000006, bind_loss = 0.000000 (1.901 sec/batch), lr: 0.000100
2021-07-13 04:34:00.407710: step 34620/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000015, bind_loss = 0.000000 (1.345 sec/batch), lr: 0.000100
2021-07-13 04:34:21.843055: step 34640/164800 (epoch 17/80),jp_loss = 0.000015, trig_loss = 0.000122, rela_loss = 0.000004, bind_loss = 0.000000 (0.867 sec/batch), lr: 0.000100
2021-07-13 04:34:50.143700: step 34660/164800 (epoch 17/80),jp_loss = 0.000153, trig_loss = 0.000153, rela_loss = 0.000006, bind_loss = 0.000000 (1.877 sec/batch), lr: 0.000100
2021-07-13 04:35:14.834636: step 34680/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.822 sec/batch), lr: 0.000100
2021-07-13 04:35:44.932644: step 34700/164800 (epoch 17/80),jp_loss = 0.000244, trig_loss = 0.001938, rela_loss = 0.000005, bind_loss = 0.000000 (2.659 sec/batch), lr: 0.000100
2021-07-13 04:36:13.854208: step 34720/164800 (epoch 17/80),jp_loss = 0.168518, trig_loss = 0.001770, rela_loss = 0.000088, bind_loss = 0.000000 (1.766 sec/batch), lr: 0.000100
2021-07-13 04:36:45.798711: step 34740/164800 (epoch 17/80),jp_loss = 0.000671, trig_loss = 0.000000, rela_loss = 0.000060, bind_loss = 0.000000 (1.752 sec/batch), lr: 0.000100
2021-07-13 04:37:27.586355: step 34760/164800 (epoch 17/80),jp_loss = 0.000244, trig_loss = 0.000137, rela_loss = 0.000009, bind_loss = 0.000135 (3.470 sec/batch), lr: 0.000100
2021-07-13 04:37:55.145493: step 34780/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000006, bind_loss = 0.000000 (0.950 sec/batch), lr: 0.000100
2021-07-13 04:38:26.432766: step 34800/164800 (epoch 17/80),jp_loss = 0.000580, trig_loss = 0.000183, rela_loss = 1.960495, bind_loss = 0.000000 (3.422 sec/batch), lr: 0.000100
2021-07-13 04:39:11.200150: step 34820/164800 (epoch 17/80),jp_loss = 0.000031, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (1.807 sec/batch), lr: 0.000100
2021-07-13 04:39:38.865055: step 34840/164800 (epoch 17/80),jp_loss = 0.000046, trig_loss = 0.000397, rela_loss = 0.000005, bind_loss = 0.000000 (2.114 sec/batch), lr: 0.000100
2021-07-13 04:40:27.301575: step 34860/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 5.489014, rela_loss = 0.000001, bind_loss = 0.000000 (0.874 sec/batch), lr: 0.000100
2021-07-13 04:40:55.398475: step 34880/164800 (epoch 17/80),jp_loss = 0.001038, trig_loss = 0.011841, rela_loss = 0.000016, bind_loss = 0.000000 (3.942 sec/batch), lr: 0.000100
2021-07-13 04:41:28.242853: step 34900/164800 (epoch 17/80),jp_loss = 0.000076, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (0.865 sec/batch), lr: 0.000100
2021-07-13 04:41:58.610655: step 34920/164800 (epoch 17/80),jp_loss = 0.000122, trig_loss = 0.039551, rela_loss = 0.000000, bind_loss = 0.000021 (4.056 sec/batch), lr: 0.000100
2021-07-13 04:42:25.470498: step 34940/164800 (epoch 17/80),jp_loss = 0.000153, trig_loss = 0.000031, rela_loss = 0.000022, bind_loss = 0.000000 (0.925 sec/batch), lr: 0.000100
2021-07-13 04:42:58.156482: step 34960/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000397, rela_loss = 0.000000, bind_loss = 0.000000 (1.692 sec/batch), lr: 0.000100
2021-07-13 04:43:26.711911: step 34980/164800 (epoch 17/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.272 sec/batch), lr: 0.000100
2021-07-13 04:43:57.733237: step 35000/164800 (epoch 17/80),jp_loss = 0.000061, trig_loss = 0.000198, rela_loss = 0.000002, bind_loss = 0.000005 (1.508 sec/batch), lr: 0.000100
2021-07-13 04:44:29.418436: step 35020/164800 (epoch 17/80),jp_loss = 0.000427, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (1.558 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.91%  R:  99.54%  F1:  99.72%  #: 2174

Final Score:
Precision (micro): 99.908%
   Recall (micro): 99.540%
       F1 (micro): 99.724%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  99.66%  R:  99.66%  F1:  99.66%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  98.68%  R:  98.46%  F1:  98.57%  #: 455
Localization         P:  98.34%  R: 100.00%  F1:  99.16%  #: 178
Negative_regulation  P:  99.29%  R:  99.05%  F1:  99.17%  #: 421
Phosphorylation      P:  98.06%  R:  98.06%  F1:  98.06%  #: 155
Positive_regulation  P:  99.68%  R:  98.56%  F1:  99.12%  #: 627
Protein_catabolism   P:  96.55%  R:  93.33%  F1:  94.92%  #: 30
Regulation           P:  99.51%  R:  98.54%  F1:  99.02%  #: 206
Transcription        P:  98.51%  R:  98.51%  F1:  98.51%  #: 67

Final Score:
Precision (micro): 99.135%
   Recall (micro): 98.566%
       F1 (micro): 98.850%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  99.38%  R:  98.16%  F1:  98.76%  #: 488
Gene_expression      P:  98.45%  R:  98.62%  F1:  98.54%  #: 581
Localization         P:  95.90%  R:  97.40%  F1:  96.64%  #: 192
Negative_regulation  P:  97.55%  R:  97.40%  F1:  97.48%  #: 655
Phosphorylation      P:  97.47%  R:  97.97%  F1:  97.72%  #: 197
Positive_regulation  P:  97.47%  R:  96.10%  F1:  96.78%  #: 923
Protein_catabolism   P:  96.55%  R:  93.33%  F1:  94.92%  #: 30
Regulation           P:  97.54%  R:  97.20%  F1:  97.37%  #: 286
Transcription        P:  96.59%  R:  95.51%  F1:  96.05%  #: 89

Final Score:
Precision (micro): 97.809%
   Recall (micro): 97.297%
       F1 (micro): 97.552%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  95.14%  R:  98.32%  F1:  96.70%  #: 179

Final Score:
Precision (micro): 95.135%
   Recall (micro): 98.324%
       F1 (micro): 96.703%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  95.70%  R:  94.62%  F1:  95.16%  #: 353

Gene_expression      P:  98.79%  R:  98.62%  F1:  98.71%  #: 581

Localization         P:  95.90%  R:  97.40%  F1:  96.64%  #: 192

Negative_regulation  P:  96.74%  R:  79.96%  F1:  87.55%  #: 519

Phosphorylation      P:  90.86%  R:  88.48%  F1:  89.66%  #: 191

Positive_regulation  P:  90.70%  R:  75.59%  F1:  82.46%  #: 852

Protein_catabolism   P:  96.55%  R:  93.33%  F1:  94.92%  #: 30

Regulation           P:  97.63%  R:  76.58%  F1:  85.83%  #: 269

Transcription        P:  96.59%  R:  95.51%  F1:  96.05%  #: 89

Final Score:
Precision (micro): 95.103%
   Recall (micro): 85.858%
       F1 (micro): 90.244%
epoch 17: train_loss = 0.085609, dev_loss = 0.000000, dev_rela_f1 = 0.9024
0.9116799457535176 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_17.pt

2021-07-13 04:56:22.616266: step 35040/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 1.161896, rela_loss = 0.000000, bind_loss = 0.000000 (2.083 sec/batch), lr: 0.000100
2021-07-13 04:56:59.271042: step 35060/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 2.524323, rela_loss = 0.002454, bind_loss = 0.000000 (1.139 sec/batch), lr: 0.000100
2021-07-13 04:57:45.343053: step 35080/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.982 sec/batch), lr: 0.000100
2021-07-13 04:58:15.322842: step 35100/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000458, rela_loss = 0.000000, bind_loss = 0.000000 (0.770 sec/batch), lr: 0.000100
2021-07-13 04:58:57.836194: step 35120/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.795 sec/batch), lr: 0.000100
2021-07-13 04:59:32.032218: step 35140/164800 (epoch 18/80),jp_loss = 0.004669, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (1.676 sec/batch), lr: 0.000100
2021-07-13 05:00:11.892628: step 35160/164800 (epoch 18/80),jp_loss = 0.000023, trig_loss = 0.000015, rela_loss = 0.000000, bind_loss = 0.000002 (0.638 sec/batch), lr: 0.000100
2021-07-13 05:00:40.647462: step 35180/164800 (epoch 18/80),jp_loss = 0.000015, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (0.932 sec/batch), lr: 0.000100
2021-07-13 05:01:19.642876: step 35200/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 18.124634, rela_loss = 0.000007, bind_loss = 0.000000 (1.317 sec/batch), lr: 0.000100
2021-07-13 05:01:46.983272: step 35220/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000626, rela_loss = 0.000000, bind_loss = 0.000000 (1.769 sec/batch), lr: 0.000100
2021-07-13 05:02:18.815440: step 35240/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000763, rela_loss = 0.000001, bind_loss = 0.000000 (0.819 sec/batch), lr: 0.000100
2021-07-13 05:03:00.642184: step 35260/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.875 sec/batch), lr: 0.000100
2021-07-13 05:03:31.823440: step 35280/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.440 sec/batch), lr: 0.000100
2021-07-13 05:04:09.848602: step 35300/164800 (epoch 18/80),jp_loss = 0.000076, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.476 sec/batch), lr: 0.000100
2021-07-13 05:04:46.694282: step 35320/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000003, bind_loss = 0.000000 (0.619 sec/batch), lr: 0.000100
2021-07-13 05:05:20.111168: step 35340/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000977, rela_loss = 0.000026, bind_loss = 0.000000 (1.084 sec/batch), lr: 0.000100
2021-07-13 05:05:55.749895: step 35360/164800 (epoch 18/80),jp_loss = 0.000046, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.796 sec/batch), lr: 0.000100
2021-07-13 05:06:33.185922: step 35380/164800 (epoch 18/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.795 sec/batch), lr: 0.000100
2021-07-13 05:06:57.040587: step 35400/164800 (epoch 18/80),jp_loss = 0.000488, trig_loss = 0.000275, rela_loss = 0.000004, bind_loss = 0.000014 (1.973 sec/batch), lr: 0.000100
2021-07-13 05:07:22.758844: step 35420/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000185, bind_loss = 0.000000 (0.803 sec/batch), lr: 0.000100
2021-07-13 05:08:06.405161: step 35440/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (2.692 sec/batch), lr: 0.000100
2021-07-13 05:08:37.378890: step 35460/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.056 sec/batch), lr: 0.000100
2021-07-13 05:09:04.677479: step 35480/164800 (epoch 18/80),jp_loss = 0.000298, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000001 (1.243 sec/batch), lr: 0.000100
2021-07-13 05:09:58.836292: step 35500/164800 (epoch 18/80),jp_loss = 0.000671, trig_loss = 0.023926, rela_loss = 0.000235, bind_loss = 0.000000 (6.994 sec/batch), lr: 0.000100
2021-07-13 05:10:26.048174: step 35520/164800 (epoch 18/80),jp_loss = 0.000107, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.673 sec/batch), lr: 0.000100
2021-07-13 05:10:57.679070: step 35540/164800 (epoch 18/80),jp_loss = 0.000397, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.895 sec/batch), lr: 0.000100
2021-07-13 05:11:37.105140: step 35560/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.809 sec/batch), lr: 0.000100
2021-07-13 05:12:17.824665: step 35580/164800 (epoch 18/80),jp_loss = 0.000458, trig_loss = 0.000427, rela_loss = 0.000024, bind_loss = 0.000000 (3.781 sec/batch), lr: 0.000100
2021-07-13 05:12:59.524460: step 35600/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.003021, rela_loss = 0.000021, bind_loss = 0.000000 (1.780 sec/batch), lr: 0.000100
2021-07-13 05:13:27.013541: step 35620/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000019, bind_loss = 0.000000 (1.701 sec/batch), lr: 0.000100
2021-07-13 05:13:55.209917: step 35640/164800 (epoch 18/80),jp_loss = 0.000214, trig_loss = 0.009674, rela_loss = 0.000000, bind_loss = 0.000008 (2.075 sec/batch), lr: 0.000100
2021-07-13 05:14:31.431978: step 35660/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (1.542 sec/batch), lr: 0.000100
2021-07-13 05:14:57.196966: step 35680/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000003, bind_loss = 0.000000 (0.640 sec/batch), lr: 0.000100
2021-07-13 05:15:25.833911: step 35700/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.210 sec/batch), lr: 0.000100
2021-07-13 05:15:54.365242: step 35720/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000702, rela_loss = 0.000820, bind_loss = 0.000000 (1.182 sec/batch), lr: 0.000100
2021-07-13 05:16:26.326617: step 35740/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (0.903 sec/batch), lr: 0.000100
2021-07-13 05:16:55.361627: step 35760/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.469 sec/batch), lr: 0.000100
2021-07-13 05:17:33.020691: step 35780/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000001, bind_loss = 0.000000 (0.934 sec/batch), lr: 0.000100
2021-07-13 05:18:10.843120: step 35800/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000046, rela_loss = 0.000000, bind_loss = 0.000000 (0.317 sec/batch), lr: 0.000100
2021-07-13 05:18:58.410588: step 35820/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.132 sec/batch), lr: 0.000100
2021-07-13 05:19:29.694168: step 35840/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.000275, rela_loss = 0.000001, bind_loss = 0.000000 (1.801 sec/batch), lr: 0.000100
2021-07-13 05:20:06.789357: step 35860/164800 (epoch 18/80),jp_loss = 0.000336, trig_loss = 0.000549, rela_loss = 0.000001, bind_loss = 0.005740 (4.849 sec/batch), lr: 0.000100
2021-07-13 05:20:36.452615: step 35880/164800 (epoch 18/80),jp_loss = 0.000275, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.106 sec/batch), lr: 0.000100
2021-07-13 05:21:08.115769: step 35900/164800 (epoch 18/80),jp_loss = 0.000153, trig_loss = 0.002014, rela_loss = 0.000000, bind_loss = 0.000000 (2.953 sec/batch), lr: 0.000100
2021-07-13 05:21:35.808958: step 35920/164800 (epoch 18/80),jp_loss = 0.000053, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.504 sec/batch), lr: 0.000100
2021-07-13 05:22:10.400103: step 35940/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.000004, bind_loss = 0.000000 (0.807 sec/batch), lr: 0.000100
2021-07-13 05:22:49.855063: step 35960/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (0.852 sec/batch), lr: 0.000100
2021-07-13 05:23:23.894431: step 35980/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 3.993921, bind_loss = 0.000000 (2.145 sec/batch), lr: 0.000100
2021-07-13 05:23:58.046619: step 36000/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.005554, rela_loss = 0.000000, bind_loss = 0.000000 (0.593 sec/batch), lr: 0.000100
2021-07-13 05:24:38.857733: step 36020/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.003632, rela_loss = 0.000000, bind_loss = 0.000000 (1.021 sec/batch), lr: 0.000100
2021-07-13 05:25:12.959880: step 36040/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000305, rela_loss = 0.000003, bind_loss = 0.000000 (2.374 sec/batch), lr: 0.000100
2021-07-13 05:25:45.811957: step 36060/164800 (epoch 18/80),jp_loss = 0.000641, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.349 sec/batch), lr: 0.000100
2021-07-13 05:26:12.836967: step 36080/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (0.911 sec/batch), lr: 0.000100
2021-07-13 05:26:46.934827: step 36100/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.001587, rela_loss = 0.000000, bind_loss = 0.000000 (1.455 sec/batch), lr: 0.000100
2021-07-13 05:27:11.841927: step 36120/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000012 (1.678 sec/batch), lr: 0.000100
2021-07-13 05:27:51.836334: step 36140/164800 (epoch 18/80),jp_loss = 0.000038, trig_loss = 0.000031, rela_loss = 0.000026, bind_loss = 0.000000 (1.215 sec/batch), lr: 0.000100
2021-07-13 05:28:28.372041: step 36160/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000002, bind_loss = 0.000000 (0.914 sec/batch), lr: 0.000100
2021-07-13 05:29:00.369462: step 36180/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000015, rela_loss = 0.000003, bind_loss = 0.000335 (0.815 sec/batch), lr: 0.000100
2021-07-13 05:29:28.331369: step 36200/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000009 (1.764 sec/batch), lr: 0.000100
2021-07-13 05:29:56.290471: step 36220/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000007, bind_loss = 0.000000 (0.511 sec/batch), lr: 0.000100
2021-07-13 05:30:26.369296: step 36240/164800 (epoch 18/80),jp_loss = 0.000153, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.001021 (3.077 sec/batch), lr: 0.000100
2021-07-13 05:31:05.306808: step 36260/164800 (epoch 18/80),jp_loss = 0.000153, trig_loss = 0.003113, rela_loss = 0.000002, bind_loss = 0.000000 (3.047 sec/batch), lr: 0.000100
2021-07-13 05:31:36.873559: step 36280/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000275, rela_loss = 0.000001, bind_loss = 0.000000 (1.573 sec/batch), lr: 0.000100
2021-07-13 05:32:13.796933: step 36300/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000011, bind_loss = 0.000009 (1.994 sec/batch), lr: 0.000100
2021-07-13 05:32:44.372662: step 36320/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.000153, rela_loss = 0.000002, bind_loss = 0.000000 (1.395 sec/batch), lr: 0.000100
2021-07-13 05:33:27.936103: step 36340/164800 (epoch 18/80),jp_loss = 0.000671, trig_loss = 0.708252, rela_loss = 0.000002, bind_loss = 0.000000 (3.173 sec/batch), lr: 0.000100
2021-07-13 05:33:54.482479: step 36360/164800 (epoch 18/80),jp_loss = 0.000076, trig_loss = 0.000275, rela_loss = 0.000007, bind_loss = 0.000000 (1.326 sec/batch), lr: 0.000100
2021-07-13 05:34:26.980659: step 36380/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000427, rela_loss = 0.000000, bind_loss = 0.000000 (0.888 sec/batch), lr: 0.000100
2021-07-13 05:35:09.162893: step 36400/164800 (epoch 18/80),jp_loss = 0.000458, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000014 (1.889 sec/batch), lr: 0.000100
2021-07-13 05:35:49.812535: step 36420/164800 (epoch 18/80),jp_loss = 0.000092, trig_loss = 0.000244, rela_loss = 0.000001, bind_loss = 0.000000 (1.356 sec/batch), lr: 0.000100
2021-07-13 05:36:18.926347: step 36440/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.005219, rela_loss = 0.000146, bind_loss = 0.000000 (1.142 sec/batch), lr: 0.000100
2021-07-13 05:36:46.710301: step 36460/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.586 sec/batch), lr: 0.000100
2021-07-13 05:37:12.998481: step 36480/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000183, rela_loss = 0.000014, bind_loss = 0.000009 (2.072 sec/batch), lr: 0.000100
2021-07-13 05:37:45.511558: step 36500/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000002, bind_loss = 0.000000 (2.620 sec/batch), lr: 0.000100
2021-07-13 05:38:15.695550: step 36520/164800 (epoch 18/80),jp_loss = 0.000046, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.903 sec/batch), lr: 0.000100
2021-07-13 05:38:53.398083: step 36540/164800 (epoch 18/80),jp_loss = 0.000797, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.026 sec/batch), lr: 0.000100
2021-07-13 05:39:15.651755: step 36560/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.002869, rela_loss = 0.000020, bind_loss = 0.000000 (1.877 sec/batch), lr: 0.000100
2021-07-13 05:40:00.903187: step 36580/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.213283, bind_loss = 0.000000 (3.096 sec/batch), lr: 0.000100
2021-07-13 05:40:28.501669: step 36600/164800 (epoch 18/80),jp_loss = 0.000046, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (1.530 sec/batch), lr: 0.000100
2021-07-13 05:41:00.420090: step 36620/164800 (epoch 18/80),jp_loss = 0.000046, trig_loss = 0.000031, rela_loss = 0.000013, bind_loss = 0.000000 (1.985 sec/batch), lr: 0.000100
2021-07-13 05:41:27.286152: step 36640/164800 (epoch 18/80),jp_loss = 0.025345, trig_loss = 0.000053, rela_loss = 0.000000, bind_loss = 0.000000 (0.503 sec/batch), lr: 0.000100
2021-07-13 05:42:08.562804: step 36660/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (2.077 sec/batch), lr: 0.000100
2021-07-13 05:42:42.943309: step 36680/164800 (epoch 18/80),jp_loss = 0.000671, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.434 sec/batch), lr: 0.000100
2021-07-13 05:43:05.085047: step 36700/164800 (epoch 18/80),jp_loss = 0.000015, trig_loss = 0.000626, rela_loss = 0.000006, bind_loss = 0.000000 (0.879 sec/batch), lr: 0.000100
2021-07-13 05:43:33.545131: step 36720/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000458, rela_loss = 0.000000, bind_loss = 0.000000 (1.862 sec/batch), lr: 0.000100
2021-07-13 05:44:00.440137: step 36740/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000031, rela_loss = 0.000049, bind_loss = 0.000000 (0.827 sec/batch), lr: 0.000100
2021-07-13 05:44:31.754170: step 36760/164800 (epoch 18/80),jp_loss = 0.000137, trig_loss = 0.000488, rela_loss = 0.000062, bind_loss = 0.000000 (2.694 sec/batch), lr: 0.000100
2021-07-13 05:45:01.781048: step 36780/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000010, bind_loss = 0.000000 (2.078 sec/batch), lr: 0.000100
2021-07-13 05:45:34.818878: step 36800/164800 (epoch 18/80),jp_loss = 0.000305, trig_loss = 0.000000, rela_loss = 0.060363, bind_loss = 0.000000 (1.877 sec/batch), lr: 0.000100
2021-07-13 05:46:17.831274: step 36820/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000076, rela_loss = 0.000487, bind_loss = 0.000017 (3.391 sec/batch), lr: 0.000100
2021-07-13 05:46:47.413056: step 36840/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.862 sec/batch), lr: 0.000100
2021-07-13 05:47:18.665395: step 36860/164800 (epoch 18/80),jp_loss = 0.002350, trig_loss = 0.000305, rela_loss = 0.000207, bind_loss = 0.000000 (3.539 sec/batch), lr: 0.000100
2021-07-13 05:48:04.975548: step 36880/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000025, bind_loss = 0.000000 (1.780 sec/batch), lr: 0.000100
2021-07-13 05:48:32.554991: step 36900/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.003006, rela_loss = 0.000034, bind_loss = 0.000000 (1.874 sec/batch), lr: 0.000100
2021-07-13 05:49:20.161792: step 36920/164800 (epoch 18/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000011, bind_loss = 0.000000 (0.645 sec/batch), lr: 0.000100
2021-07-13 05:49:47.377422: step 36940/164800 (epoch 18/80),jp_loss = 0.000183, trig_loss = 0.002197, rela_loss = 0.000001, bind_loss = 0.000000 (3.868 sec/batch), lr: 0.000100
2021-07-13 05:50:19.389966: step 36960/164800 (epoch 18/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000002, bind_loss = 0.000000 (0.795 sec/batch), lr: 0.000100
2021-07-13 05:50:50.904460: step 36980/164800 (epoch 18/80),jp_loss = 0.000214, trig_loss = 0.164948, rela_loss = 0.000000, bind_loss = 0.000015 (4.508 sec/batch), lr: 0.000100
2021-07-13 05:51:17.491141: step 37000/164800 (epoch 18/80),jp_loss = 0.000076, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.975 sec/batch), lr: 0.000100
2021-07-13 05:51:50.282874: step 37020/164800 (epoch 18/80),jp_loss = 0.000107, trig_loss = 0.000153, rela_loss = 0.000001, bind_loss = 0.000000 (2.407 sec/batch), lr: 0.000100
2021-07-13 05:52:18.729643: step 37040/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.194 sec/batch), lr: 0.000100
2021-07-13 05:52:50.524469: step 37060/164800 (epoch 18/80),jp_loss = 0.000122, trig_loss = 0.000031, rela_loss = 0.000006, bind_loss = 0.000016 (1.549 sec/batch), lr: 0.000100
2021-07-13 05:53:21.723059: step 37080/164800 (epoch 18/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (1.443 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.72%  R:  99.68%  F1:  99.70%  #: 2174

Final Score:
Precision (micro): 99.724%
   Recall (micro): 99.678%
       F1 (micro): 99.701%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  99.66%  R:  99.66%  F1:  99.66%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  98.04%  R:  99.12%  F1:  98.58%  #: 455
Localization         P:  99.44%  R: 100.00%  F1:  99.72%  #: 178
Negative_regulation  P:  99.52%  R:  99.05%  F1:  99.29%  #: 421
Phosphorylation      P:  99.35%  R:  98.71%  F1:  99.03%  #: 155
Positive_regulation  P:  99.35%  R:  97.61%  F1:  98.47%  #: 627
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P: 100.00%  R:  98.54%  F1:  99.27%  #: 206
Transcription        P:  89.19%  R:  98.51%  F1:  93.62%  #: 67

Final Score:
Precision (micro): 98.849%
   Recall (micro): 98.525%
       F1 (micro): 98.687%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  99.18%  R:  99.39%  F1:  99.28%  #: 488
Gene_expression      P:  97.96%  R:  98.80%  F1:  98.38%  #: 583
Localization         P:  97.38%  R:  96.88%  F1:  97.13%  #: 192
Negative_regulation  P:  98.45%  R:  96.95%  F1:  97.69%  #: 655
Phosphorylation      P:  98.98%  R:  98.48%  F1:  98.73%  #: 197
Positive_regulation  P:  97.59%  R:  96.64%  F1:  97.11%  #: 923
Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30
Regulation           P:  98.21%  R:  95.80%  F1:  96.99%  #: 286
Transcription        P:  90.32%  R:  94.38%  F1:  92.31%  #: 89

Final Score:
Precision (micro): 97.928%
   Recall (micro): 97.444%
       F1 (micro): 97.685%
#############----bind论元情况评估----####################################
binding statistics:
bind  P: 100.00%  R:  98.34%  F1:  99.16%  #: 181

Final Score:
Precision (micro): 100.000%
   Recall (micro): 98.343%
       F1 (micro): 99.164%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  98.30%  R:  98.02%  F1:  98.16%  #: 353

Gene_expression      P:  98.13%  R:  98.80%  F1:  98.46%  #: 583

Localization         P:  97.38%  R:  96.88%  F1:  97.13%  #: 192

Negative_regulation  P:  97.62%  R:  79.19%  F1:  87.45%  #: 519

Phosphorylation      P:  92.39%  R:  89.01%  F1:  90.67%  #: 191

Positive_regulation  P:  97.04%  R:  80.75%  F1:  88.15%  #: 852

Protein_catabolism   P:  93.55%  R:  96.67%  F1:  95.08%  #: 30

Regulation           P:  95.79%  R:  76.21%  F1:  84.89%  #: 269

Transcription        P:  90.32%  R:  94.38%  F1:  92.31%  #: 89

Final Score:
Precision (micro): 96.873%
   Recall (micro): 87.557%
       F1 (micro): 91.980%
epoch 18: train_loss = 0.042566, dev_loss = 0.000000, dev_rela_f1 = 0.9198
0.9197952218430034 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_18.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.9197952218430034 ---- 18

2021-07-13 06:06:24.158437: step 37100/164800 (epoch 19/80),jp_loss = 0.000092, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (1.918 sec/batch), lr: 0.000100
2021-07-13 06:06:55.116578: step 37120/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 1.162170, rela_loss = 0.000000, bind_loss = 0.000000 (0.947 sec/batch), lr: 0.000100
2021-07-13 06:07:33.635376: step 37140/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000006, bind_loss = 0.000000 (0.781 sec/batch), lr: 0.000100
2021-07-13 06:07:59.181917: step 37160/164800 (epoch 19/80),jp_loss = 0.070251, trig_loss = 11.815918, rela_loss = 0.000000, bind_loss = 0.000000 (0.735 sec/batch), lr: 0.000100
2021-07-13 06:08:42.233721: step 37180/164800 (epoch 19/80),jp_loss = 0.000015, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.953 sec/batch), lr: 0.000100
2021-07-13 06:09:17.413576: step 37200/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.611 sec/batch), lr: 0.000100
2021-07-13 06:09:56.641710: step 37220/164800 (epoch 19/80),jp_loss = 0.000038, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.708 sec/batch), lr: 0.000100
2021-07-13 06:10:26.019315: step 37240/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.953 sec/batch), lr: 0.000100
2021-07-13 06:11:04.226954: step 37260/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.002686, bind_loss = 0.000000 (1.602 sec/batch), lr: 0.000100
2021-07-13 06:11:32.360722: step 37280/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000443, rela_loss = 0.000000, bind_loss = 0.000000 (1.634 sec/batch), lr: 0.000100
2021-07-13 06:12:04.461984: step 37300/164800 (epoch 19/80),jp_loss = 0.000076, trig_loss = 0.002457, rela_loss = 0.000004, bind_loss = 0.000000 (0.773 sec/batch), lr: 0.000100
2021-07-13 06:12:47.044455: step 37320/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.891 sec/batch), lr: 0.000100
2021-07-13 06:13:17.652732: step 37340/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.276 sec/batch), lr: 0.000100
2021-07-13 06:13:56.344890: step 37360/164800 (epoch 19/80),jp_loss = 0.000038, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.449 sec/batch), lr: 0.000100
2021-07-13 06:14:33.871978: step 37380/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.616 sec/batch), lr: 0.000100
2021-07-13 06:15:07.114674: step 37400/164800 (epoch 19/80),jp_loss = 0.000153, trig_loss = 0.000488, rela_loss = 0.000013, bind_loss = 0.000000 (1.155 sec/batch), lr: 0.000100
2021-07-13 06:15:43.947954: step 37420/164800 (epoch 19/80),jp_loss = 0.000076, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (0.740 sec/batch), lr: 0.000100
2021-07-13 06:16:20.686190: step 37440/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.908 sec/batch), lr: 0.000100
2021-07-13 06:16:46.129256: step 37460/164800 (epoch 19/80),jp_loss = 0.000229, trig_loss = 0.001099, rela_loss = 0.000015, bind_loss = 0.000005 (1.926 sec/batch), lr: 0.000100
2021-07-13 06:17:11.923287: step 37480/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (0.984 sec/batch), lr: 0.000100
2021-07-13 06:17:55.778208: step 37500/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.067566, rela_loss = 0.000025, bind_loss = 0.000000 (2.562 sec/batch), lr: 0.000100
2021-07-13 06:18:26.503092: step 37520/164800 (epoch 19/80),jp_loss = 0.000122, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (1.068 sec/batch), lr: 0.000100
2021-07-13 06:18:54.091864: step 37540/164800 (epoch 19/80),jp_loss = 0.002190, trig_loss = 0.000153, rela_loss = 0.175364, bind_loss = 0.000000 (1.239 sec/batch), lr: 0.000100
2021-07-13 06:19:46.869366: step 37560/164800 (epoch 19/80),jp_loss = 0.000122, trig_loss = 1.790039, rela_loss = 0.000036, bind_loss = 0.000000 (6.680 sec/batch), lr: 0.000100
2021-07-13 06:20:14.000191: step 37580/164800 (epoch 19/80),jp_loss = 0.000015, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.184 sec/batch), lr: 0.000100
2021-07-13 06:20:45.585511: step 37600/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.867 sec/batch), lr: 0.000100
2021-07-13 06:21:28.065376: step 37620/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.046 sec/batch), lr: 0.000100
2021-07-13 06:22:08.312435: step 37640/164800 (epoch 19/80),jp_loss = 0.000092, trig_loss = 1.331512, rela_loss = 0.000008, bind_loss = 0.000000 (3.673 sec/batch), lr: 0.000100
2021-07-13 06:22:50.589331: step 37660/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.007538, rela_loss = 0.000001, bind_loss = 0.000000 (1.777 sec/batch), lr: 0.000100
2021-07-13 06:23:18.724077: step 37680/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000017, bind_loss = 0.000000 (1.708 sec/batch), lr: 0.000100
2021-07-13 06:23:48.483836: step 37700/164800 (epoch 19/80),jp_loss = 0.000565, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000006 (2.361 sec/batch), lr: 0.000100
2021-07-13 06:24:26.242159: step 37720/164800 (epoch 19/80),jp_loss = 0.000046, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (1.894 sec/batch), lr: 0.000100
2021-07-13 06:24:53.767942: step 37740/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.001953, rela_loss = 0.000001, bind_loss = 0.000000 (0.628 sec/batch), lr: 0.000100
2021-07-13 06:25:22.031432: step 37760/164800 (epoch 19/80),jp_loss = 0.000046, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.331 sec/batch), lr: 0.000100
2021-07-13 06:25:51.729474: step 37780/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000916, rela_loss = 0.000000, bind_loss = 0.000000 (1.237 sec/batch), lr: 0.000100
2021-07-13 06:26:23.590977: step 37800/164800 (epoch 19/80),jp_loss = 0.000015, trig_loss = 0.000076, rela_loss = 0.000000, bind_loss = 0.000000 (0.772 sec/batch), lr: 0.000100
2021-07-13 06:26:53.546881: step 37820/164800 (epoch 19/80),jp_loss = 0.000244, trig_loss = 0.000305, rela_loss = 0.000000, bind_loss = 0.000000 (1.581 sec/batch), lr: 0.000100
2021-07-13 06:27:30.975351: step 37840/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (0.950 sec/batch), lr: 0.000100
2021-07-13 06:28:08.199643: step 37860/164800 (epoch 19/80),jp_loss = 0.000008, trig_loss = 0.000038, rela_loss = 0.000000, bind_loss = 0.000000 (0.468 sec/batch), lr: 0.000100
2021-07-13 06:28:55.398467: step 37880/164800 (epoch 19/80),jp_loss = 0.000015, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.145 sec/batch), lr: 0.000100
2021-07-13 06:29:27.267741: step 37900/164800 (epoch 19/80),jp_loss = 0.000259, trig_loss = 0.000275, rela_loss = 0.000943, bind_loss = 0.000000 (1.722 sec/batch), lr: 0.000100
2021-07-13 06:30:04.617297: step 37920/164800 (epoch 19/80),jp_loss = 0.000427, trig_loss = 0.000580, rela_loss = 0.000009, bind_loss = 0.002774 (5.087 sec/batch), lr: 0.000100
2021-07-13 06:30:33.491120: step 37940/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.077 sec/batch), lr: 0.000100
2021-07-13 06:31:04.787808: step 37960/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000305, rela_loss = 0.000004, bind_loss = 0.000000 (3.212 sec/batch), lr: 0.000100
2021-07-13 06:31:32.260853: step 37980/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000595, rela_loss = 0.000000, bind_loss = 0.000000 (0.545 sec/batch), lr: 0.000100
2021-07-13 06:32:06.582367: step 38000/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (0.989 sec/batch), lr: 0.000100
2021-07-13 06:32:44.370996: step 38020/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000183, rela_loss = 0.000397, bind_loss = 0.000000 (0.749 sec/batch), lr: 0.000100
2021-07-13 06:33:17.138624: step 38040/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000038, bind_loss = 0.000000 (2.500 sec/batch), lr: 0.000100
2021-07-13 06:33:49.893009: step 38060/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 2.172791, rela_loss = 0.000104, bind_loss = 0.000000 (0.706 sec/batch), lr: 0.000100
2021-07-13 06:34:30.736061: step 38080/164800 (epoch 19/80),jp_loss = 0.001770, trig_loss = 0.000275, rela_loss = 0.000012, bind_loss = 0.000000 (1.194 sec/batch), lr: 0.000100
2021-07-13 06:35:04.922906: step 38100/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000946, rela_loss = 0.000898, bind_loss = 0.000000 (2.282 sec/batch), lr: 0.000100
2021-07-13 06:35:36.566016: step 38120/164800 (epoch 19/80),jp_loss = 0.000183, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.288 sec/batch), lr: 0.000100
2021-07-13 06:36:02.606554: step 38140/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (0.824 sec/batch), lr: 0.000100
2021-07-13 06:36:35.580308: step 38160/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.200 sec/batch), lr: 0.000100
2021-07-13 06:37:01.073145: step 38180/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000099 (1.712 sec/batch), lr: 0.000100
2021-07-13 06:37:40.646612: step 38200/164800 (epoch 19/80),jp_loss = 0.000038, trig_loss = 0.000046, rela_loss = 0.000066, bind_loss = 0.000000 (1.163 sec/batch), lr: 0.000100
2021-07-13 06:38:17.333736: step 38220/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (0.602 sec/batch), lr: 0.000100
2021-07-13 06:38:50.116625: step 38240/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000002, bind_loss = 0.000012 (0.677 sec/batch), lr: 0.000100
2021-07-13 06:39:18.426084: step 38260/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000005, bind_loss = 0.000003 (1.928 sec/batch), lr: 0.000100
2021-07-13 06:39:46.446092: step 38280/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000000 (0.511 sec/batch), lr: 0.000100
2021-07-13 06:40:16.845740: step 38300/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000005, bind_loss = 0.004069 (3.357 sec/batch), lr: 0.000100
2021-07-13 06:40:56.774330: step 38320/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000214, rela_loss = 0.000000, bind_loss = 0.000000 (3.142 sec/batch), lr: 0.000100
2021-07-13 06:41:28.138146: step 38340/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 7.827301, rela_loss = 0.000002, bind_loss = 0.000000 (1.422 sec/batch), lr: 0.000100
2021-07-13 06:42:05.192826: step 38360/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000014 (1.878 sec/batch), lr: 0.000100
2021-07-13 06:42:34.571164: step 38380/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000003, bind_loss = 0.000000 (1.255 sec/batch), lr: 0.000100
2021-07-13 06:43:19.360358: step 38400/164800 (epoch 19/80),jp_loss = 0.000198, trig_loss = 0.000366, rela_loss = 0.000002, bind_loss = 0.000000 (2.983 sec/batch), lr: 0.000100
2021-07-13 06:43:47.031053: step 38420/164800 (epoch 19/80),jp_loss = 0.000076, trig_loss = 10.737457, rela_loss = 0.000053, bind_loss = 0.000000 (1.330 sec/batch), lr: 0.000100
2021-07-13 06:44:21.103732: step 38440/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.913 sec/batch), lr: 0.000100
2021-07-13 06:45:04.315400: step 38460/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000122, rela_loss = 0.000003, bind_loss = 0.000285 (2.335 sec/batch), lr: 0.000100
2021-07-13 06:45:44.744778: step 38480/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000290, rela_loss = 0.000004, bind_loss = 0.000000 (1.358 sec/batch), lr: 0.000100
2021-07-13 06:46:14.511626: step 38500/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000381, rela_loss = 0.000106, bind_loss = 0.000000 (1.247 sec/batch), lr: 0.000100
2021-07-13 06:46:41.975475: step 38520/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (1.649 sec/batch), lr: 0.000100
2021-07-13 06:47:08.075707: step 38540/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000088, bind_loss = 0.000020 (1.813 sec/batch), lr: 0.000100
2021-07-13 06:47:40.277806: step 38560/164800 (epoch 19/80),jp_loss = 0.000305, trig_loss = 0.000122, rela_loss = 0.000003, bind_loss = 0.000000 (2.311 sec/batch), lr: 0.000100
2021-07-13 06:48:10.747968: step 38580/164800 (epoch 19/80),jp_loss = 0.000092, trig_loss = 0.000061, rela_loss = 0.000002, bind_loss = 0.000000 (0.745 sec/batch), lr: 0.000100
2021-07-13 06:48:48.575870: step 38600/164800 (epoch 19/80),jp_loss = 0.000076, trig_loss = 0.000008, rela_loss = 0.000004, bind_loss = 0.000000 (1.114 sec/batch), lr: 0.000100
2021-07-13 06:49:11.922883: step 38620/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.003357, rela_loss = 0.000008, bind_loss = 0.000000 (2.071 sec/batch), lr: 0.000100
2021-07-13 06:50:00.520794: step 38640/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000244, rela_loss = 0.021334, bind_loss = 0.000000 (3.391 sec/batch), lr: 0.000100
2021-07-13 06:50:28.365974: step 38660/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (1.452 sec/batch), lr: 0.000100
2021-07-13 06:51:01.403320: step 38680/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000153, rela_loss = 0.000586, bind_loss = 0.000000 (1.711 sec/batch), lr: 0.000100
2021-07-13 06:51:28.443795: step 38700/164800 (epoch 19/80),jp_loss = 0.000023, trig_loss = 0.000023, rela_loss = 0.000004, bind_loss = 0.000000 (0.541 sec/batch), lr: 0.000100
2021-07-13 06:52:09.195928: step 38720/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.002747, rela_loss = 0.000000, bind_loss = 0.000000 (2.099 sec/batch), lr: 0.000100
2021-07-13 06:52:43.535964: step 38740/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000002, bind_loss = 0.000000 (1.868 sec/batch), lr: 0.000100
2021-07-13 06:53:05.805914: step 38760/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000061, rela_loss = 0.000005, bind_loss = 0.000000 (1.005 sec/batch), lr: 0.000100
2021-07-13 06:53:33.668437: step 38780/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000183, rela_loss = 0.000000, bind_loss = 0.000000 (2.051 sec/batch), lr: 0.000100
2021-07-13 06:54:00.470357: step 38800/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000002, bind_loss = 0.000000 (0.625 sec/batch), lr: 0.000100
2021-07-13 06:54:31.423984: step 38820/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000885, rela_loss = 0.000000, bind_loss = 0.000000 (2.629 sec/batch), lr: 0.000100
2021-07-13 06:55:01.608079: step 38840/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000061, rela_loss = 0.000102, bind_loss = 0.000000 (1.956 sec/batch), lr: 0.000100
2021-07-13 06:55:34.125724: step 38860/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000122, rela_loss = 0.000001, bind_loss = 0.000000 (1.777 sec/batch), lr: 0.000100
2021-07-13 06:56:15.924350: step 38880/164800 (epoch 19/80),jp_loss = 0.000061, trig_loss = 0.000031, rela_loss = 0.000001, bind_loss = 0.000007 (3.337 sec/batch), lr: 0.000100
2021-07-13 06:56:45.068361: step 38900/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000000, bind_loss = 0.000000 (0.831 sec/batch), lr: 0.000100
2021-07-13 06:57:17.132125: step 38920/164800 (epoch 19/80),jp_loss = 24.576538, trig_loss = 0.000214, rela_loss = 0.000017, bind_loss = 0.000000 (3.558 sec/batch), lr: 0.000100
2021-07-13 06:58:04.555631: step 38940/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000122, rela_loss = 0.000000, bind_loss = 0.000000 (2.264 sec/batch), lr: 0.000100
2021-07-13 06:58:33.540187: step 38960/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000488, rela_loss = 0.000012, bind_loss = 0.000000 (2.078 sec/batch), lr: 0.000100
2021-07-13 06:59:21.795753: step 38980/164800 (epoch 19/80),jp_loss = 0.000244, trig_loss = 0.000000, rela_loss = 0.000107, bind_loss = 0.000000 (0.688 sec/batch), lr: 0.000100
2021-07-13 06:59:50.001312: step 39000/164800 (epoch 19/80),jp_loss = 0.000183, trig_loss = 0.000183, rela_loss = 0.000006, bind_loss = 0.000000 (4.000 sec/batch), lr: 0.000100
2021-07-13 07:00:23.511574: step 39020/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.775 sec/batch), lr: 0.000100
2021-07-13 07:00:54.837678: step 39040/164800 (epoch 19/80),jp_loss = 0.000153, trig_loss = 2.341492, rela_loss = 0.000000, bind_loss = 0.000024 (4.029 sec/batch), lr: 0.000100
2021-07-13 07:01:21.874828: step 39060/164800 (epoch 19/80),jp_loss = 0.000137, trig_loss = 0.000122, rela_loss = 0.000001, bind_loss = 0.000000 (1.004 sec/batch), lr: 0.000100
2021-07-13 07:01:54.404349: step 39080/164800 (epoch 19/80),jp_loss = 0.000015, trig_loss = 0.000366, rela_loss = 0.000000, bind_loss = 0.000000 (2.158 sec/batch), lr: 0.000100
2021-07-13 07:02:23.274347: step 39100/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.210 sec/batch), lr: 0.000100
2021-07-13 07:02:57.615887: step 39120/164800 (epoch 19/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.004543, bind_loss = 0.000019 (1.994 sec/batch), lr: 0.000100
2021-07-13 07:03:30.220368: step 39140/164800 (epoch 19/80),jp_loss = 0.000000, trig_loss = 0.000244, rela_loss = 0.000000, bind_loss = 0.000000 (2.026 sec/batch), lr: 0.000100
Evaluating on dev set...
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
Deacetylation
have a problem!!!!
############-----参与事件的protein的预测情况----#########################
Per-relation statistics:
Protein  P:  99.86%  R:  99.91%  F1:  99.89%  #: 2174

Final Score:
Precision (micro): 99.862%
   Recall (micro): 99.908%
       F1 (micro): 99.885%
############----trigger的预测情况----##################################
Per-relation statistics:
Acetylation          P: 100.00%  R:   0.00%  F1:   0.00%  #: 2
Binding              P:  99.66%  R:  99.66%  F1:  99.66%  #: 297
Deacetylation        P: 100.00%  R:   0.00%  F1:   0.00%  #: 3
Gene_expression      P:  97.63%  R:  99.56%  F1:  98.59%  #: 455
Localization         P: 100.00%  R: 100.00%  F1: 100.00%  #: 178
Negative_regulation  P:  99.76%  R:  99.29%  F1:  99.52%  #: 421
Phosphorylation      P:  98.09%  R:  99.35%  F1:  98.72%  #: 155
Positive_regulation  P:  99.52%  R:  98.41%  F1:  98.96%  #: 627
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  99.51%  R:  99.03%  F1:  99.27%  #: 206
Transcription        P: 100.00%  R:  98.51%  F1:  99.25%  #: 67

Final Score:
Precision (micro): 99.138%
   Recall (micro): 98.935%
       F1 (micro): 99.036%
#############----trigger 与 argument间----关系判断 ######################
Per-relation statistics:
Binding              P:  98.78%  R:  99.59%  F1:  99.18%  #: 488
Gene_expression      P:  97.30%  R:  98.97%  F1:  98.13%  #: 583
Localization         P:  97.91%  R:  97.40%  F1:  97.65%  #: 192
Negative_regulation  P:  99.07%  R:  98.02%  F1:  98.54%  #: 655
Phosphorylation      P:  98.48%  R:  98.98%  F1:  98.73%  #: 197
Positive_regulation  P:  97.72%  R:  97.51%  F1:  97.61%  #: 923
Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30
Regulation           P:  97.20%  R:  97.20%  F1:  97.20%  #: 286
Transcription        P:  97.73%  R:  97.73%  F1:  97.73%  #: 88

Final Score:
Precision (micro): 98.056%
   Recall (micro): 98.199%
       F1 (micro): 98.127%
#############----bind论元情况评估----####################################
binding statistics:
bind  P:  97.28%  R:  98.90%  F1:  98.08%  #: 181

Final Score:
Precision (micro): 97.283%
   Recall (micro): 98.895%
       F1 (micro): 98.082%
#############----组合事件情况评估----#####################################
Per-relation statistics:
Binding              P:  97.74%  R:  98.02%  F1:  97.88%  #: 353

Gene_expression      P:  97.47%  R:  98.97%  F1:  98.21%  #: 583

Localization         P:  97.91%  R:  97.40%  F1:  97.65%  #: 192

Negative_regulation  P:  97.65%  R:  80.15%  F1:  88.04%  #: 519

Phosphorylation      P:  91.94%  R:  89.53%  F1:  90.72%  #: 191

Positive_regulation  P:  97.36%  R:  82.16%  F1:  89.12%  #: 852

Protein_catabolism   P:  96.67%  R:  96.67%  F1:  96.67%  #: 30

Regulation           P:  95.43%  R:  77.70%  F1:  85.66%  #: 269

Transcription        P:  97.73%  R:  97.73%  F1:  97.73%  #: 88

Final Score:
Precision (micro): 97.005%
   Recall (micro): 88.430%
       F1 (micro): 92.520%
epoch 19: train_loss = 0.030983, dev_loss = 0.000000, dev_rela_f1 = 0.9252
0.9251955117307039 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
model saved to ./saved_models/00/checkpoint_epoch_19.pt
new best model saved.
最好的预测结果是以及它的epoch: 0.9251955117307039 ---- 19

2021-07-13 07:16:28.642583: step 39160/164800 (epoch 20/80),jp_loss = 0.000153, trig_loss = 0.012512, rela_loss = 0.000000, bind_loss = 0.000000 (2.253 sec/batch), lr: 0.000100
2021-07-13 07:17:05.313678: step 39180/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 3.972351, rela_loss = 0.000001, bind_loss = 0.000000 (1.039 sec/batch), lr: 0.000100
2021-07-13 07:17:51.843029: step 39200/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000007, bind_loss = 0.000000 (0.827 sec/batch), lr: 0.000100
2021-07-13 07:18:21.533312: step 39220/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000336, rela_loss = 0.000000, bind_loss = 0.000000 (0.741 sec/batch), lr: 0.000100
2021-07-13 07:19:03.920377: step 39240/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.001038, rela_loss = 0.000090, bind_loss = 0.000000 (0.930 sec/batch), lr: 0.000100
2021-07-13 07:19:38.786093: step 39260/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000002, bind_loss = 0.000000 (1.806 sec/batch), lr: 0.000100
2021-07-13 07:20:17.910065: step 39280/164800 (epoch 20/80),jp_loss = 0.000046, trig_loss = 0.000015, rela_loss = 0.000000, bind_loss = 0.000013 (0.719 sec/batch), lr: 0.000100
2021-07-13 07:20:47.024005: step 39300/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000012, bind_loss = 0.000000 (0.999 sec/batch), lr: 0.000100
2021-07-13 07:21:24.833189: step 39320/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.337 sec/batch), lr: 0.000100
2021-07-13 07:21:53.023630: step 39340/164800 (epoch 20/80),jp_loss = 0.000046, trig_loss = 0.582321, rela_loss = 0.000691, bind_loss = 0.000000 (1.618 sec/batch), lr: 0.000100
2021-07-13 07:22:25.554165: step 39360/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000278, bind_loss = 0.000000 (0.823 sec/batch), lr: 0.000100
2021-07-13 07:23:07.438139: step 39380/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000002, bind_loss = 0.000000 (0.820 sec/batch), lr: 0.000100
2021-07-13 07:23:38.798912: step 39400/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000000, rela_loss = 0.000340, bind_loss = 0.000000 (1.284 sec/batch), lr: 0.000100
2021-07-13 07:24:17.701258: step 39420/164800 (epoch 20/80),jp_loss = 0.000015, trig_loss = 0.000046, rela_loss = 0.000000, bind_loss = 0.000000 (0.445 sec/batch), lr: 0.000100
2021-07-13 07:24:55.092302: step 39440/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000000, rela_loss = 0.000069, bind_loss = 0.000000 (0.760 sec/batch), lr: 0.000100
2021-07-13 07:25:28.594630: step 39460/164800 (epoch 20/80),jp_loss = 0.000046, trig_loss = 0.001495, rela_loss = 0.001304, bind_loss = 0.000000 (1.201 sec/batch), lr: 0.000100
2021-07-13 07:26:04.938588: step 39480/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000100, bind_loss = 0.000000 (0.817 sec/batch), lr: 0.000100
2021-07-13 07:26:42.561802: step 39500/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000061, rela_loss = 0.000006, bind_loss = 0.000000 (0.992 sec/batch), lr: 0.000100
2021-07-13 07:27:06.612247: step 39520/164800 (epoch 20/80),jp_loss = 0.000046, trig_loss = 0.000671, rela_loss = 0.000004, bind_loss = 0.000005 (1.948 sec/batch), lr: 0.000100
2021-07-13 07:27:32.114636: step 39540/164800 (epoch 20/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000001, bind_loss = 0.000000 (0.868 sec/batch), lr: 0.000100
2021-07-13 07:28:15.255816: step 39560/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 11.031708, rela_loss = 0.000342, bind_loss = 0.000000 (3.027 sec/batch), lr: 0.000100
2021-07-13 07:28:45.349970: step 39580/164800 (epoch 20/80),jp_loss = 0.000427, trig_loss = 0.000061, rela_loss = 0.000046, bind_loss = 0.000000 (0.997 sec/batch), lr: 0.000100
2021-07-13 07:29:14.124112: step 39600/164800 (epoch 20/80),jp_loss = 0.000198, trig_loss = 0.000229, rela_loss = 0.000000, bind_loss = 0.000000 (1.247 sec/batch), lr: 0.000100
2021-07-13 07:30:07.260030: step 39620/164800 (epoch 20/80),jp_loss = 0.000183, trig_loss = 4.170532, rela_loss = 0.000007, bind_loss = 0.000000 (6.590 sec/batch), lr: 0.000100
2021-07-13 07:30:33.326794: step 39640/164800 (epoch 20/80),jp_loss = 0.000015, trig_loss = 0.000061, rela_loss = 0.000000, bind_loss = 0.000000 (0.774 sec/batch), lr: 0.000100
2021-07-13 07:31:05.164291: step 39660/164800 (epoch 20/80),jp_loss = 0.000183, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (0.824 sec/batch), lr: 0.000100
2021-07-13 07:31:46.279714: step 39680/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000031, rela_loss = 0.000010, bind_loss = 0.000000 (0.828 sec/batch), lr: 0.000100
2021-07-13 07:32:27.664658: step 39700/164800 (epoch 20/80),jp_loss = 0.000061, trig_loss = 0.002563, rela_loss = 0.000024, bind_loss = 0.000000 (3.725 sec/batch), lr: 0.000100
2021-07-13 07:33:10.430134: step 39720/164800 (epoch 20/80),jp_loss = 0.000092, trig_loss = 0.001038, rela_loss = 0.000673, bind_loss = 0.000000 (2.109 sec/batch), lr: 0.000100
2021-07-13 07:33:38.881327: step 39740/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000092, rela_loss = 0.000012, bind_loss = 0.000000 (2.043 sec/batch), lr: 0.000100
2021-07-13 07:34:08.658377: step 39760/164800 (epoch 20/80),jp_loss = 0.000092, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000031 (2.127 sec/batch), lr: 0.000100
2021-07-13 07:34:45.457779: step 39780/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000153, rela_loss = 0.000000, bind_loss = 0.000000 (1.660 sec/batch), lr: 0.000100
2021-07-13 07:35:13.162860: step 39800/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (0.833 sec/batch), lr: 0.000100
2021-07-13 07:35:41.849916: step 39820/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.000031, rela_loss = 0.000000, bind_loss = 0.000000 (1.341 sec/batch), lr: 0.000100
2021-07-13 07:36:11.422565: step 39840/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000473, rela_loss = 0.000000, bind_loss = 0.000000 (1.429 sec/batch), lr: 0.000100
2021-07-13 07:36:44.313717: step 39860/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000168, rela_loss = 0.000003, bind_loss = 0.000000 (0.802 sec/batch), lr: 0.000100
2021-07-13 07:37:13.838729: step 39880/164800 (epoch 20/80),jp_loss = 0.000061, trig_loss = 0.000000, rela_loss = 0.000000, bind_loss = 0.000000 (1.485 sec/batch), lr: 0.000100
2021-07-13 07:37:52.213051: step 39900/164800 (epoch 20/80),jp_loss = 0.000031, trig_loss = 0.001007, rela_loss = 0.000007, bind_loss = 0.000000 (0.963 sec/batch), lr: 0.000100
2021-07-13 07:38:31.271836: step 39920/164800 (epoch 20/80),jp_loss = 0.000008, trig_loss = 0.000023, rela_loss = 0.000000, bind_loss = 0.000000 (0.416 sec/batch), lr: 0.000100
2021-07-13 07:39:18.641902: step 39940/164800 (epoch 20/80),jp_loss = 0.000000, trig_loss = 0.000092, rela_loss = 0.000002, bind_loss = 0.000000 (1.080 sec/batch), lr: 0.000100
